{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxkYE3ui8jUA"
      },
      "source": [
        "# Conformalized Early Stopping -- Regression\n",
        "\n",
        "- We implement the conformalized early stopping algorithm as well as the benchmark methods on the bike sharing demand dataset provided by Hadi Fanaee Tork from Capital Bikeshare and hosted by the UCI Machine Learning Repository [1]. \n",
        "\n",
        "**Note: the following dataset description is copied from UCI Machine Learning Repository. **\n",
        "Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. \n",
        "\n",
        "Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.\n",
        "\n",
        "- We follow the data cleaning process and used the same model architecture as in the conformalized quantile regression experiments https://github.com/yromano/cqr/tree/master/datasets [2]. To be specific, we standardize the features to have zero mean and unit variance and we rescale the response by dividing it by its mean absolute value\n",
        "\n",
        "- For the benchmark methods, we randomly selected 2000 samples for training the deep neural network models, 1000 validation samples to decide the early stopped models, and additional 1000 samples for calibration. For the conformalized early stopping method, we use the same subset of selected samples but merge the training and validation samples and use the merged dataset for training. The 1000 calibration samples are used together with new test point to select the best models. For both benchmark and our proposed method, we train the model for  ùëámax=200  epochs, saving every snapshot, and compute the marginal coverage rate and size of the prediction intervals averaged over 100 test samples.\n",
        "\n",
        "[1] Fanaee-T, Hadi, and Gama, Joao, Event labeling combining ensemble detectors and background knowledge, Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg.\n",
        "\n",
        "[2] Yaniv Romano, Evan Patterson, Emmanuel J. Cand√®s, Conformalized Quantile Regression, Advances in Neural Information Processing Systems (2019), https://proceedings.neurips.cc/paper/2019/file/5103c3584b063c431bd1268e9b5e76fb-Paper.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JIldzj5v85NM"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sCwcnBLS9tfs"
      },
      "outputs": [],
      "source": [
        "# Python 2/3 compatibility\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "import torch as th\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sympy import *\n",
        "import pathlib\n",
        "import pdb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from method import CES_regression\n",
        "from networks import mse_model, MSE_loss\n",
        "from inference import Conformal_PI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lIBhCgRV-N-5"
      },
      "outputs": [],
      "source": [
        "# Colors from Colorbrewer Paired_12\n",
        "colors = [[31, 120, 180], [51, 160, 44], [250,159,181]]\n",
        "colors = [(r / 255, g / 255, b / 255) for (r, g, b) in colors]\n",
        "\n",
        "def plot_loss(train_loss, val_loss):\n",
        "    x = np.arange(1, len(train_loss) + 1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(x, train_loss, color=colors[0], label=\"Training loss\", linewidth=2)\n",
        "    plt.plot(x, val_loss, color=colors[1], label=\"Validation loss\", linewidth=2)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(\"Evolution of the training, validation and test loss\")\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIBXVhEI-gls"
      },
      "source": [
        "## Loading and cleaning the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0mWmJmd2-mQK"
      },
      "outputs": [],
      "source": [
        "reload_dataset = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cYyJKayE-jwP"
      },
      "outputs": [],
      "source": [
        "if reload_dataset:\n",
        "  !git clone https://github.com/yromano/cqr.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hdg9xK0z_BgT"
      },
      "outputs": [],
      "source": [
        "from cqr.datasets import datasets\n",
        "\n",
        "class PrepareData(Dataset):\n",
        "\n",
        "    def __init__(self, X, y, scale_X=False):\n",
        "        if not torch.is_tensor(X):\n",
        "            if scale_X:\n",
        "                X = StandardScaler().fit_transform(X)\n",
        "                self.X = torch.from_numpy(X)\n",
        "            self.X = torch.from_numpy(X)\n",
        "        if not torch.is_tensor(y):\n",
        "            self.y = torch.from_numpy(y)\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx].float(), self.y[idx].float()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7XGL3H4_O0d"
      },
      "source": [
        "## Training and evaluating the benchmark methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ1fKvOH--4_",
        "outputId": "747128c1-84fc-474f-e69f-85911e2ed108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (BM): train (2000, 18), validation (1000, 18), calibration (1000, 18), test (100, 18)\n"
          ]
        }
      ],
      "source": [
        "# specify the number of samples in training, validation, calibration and test datasets\n",
        "n_train = 2000\n",
        "n_val = 1000\n",
        "n_cal = 1000\n",
        "n_test = 100 \n",
        "\n",
        "seed = 23333\n",
        "np.random.seed(seed)\n",
        "th.manual_seed(seed)\n",
        "\n",
        "idx = np.random.permutation(n_train+n_val+n_cal)\n",
        "idx_test = np.random.permutation(n_test)\n",
        "\n",
        "# divide the data into proper training set and calibration set\n",
        "idx_train_BM, idx_val_BM, idx_cal_BM = idx[:n_train], idx[n_train:n_val+n_train], idx[n_val+n_train: n_val+n_train + n_cal]\n",
        "\n",
        "# load the data\n",
        "X, y = datasets.GetDataset('bike', './cqr/datasets/')\n",
        "\n",
        "# split the dataset into disjoint subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# zero mean and unit variance scaling of the train and test features\n",
        "scalerX = StandardScaler()\n",
        "scalerX = scalerX.fit(X_train[idx_train_BM])\n",
        "X_train = scalerX.transform(X_train)\n",
        "X_test = scalerX.transform(X_test[idx_test])\n",
        "\n",
        "# scale the response values by dividing each by the mean absolute response\n",
        "mean_ytrain = np.mean(np.abs(y_train[idx_train_BM]))\n",
        "y_train = np.squeeze(y_train)/mean_ytrain\n",
        "y_test = np.squeeze(y_test[idx_test])/mean_ytrain\n",
        "\n",
        "# reshape the data\n",
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)\n",
        "X_test = np.asarray(X_test)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "# data splitting\n",
        "X_train_BM, y_train_BM = X_train[idx_train_BM], y_train[idx_train_BM]\n",
        "X_val_BM, y_val_BM = X_train[idx_val_BM], y_train[idx_val_BM]\n",
        "X_cal_BM, y_cal_BM = X_train[idx_cal_BM], y_train[idx_cal_BM]\n",
        "\n",
        "print(\"Size (BM): train (%d, %d), validation (%d, %d), calibration (%d, %d), test (%d, %d)\" % \\\n",
        "      (X_train_BM.shape[0], X_train_BM.shape[1], X_val_BM.shape[0], X_val_BM.shape[1], \n",
        "       X_cal_BM.shape[0], X_cal_BM.shape[1], X_test.shape[0], X_test.shape[1]))\n",
        "# sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "J9cV5Ocx_ysS"
      },
      "outputs": [],
      "source": [
        "# set model hyperparameter\n",
        "batch_size = 64\n",
        "in_shape = X_train_BM.shape[1]\n",
        "hidden_layer_size = 256\n",
        "dropout = 0\n",
        "num_epochs = 200\n",
        "lr = 0.0005\n",
        "wd = 1e-5\n",
        "\n",
        "num_workers = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWjXs3W1_rtl",
        "outputId": "c09e4b71-a5e0-4a90-9b38-aac07d6a9b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloader size (BM): train (32), validation (15), calibration (1000), test (100)\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(PrepareData(X_train_BM, y_train_BM, scale_X=False), batch_size=batch_size)\n",
        "val_loader = DataLoader(PrepareData(X_val_BM, y_val_BM, scale_X=False), batch_size=batch_size, drop_last = True) \n",
        "calib_loader = DataLoader(PrepareData(X_cal_BM, y_cal_BM, scale_X=False), batch_size=1, shuffle = False, drop_last=True)\n",
        "test_loader = DataLoader(PrepareData(X_test, y_test, scale_X=False), batch_size= 1, shuffle = False)\n",
        "\n",
        "print(\"Dataloader size (BM): train (%d), validation (%d), calibration (%d), test (%d)\" % \\\n",
        "      (len(train_loader), len(val_loader), len(calib_loader), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFqDP_iH_vzR",
        "outputId": "3818d115-12f5-4897-db7b-d91f6e0b2141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 64\n",
            "n_epochs= 200\n",
            "learning_rate= 0.0005\n",
            "==============================\n"
          ]
        }
      ],
      "source": [
        "# intialize the model\n",
        "mod = mse_model(in_shape = in_shape, hidden_size = hidden_layer_size) #, dropout = dropout\n",
        "optimizer = torch.optim.Adam(mod.parameters(), lr=lr, weight_decay = wd)\n",
        "\n",
        "if th.cuda.is_available():\n",
        "    # Make CuDNN Determinist\n",
        "    th.backends.cudnn.deterministic = True\n",
        "    th.cuda.manual_seed(seed)\n",
        "\n",
        "# Define default device, we should use the GPU (cuda) if available\n",
        "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
        "\n",
        "BM_reg = CES_regression(mod, device, train_loader, batch_size=batch_size, max_epoch = num_epochs, \n",
        "                        learning_rate=lr, val_loader=val_loader, criterion= MSE_loss, optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_39tUd88AHcj",
        "outputId": "447e23dd-715b-485f-bdac-f4cefcf2e097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 200, 9% \t train_loss: 2.09  took: 0.01s\n",
            "Epoch 1 of 200, 18% \t train_loss: 1.30  took: 0.01s\n",
            "Epoch 1 of 200, 28% \t train_loss: 0.85  took: 0.01s\n",
            "Epoch 1 of 200, 37% \t train_loss: 1.13  took: 0.01s\n",
            "Epoch 1 of 200, 46% \t train_loss: 0.87  took: 0.01s\n",
            "Epoch 1 of 200, 56% \t train_loss: 1.00  took: 0.01s\n",
            "Epoch 1 of 200, 65% \t train_loss: 0.90  took: 0.01s\n",
            "Epoch 1 of 200, 75% \t train_loss: 0.74  took: 0.01s\n",
            "Epoch 1 of 200, 84% \t train_loss: 0.63  took: 0.01s\n",
            "Epoch 1 of 200, 93% \t train_loss: 0.62  took: 0.01s\n",
            "val_loss = 0.63\n",
            "Snapshot saved at epoch 1.\n",
            "Epoch 2 of 200, 9% \t train_loss: 0.75  took: 0.01s\n",
            "Epoch 2 of 200, 18% \t train_loss: 0.57  took: 0.01s\n",
            "Epoch 2 of 200, 28% \t train_loss: 0.53  took: 0.01s\n",
            "Epoch 2 of 200, 37% \t train_loss: 0.59  took: 0.01s\n",
            "Epoch 2 of 200, 46% \t train_loss: 0.51  took: 0.01s\n",
            "Epoch 2 of 200, 56% \t train_loss: 0.64  took: 0.01s\n",
            "Epoch 2 of 200, 65% \t train_loss: 0.62  took: 0.01s\n",
            "Epoch 2 of 200, 75% \t train_loss: 0.53  took: 0.01s\n",
            "Epoch 2 of 200, 84% \t train_loss: 0.44  took: 0.01s\n",
            "Epoch 2 of 200, 93% \t train_loss: 0.51  took: 0.01s\n",
            "val_loss = 0.55\n",
            "Snapshot saved at epoch 2.\n",
            "Epoch 3 of 200, 9% \t train_loss: 0.64  took: 0.01s\n",
            "Epoch 3 of 200, 18% \t train_loss: 0.49  took: 0.01s\n",
            "Epoch 3 of 200, 28% \t train_loss: 0.50  took: 0.01s\n",
            "Epoch 3 of 200, 37% \t train_loss: 0.54  took: 0.01s\n",
            "Epoch 3 of 200, 46% \t train_loss: 0.45  took: 0.01s\n",
            "Epoch 3 of 200, 56% \t train_loss: 0.59  took: 0.01s\n",
            "Epoch 3 of 200, 65% \t train_loss: 0.57  took: 0.01s\n",
            "Epoch 3 of 200, 75% \t train_loss: 0.49  took: 0.01s\n",
            "Epoch 3 of 200, 84% \t train_loss: 0.43  took: 0.01s\n",
            "Epoch 3 of 200, 93% \t train_loss: 0.49  took: 0.01s\n",
            "val_loss = 0.53\n",
            "Snapshot saved at epoch 3.\n",
            "Epoch 4 of 200, 9% \t train_loss: 0.61  took: 0.01s\n",
            "Epoch 4 of 200, 18% \t train_loss: 0.47  took: 0.01s\n",
            "Epoch 4 of 200, 28% \t train_loss: 0.48  took: 0.01s\n",
            "Epoch 4 of 200, 37% \t train_loss: 0.51  took: 0.01s\n",
            "Epoch 4 of 200, 46% \t train_loss: 0.42  took: 0.01s\n",
            "Epoch 4 of 200, 56% \t train_loss: 0.56  took: 0.01s\n",
            "Epoch 4 of 200, 65% \t train_loss: 0.53  took: 0.01s\n",
            "Epoch 4 of 200, 75% \t train_loss: 0.46  took: 0.01s\n",
            "Epoch 4 of 200, 84% \t train_loss: 0.41  took: 0.02s\n",
            "Epoch 4 of 200, 93% \t train_loss: 0.47  took: 0.01s\n",
            "val_loss = 0.51\n",
            "Snapshot saved at epoch 4.\n",
            "Epoch 5 of 200, 9% \t train_loss: 0.59  took: 0.01s\n",
            "Epoch 5 of 200, 18% \t train_loss: 0.45  took: 0.01s\n",
            "Epoch 5 of 200, 28% \t train_loss: 0.45  took: 0.01s\n",
            "Epoch 5 of 200, 37% \t train_loss: 0.49  took: 0.01s\n",
            "Epoch 5 of 200, 46% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 5 of 200, 56% \t train_loss: 0.53  took: 0.01s\n",
            "Epoch 5 of 200, 65% \t train_loss: 0.50  took: 0.01s\n",
            "Epoch 5 of 200, 75% \t train_loss: 0.43  took: 0.01s\n",
            "Epoch 5 of 200, 84% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 5 of 200, 93% \t train_loss: 0.45  took: 0.01s\n",
            "val_loss = 0.49\n",
            "Snapshot saved at epoch 5.\n",
            "Epoch 6 of 200, 9% \t train_loss: 0.56  took: 0.01s\n",
            "Epoch 6 of 200, 18% \t train_loss: 0.43  took: 0.01s\n",
            "Epoch 6 of 200, 28% \t train_loss: 0.42  took: 0.01s\n",
            "Epoch 6 of 200, 37% \t train_loss: 0.46  took: 0.01s\n",
            "Epoch 6 of 200, 46% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 6 of 200, 56% \t train_loss: 0.50  took: 0.01s\n",
            "Epoch 6 of 200, 65% \t train_loss: 0.47  took: 0.01s\n",
            "Epoch 6 of 200, 75% \t train_loss: 0.41  took: 0.01s\n",
            "Epoch 6 of 200, 84% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 6 of 200, 93% \t train_loss: 0.43  took: 0.01s\n",
            "val_loss = 0.47\n",
            "Snapshot saved at epoch 6.\n",
            "Epoch 7 of 200, 9% \t train_loss: 0.54  took: 0.01s\n",
            "Epoch 7 of 200, 18% \t train_loss: 0.41  took: 0.01s\n",
            "Epoch 7 of 200, 28% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 7 of 200, 37% \t train_loss: 0.44  took: 0.01s\n",
            "Epoch 7 of 200, 46% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 7 of 200, 56% \t train_loss: 0.47  took: 0.01s\n",
            "Epoch 7 of 200, 65% \t train_loss: 0.45  took: 0.01s\n",
            "Epoch 7 of 200, 75% \t train_loss: 0.38  took: 0.01s\n",
            "Epoch 7 of 200, 84% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 7 of 200, 93% \t train_loss: 0.40  took: 0.01s\n",
            "val_loss = 0.45\n",
            "Snapshot saved at epoch 7.\n",
            "Epoch 8 of 200, 9% \t train_loss: 0.51  took: 0.01s\n",
            "Epoch 8 of 200, 18% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 8 of 200, 28% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 8 of 200, 37% \t train_loss: 0.41  took: 0.01s\n",
            "Epoch 8 of 200, 46% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 8 of 200, 56% \t train_loss: 0.44  took: 0.01s\n",
            "Epoch 8 of 200, 65% \t train_loss: 0.42  took: 0.01s\n",
            "Epoch 8 of 200, 75% \t train_loss: 0.36  took: 0.01s\n",
            "Epoch 8 of 200, 84% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 8 of 200, 93% \t train_loss: 0.38  took: 0.01s\n",
            "val_loss = 0.43\n",
            "Snapshot saved at epoch 8.\n",
            "Epoch 9 of 200, 9% \t train_loss: 0.49  took: 0.01s\n",
            "Epoch 9 of 200, 18% \t train_loss: 0.38  took: 0.01s\n",
            "Epoch 9 of 200, 28% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 9 of 200, 37% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 9 of 200, 46% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 9 of 200, 56% \t train_loss: 0.42  took: 0.01s\n",
            "Epoch 9 of 200, 65% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 9 of 200, 75% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 9 of 200, 84% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 9 of 200, 93% \t train_loss: 0.36  took: 0.02s\n",
            "val_loss = 0.42\n",
            "Snapshot saved at epoch 9.\n",
            "Epoch 10 of 200, 9% \t train_loss: 0.47  took: 0.01s\n",
            "Epoch 10 of 200, 18% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 10 of 200, 28% \t train_loss: 0.34  took: 0.02s\n",
            "Epoch 10 of 200, 37% \t train_loss: 0.38  took: 0.01s\n",
            "Epoch 10 of 200, 46% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 10 of 200, 56% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 10 of 200, 65% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 10 of 200, 75% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 10 of 200, 84% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 10 of 200, 93% \t train_loss: 0.35  took: 0.01s\n",
            "val_loss = 0.41\n",
            "Snapshot saved at epoch 10.\n",
            "Epoch 11 of 200, 9% \t train_loss: 0.45  took: 0.01s\n",
            "Epoch 11 of 200, 18% \t train_loss: 0.36  took: 0.01s\n",
            "Epoch 11 of 200, 28% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 11 of 200, 37% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 11 of 200, 46% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 11 of 200, 56% \t train_loss: 0.38  took: 0.01s\n",
            "Epoch 11 of 200, 65% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 11 of 200, 75% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 11 of 200, 84% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 11 of 200, 93% \t train_loss: 0.33  took: 0.01s\n",
            "val_loss = 0.40\n",
            "Snapshot saved at epoch 11.\n",
            "Epoch 12 of 200, 9% \t train_loss: 0.43  took: 0.01s\n",
            "Epoch 12 of 200, 18% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 12 of 200, 28% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 12 of 200, 37% \t train_loss: 0.36  took: 0.01s\n",
            "Epoch 12 of 200, 46% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 12 of 200, 56% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 12 of 200, 65% \t train_loss: 0.36  took: 0.01s\n",
            "Epoch 12 of 200, 75% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 12 of 200, 84% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 12 of 200, 93% \t train_loss: 0.32  took: 0.01s\n",
            "val_loss = 0.40\n",
            "Snapshot saved at epoch 12.\n",
            "Epoch 13 of 200, 9% \t train_loss: 0.42  took: 0.01s\n",
            "Epoch 13 of 200, 18% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 13 of 200, 28% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 13 of 200, 37% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 13 of 200, 46% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 13 of 200, 56% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 13 of 200, 65% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 13 of 200, 75% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 13 of 200, 84% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 13 of 200, 93% \t train_loss: 0.31  took: 0.01s\n",
            "val_loss = 0.39\n",
            "Snapshot saved at epoch 13.\n",
            "Epoch 14 of 200, 9% \t train_loss: 0.41  took: 0.01s\n",
            "Epoch 14 of 200, 18% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 14 of 200, 28% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 14 of 200, 37% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 14 of 200, 46% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 14 of 200, 56% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 14 of 200, 65% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 14 of 200, 75% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 14 of 200, 84% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 14 of 200, 93% \t train_loss: 0.30  took: 0.01s\n",
            "val_loss = 0.39\n",
            "Snapshot saved at epoch 14.\n",
            "Epoch 15 of 200, 9% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 15 of 200, 18% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 15 of 200, 28% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 15 of 200, 37% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 15 of 200, 46% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 15 of 200, 56% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 15 of 200, 65% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 15 of 200, 75% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 15 of 200, 84% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 15 of 200, 93% \t train_loss: 0.29  took: 0.01s\n",
            "val_loss = 0.38\n",
            "Snapshot saved at epoch 15.\n",
            "Epoch 16 of 200, 9% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 16 of 200, 18% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 16 of 200, 28% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 16 of 200, 37% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 16 of 200, 46% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 16 of 200, 56% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 16 of 200, 65% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 16 of 200, 75% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 16 of 200, 84% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 16 of 200, 93% \t train_loss: 0.28  took: 0.01s\n",
            "val_loss = 0.38\n",
            "Snapshot saved at epoch 16.\n",
            "Epoch 17 of 200, 9% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 17 of 200, 18% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 17 of 200, 28% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 17 of 200, 37% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 17 of 200, 46% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 17 of 200, 56% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 17 of 200, 65% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 17 of 200, 75% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 17 of 200, 84% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 17 of 200, 93% \t train_loss: 0.27  took: 0.01s\n",
            "val_loss = 0.38\n",
            "Snapshot saved at epoch 17.\n",
            "Epoch 18 of 200, 9% \t train_loss: 0.38  took: 0.01s\n",
            "Epoch 18 of 200, 18% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 18 of 200, 28% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 18 of 200, 37% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 18 of 200, 46% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 18 of 200, 56% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 18 of 200, 65% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 18 of 200, 75% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 18 of 200, 84% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 18 of 200, 93% \t train_loss: 0.26  took: 0.01s\n",
            "val_loss = 0.37\n",
            "Snapshot saved at epoch 18.\n",
            "Epoch 19 of 200, 9% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 19 of 200, 18% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 19 of 200, 28% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 19 of 200, 37% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 19 of 200, 46% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 19 of 200, 56% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 19 of 200, 65% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 19 of 200, 75% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 19 of 200, 84% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 19 of 200, 93% \t train_loss: 0.26  took: 0.01s\n",
            "val_loss = 0.37\n",
            "Snapshot saved at epoch 19.\n",
            "Epoch 20 of 200, 9% \t train_loss: 0.36  took: 0.01s\n",
            "Epoch 20 of 200, 18% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 20 of 200, 28% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 20 of 200, 37% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 20 of 200, 46% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 20 of 200, 56% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 20 of 200, 65% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 20 of 200, 75% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 20 of 200, 84% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 20 of 200, 93% \t train_loss: 0.25  took: 0.01s\n",
            "val_loss = 0.37\n",
            "Snapshot saved at epoch 20.\n",
            "Epoch 21 of 200, 9% \t train_loss: 0.36  took: 0.01s\n",
            "Epoch 21 of 200, 18% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 21 of 200, 28% \t train_loss: 0.26  took: 0.02s\n",
            "Epoch 21 of 200, 37% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 21 of 200, 46% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 21 of 200, 56% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 21 of 200, 65% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 21 of 200, 75% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 21 of 200, 84% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 21 of 200, 93% \t train_loss: 0.24  took: 0.01s\n",
            "val_loss = 0.36\n",
            "Snapshot saved at epoch 21.\n",
            "Epoch 22 of 200, 9% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 22 of 200, 18% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 22 of 200, 28% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 22 of 200, 37% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 22 of 200, 46% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 22 of 200, 56% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 22 of 200, 65% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 22 of 200, 75% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 22 of 200, 84% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 22 of 200, 93% \t train_loss: 0.23  took: 0.02s\n",
            "val_loss = 0.36\n",
            "Snapshot saved at epoch 22.\n",
            "Epoch 23 of 200, 9% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 23 of 200, 18% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 23 of 200, 28% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 23 of 200, 37% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 23 of 200, 46% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 23 of 200, 56% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 23 of 200, 65% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 23 of 200, 75% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 23 of 200, 84% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 23 of 200, 93% \t train_loss: 0.23  took: 0.01s\n",
            "val_loss = 0.36\n",
            "Snapshot saved at epoch 23.\n",
            "Epoch 24 of 200, 9% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 24 of 200, 18% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 24 of 200, 28% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 24 of 200, 37% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 24 of 200, 46% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 24 of 200, 56% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 24 of 200, 65% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 24 of 200, 75% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 24 of 200, 84% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 24 of 200, 93% \t train_loss: 0.22  took: 0.01s\n",
            "val_loss = 0.35\n",
            "Snapshot saved at epoch 24.\n",
            "Epoch 25 of 200, 9% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 25 of 200, 18% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 25 of 200, 28% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 25 of 200, 37% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 25 of 200, 46% \t train_loss: 0.23  took: 0.02s\n",
            "Epoch 25 of 200, 56% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 25 of 200, 65% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 25 of 200, 75% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 25 of 200, 84% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 25 of 200, 93% \t train_loss: 0.22  took: 0.02s\n",
            "val_loss = 0.35\n",
            "Snapshot saved at epoch 25.\n",
            "Epoch 26 of 200, 9% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 26 of 200, 18% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 26 of 200, 28% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 26 of 200, 37% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 26 of 200, 46% \t train_loss: 0.22  took: 0.02s\n",
            "Epoch 26 of 200, 56% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 26 of 200, 65% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 26 of 200, 75% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 26 of 200, 84% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 26 of 200, 93% \t train_loss: 0.21  took: 0.01s\n",
            "val_loss = 0.35\n",
            "Snapshot saved at epoch 26.\n",
            "Epoch 27 of 200, 9% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 27 of 200, 18% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 27 of 200, 28% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 27 of 200, 37% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 27 of 200, 46% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 27 of 200, 56% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 27 of 200, 65% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 27 of 200, 75% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 27 of 200, 84% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 27 of 200, 93% \t train_loss: 0.20  took: 0.01s\n",
            "val_loss = 0.35\n",
            "Snapshot saved at epoch 27.\n",
            "Epoch 28 of 200, 9% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 28 of 200, 18% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 28 of 200, 28% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 28 of 200, 37% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 28 of 200, 46% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 28 of 200, 56% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 28 of 200, 65% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 28 of 200, 75% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 28 of 200, 84% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 28 of 200, 93% \t train_loss: 0.20  took: 0.01s\n",
            "val_loss = 0.34\n",
            "Snapshot saved at epoch 28.\n",
            "Epoch 29 of 200, 9% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 29 of 200, 18% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 29 of 200, 28% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 29 of 200, 37% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 29 of 200, 46% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 29 of 200, 56% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 29 of 200, 65% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 29 of 200, 75% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 29 of 200, 84% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 29 of 200, 93% \t train_loss: 0.19  took: 0.01s\n",
            "val_loss = 0.34\n",
            "Snapshot saved at epoch 29.\n",
            "Epoch 30 of 200, 9% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 30 of 200, 18% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 30 of 200, 28% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 30 of 200, 37% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 30 of 200, 46% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 30 of 200, 56% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 30 of 200, 65% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 30 of 200, 75% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 30 of 200, 84% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 30 of 200, 93% \t train_loss: 0.19  took: 0.01s\n",
            "val_loss = 0.34\n",
            "Snapshot saved at epoch 30.\n",
            "Epoch 31 of 200, 9% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 31 of 200, 18% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 31 of 200, 28% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 31 of 200, 37% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 31 of 200, 46% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 31 of 200, 56% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 31 of 200, 65% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 31 of 200, 75% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 31 of 200, 84% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 31 of 200, 93% \t train_loss: 0.19  took: 0.01s\n",
            "val_loss = 0.34\n",
            "Snapshot saved at epoch 31.\n",
            "Epoch 32 of 200, 9% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 32 of 200, 18% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 32 of 200, 28% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 32 of 200, 37% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 32 of 200, 46% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 32 of 200, 56% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 32 of 200, 65% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 32 of 200, 75% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 32 of 200, 84% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 32 of 200, 93% \t train_loss: 0.18  took: 0.01s\n",
            "val_loss = 0.33\n",
            "Snapshot saved at epoch 32.\n",
            "Epoch 33 of 200, 9% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 33 of 200, 18% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 33 of 200, 28% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 33 of 200, 37% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 33 of 200, 46% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 33 of 200, 56% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 33 of 200, 65% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 33 of 200, 75% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 33 of 200, 84% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 33 of 200, 93% \t train_loss: 0.18  took: 0.01s\n",
            "val_loss = 0.33\n",
            "Snapshot saved at epoch 33.\n",
            "Epoch 34 of 200, 9% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 34 of 200, 18% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 34 of 200, 28% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 34 of 200, 37% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 34 of 200, 46% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 34 of 200, 56% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 34 of 200, 65% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 34 of 200, 75% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 34 of 200, 84% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 34 of 200, 93% \t train_loss: 0.17  took: 0.01s\n",
            "val_loss = 0.33\n",
            "Snapshot saved at epoch 34.\n",
            "Epoch 35 of 200, 9% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 35 of 200, 18% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 35 of 200, 28% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 35 of 200, 37% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 35 of 200, 46% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 35 of 200, 56% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 35 of 200, 65% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 35 of 200, 75% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 35 of 200, 84% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 35 of 200, 93% \t train_loss: 0.17  took: 0.01s\n",
            "val_loss = 0.33\n",
            "Snapshot saved at epoch 35.\n",
            "Epoch 36 of 200, 9% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 36 of 200, 18% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 36 of 200, 28% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 36 of 200, 37% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 36 of 200, 46% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 36 of 200, 56% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 36 of 200, 65% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 36 of 200, 75% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 36 of 200, 84% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 36 of 200, 93% \t train_loss: 0.17  took: 0.01s\n",
            "val_loss = 0.33\n",
            "Snapshot saved at epoch 36.\n",
            "Epoch 37 of 200, 9% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 37 of 200, 18% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 37 of 200, 28% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 37 of 200, 37% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 37 of 200, 46% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 37 of 200, 56% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 37 of 200, 65% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 37 of 200, 75% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 37 of 200, 84% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 37 of 200, 93% \t train_loss: 0.16  took: 0.01s\n",
            "val_loss = 0.32\n",
            "Snapshot saved at epoch 37.\n",
            "Epoch 38 of 200, 9% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 38 of 200, 18% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 38 of 200, 28% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 38 of 200, 37% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 38 of 200, 46% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 38 of 200, 56% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 38 of 200, 65% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 38 of 200, 75% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 38 of 200, 84% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 38 of 200, 93% \t train_loss: 0.16  took: 0.01s\n",
            "val_loss = 0.32\n",
            "Snapshot saved at epoch 38.\n",
            "Epoch 39 of 200, 9% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 39 of 200, 18% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 39 of 200, 28% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 39 of 200, 37% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 39 of 200, 46% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 39 of 200, 56% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 39 of 200, 65% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 39 of 200, 75% \t train_loss: 0.21  took: 0.02s\n",
            "Epoch 39 of 200, 84% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 39 of 200, 93% \t train_loss: 0.16  took: 0.01s\n",
            "val_loss = 0.32\n",
            "Snapshot saved at epoch 39.\n",
            "Epoch 40 of 200, 9% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 40 of 200, 18% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 40 of 200, 28% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 40 of 200, 37% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 40 of 200, 46% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 40 of 200, 56% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 40 of 200, 65% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 40 of 200, 75% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 40 of 200, 84% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 40 of 200, 93% \t train_loss: 0.15  took: 0.01s\n",
            "val_loss = 0.31\n",
            "Snapshot saved at epoch 40.\n",
            "Epoch 41 of 200, 9% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 41 of 200, 18% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 41 of 200, 28% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 41 of 200, 37% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 41 of 200, 46% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 41 of 200, 56% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 41 of 200, 65% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 41 of 200, 75% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 41 of 200, 84% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 41 of 200, 93% \t train_loss: 0.15  took: 0.01s\n",
            "val_loss = 0.31\n",
            "Snapshot saved at epoch 41.\n",
            "Epoch 42 of 200, 9% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 42 of 200, 18% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 42 of 200, 28% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 42 of 200, 37% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 42 of 200, 46% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 42 of 200, 56% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 42 of 200, 65% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 42 of 200, 75% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 42 of 200, 84% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 42 of 200, 93% \t train_loss: 0.15  took: 0.01s\n",
            "val_loss = 0.31\n",
            "Snapshot saved at epoch 42.\n",
            "Epoch 43 of 200, 9% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 43 of 200, 18% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 43 of 200, 28% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 43 of 200, 37% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 43 of 200, 46% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 43 of 200, 56% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 43 of 200, 65% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 43 of 200, 75% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 43 of 200, 84% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 43 of 200, 93% \t train_loss: 0.14  took: 0.01s\n",
            "val_loss = 0.31\n",
            "Snapshot saved at epoch 43.\n",
            "Epoch 44 of 200, 9% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 44 of 200, 18% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 44 of 200, 28% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 44 of 200, 37% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 44 of 200, 46% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 44 of 200, 56% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 44 of 200, 65% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 44 of 200, 75% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 44 of 200, 84% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 44 of 200, 93% \t train_loss: 0.14  took: 0.01s\n",
            "val_loss = 0.30\n",
            "Snapshot saved at epoch 44.\n",
            "Epoch 45 of 200, 9% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 45 of 200, 18% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 45 of 200, 28% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 45 of 200, 37% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 45 of 200, 46% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 45 of 200, 56% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 45 of 200, 65% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 45 of 200, 75% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 45 of 200, 84% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 45 of 200, 93% \t train_loss: 0.14  took: 0.01s\n",
            "val_loss = 0.30\n",
            "Snapshot saved at epoch 45.\n",
            "Epoch 46 of 200, 9% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 46 of 200, 18% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 46 of 200, 28% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 46 of 200, 37% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 46 of 200, 46% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 46 of 200, 56% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 46 of 200, 65% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 46 of 200, 75% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 46 of 200, 84% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 46 of 200, 93% \t train_loss: 0.13  took: 0.02s\n",
            "val_loss = 0.30\n",
            "Snapshot saved at epoch 46.\n",
            "Epoch 47 of 200, 9% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 47 of 200, 18% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 47 of 200, 28% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 47 of 200, 37% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 47 of 200, 46% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 47 of 200, 56% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 47 of 200, 65% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 47 of 200, 75% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 47 of 200, 84% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 47 of 200, 93% \t train_loss: 0.13  took: 0.01s\n",
            "val_loss = 0.30\n",
            "Snapshot saved at epoch 47.\n",
            "Epoch 48 of 200, 9% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 48 of 200, 18% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 48 of 200, 28% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 48 of 200, 37% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 48 of 200, 46% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 48 of 200, 56% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 48 of 200, 65% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 48 of 200, 75% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 48 of 200, 84% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 48 of 200, 93% \t train_loss: 0.13  took: 0.01s\n",
            "val_loss = 0.29\n",
            "Snapshot saved at epoch 48.\n",
            "Epoch 49 of 200, 9% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 49 of 200, 18% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 49 of 200, 28% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 49 of 200, 37% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 49 of 200, 46% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 49 of 200, 56% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 49 of 200, 65% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 49 of 200, 75% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 49 of 200, 84% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 49 of 200, 93% \t train_loss: 0.12  took: 0.01s\n",
            "val_loss = 0.29\n",
            "Snapshot saved at epoch 49.\n",
            "Epoch 50 of 200, 9% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 50 of 200, 18% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 50 of 200, 28% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 50 of 200, 37% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 50 of 200, 46% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 50 of 200, 56% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 50 of 200, 65% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 50 of 200, 75% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 50 of 200, 84% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 50 of 200, 93% \t train_loss: 0.12  took: 0.01s\n",
            "val_loss = 0.29\n",
            "Snapshot saved at epoch 50.\n",
            "Epoch 51 of 200, 9% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 51 of 200, 18% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 51 of 200, 28% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 51 of 200, 37% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 51 of 200, 46% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 51 of 200, 56% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 51 of 200, 65% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 51 of 200, 75% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 51 of 200, 84% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 51 of 200, 93% \t train_loss: 0.12  took: 0.01s\n",
            "val_loss = 0.29\n",
            "Snapshot saved at epoch 51.\n",
            "Epoch 52 of 200, 9% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 52 of 200, 18% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 52 of 200, 28% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 52 of 200, 37% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 52 of 200, 46% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 52 of 200, 56% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 52 of 200, 65% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 52 of 200, 75% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 52 of 200, 84% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 52 of 200, 93% \t train_loss: 0.11  took: 0.01s\n",
            "val_loss = 0.29\n",
            "Snapshot saved at epoch 52.\n",
            "Epoch 53 of 200, 9% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 53 of 200, 18% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 53 of 200, 28% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 53 of 200, 37% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 53 of 200, 46% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 53 of 200, 56% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 53 of 200, 65% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 53 of 200, 75% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 53 of 200, 84% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 53 of 200, 93% \t train_loss: 0.11  took: 0.01s\n",
            "val_loss = 0.28\n",
            "Snapshot saved at epoch 53.\n",
            "Epoch 54 of 200, 9% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 54 of 200, 18% \t train_loss: 0.18  took: 0.02s\n",
            "Epoch 54 of 200, 28% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 54 of 200, 37% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 54 of 200, 46% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 54 of 200, 56% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 54 of 200, 65% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 54 of 200, 75% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 54 of 200, 84% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 54 of 200, 93% \t train_loss: 0.11  took: 0.01s\n",
            "val_loss = 0.28\n",
            "Snapshot saved at epoch 54.\n",
            "Epoch 55 of 200, 9% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 55 of 200, 18% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 55 of 200, 28% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 55 of 200, 37% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 55 of 200, 46% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 55 of 200, 56% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 55 of 200, 65% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 55 of 200, 75% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 55 of 200, 84% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 55 of 200, 93% \t train_loss: 0.10  took: 0.01s\n",
            "val_loss = 0.28\n",
            "Snapshot saved at epoch 55.\n",
            "Epoch 56 of 200, 9% \t train_loss: 0.19  took: 0.02s\n",
            "Epoch 56 of 200, 18% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 56 of 200, 28% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 56 of 200, 37% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 56 of 200, 46% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 56 of 200, 56% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 56 of 200, 65% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 56 of 200, 75% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 56 of 200, 84% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 56 of 200, 93% \t train_loss: 0.10  took: 0.01s\n",
            "val_loss = 0.28\n",
            "Snapshot saved at epoch 56.\n",
            "Epoch 57 of 200, 9% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 57 of 200, 18% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 57 of 200, 28% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 57 of 200, 37% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 57 of 200, 46% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 57 of 200, 56% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 57 of 200, 65% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 57 of 200, 75% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 57 of 200, 84% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 57 of 200, 93% \t train_loss: 0.10  took: 0.01s\n",
            "val_loss = 0.28\n",
            "Snapshot saved at epoch 57.\n",
            "Epoch 58 of 200, 9% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 58 of 200, 18% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 58 of 200, 28% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 58 of 200, 37% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 58 of 200, 46% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 58 of 200, 56% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 58 of 200, 65% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 58 of 200, 75% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 58 of 200, 84% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 58 of 200, 93% \t train_loss: 0.10  took: 0.01s\n",
            "val_loss = 0.27\n",
            "Snapshot saved at epoch 58.\n",
            "Epoch 59 of 200, 9% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 59 of 200, 18% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 59 of 200, 28% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 59 of 200, 37% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 59 of 200, 46% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 59 of 200, 56% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 59 of 200, 65% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 59 of 200, 75% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 59 of 200, 84% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 59 of 200, 93% \t train_loss: 0.09  took: 0.01s\n",
            "val_loss = 0.27\n",
            "Snapshot saved at epoch 59.\n",
            "Epoch 60 of 200, 9% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 60 of 200, 18% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 60 of 200, 28% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 60 of 200, 37% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 60 of 200, 46% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 60 of 200, 56% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 60 of 200, 65% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 60 of 200, 75% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 60 of 200, 84% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 60 of 200, 93% \t train_loss: 0.09  took: 0.01s\n",
            "val_loss = 0.27\n",
            "Snapshot saved at epoch 60.\n",
            "Epoch 61 of 200, 9% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 61 of 200, 18% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 61 of 200, 28% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 61 of 200, 37% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 61 of 200, 46% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 61 of 200, 56% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 61 of 200, 65% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 61 of 200, 75% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 61 of 200, 84% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 61 of 200, 93% \t train_loss: 0.09  took: 0.01s\n",
            "val_loss = 0.27\n",
            "Snapshot saved at epoch 61.\n",
            "Epoch 62 of 200, 9% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 62 of 200, 18% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 62 of 200, 28% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 62 of 200, 37% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 62 of 200, 46% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 62 of 200, 56% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 62 of 200, 65% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 62 of 200, 75% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 62 of 200, 84% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 62 of 200, 93% \t train_loss: 0.09  took: 0.01s\n",
            "val_loss = 0.27\n",
            "Snapshot saved at epoch 62.\n",
            "Epoch 63 of 200, 9% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 63 of 200, 18% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 63 of 200, 28% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 63 of 200, 37% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 63 of 200, 46% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 63 of 200, 56% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 63 of 200, 65% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 63 of 200, 75% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 63 of 200, 84% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 63 of 200, 93% \t train_loss: 0.08  took: 0.01s\n",
            "val_loss = 0.27\n",
            "Snapshot saved at epoch 63.\n",
            "Epoch 64 of 200, 9% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 64 of 200, 18% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 64 of 200, 28% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 64 of 200, 37% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 64 of 200, 46% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 64 of 200, 56% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 64 of 200, 65% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 64 of 200, 75% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 64 of 200, 84% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 64 of 200, 93% \t train_loss: 0.08  took: 0.01s\n",
            "val_loss = 0.26\n",
            "Snapshot saved at epoch 64.\n",
            "Epoch 65 of 200, 9% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 65 of 200, 18% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 65 of 200, 28% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 65 of 200, 37% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 65 of 200, 46% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 65 of 200, 56% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 65 of 200, 65% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 65 of 200, 75% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 65 of 200, 84% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 65 of 200, 93% \t train_loss: 0.08  took: 0.01s\n",
            "val_loss = 0.26\n",
            "Snapshot saved at epoch 65.\n",
            "Epoch 66 of 200, 9% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 66 of 200, 18% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 66 of 200, 28% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 66 of 200, 37% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 66 of 200, 46% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 66 of 200, 56% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 66 of 200, 65% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 66 of 200, 75% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 66 of 200, 84% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 66 of 200, 93% \t train_loss: 0.08  took: 0.01s\n",
            "val_loss = 0.26\n",
            "Snapshot saved at epoch 66.\n",
            "Epoch 67 of 200, 9% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 67 of 200, 18% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 67 of 200, 28% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 67 of 200, 37% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 67 of 200, 46% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 67 of 200, 56% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 67 of 200, 65% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 67 of 200, 75% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 67 of 200, 84% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 67 of 200, 93% \t train_loss: 0.08  took: 0.01s\n",
            "val_loss = 0.26\n",
            "Snapshot saved at epoch 67.\n",
            "Epoch 68 of 200, 9% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 68 of 200, 18% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 68 of 200, 28% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 68 of 200, 37% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 68 of 200, 46% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 68 of 200, 56% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 68 of 200, 65% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 68 of 200, 75% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 68 of 200, 84% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 68 of 200, 93% \t train_loss: 0.07  took: 0.01s\n",
            "val_loss = 0.26\n",
            "Snapshot saved at epoch 68.\n",
            "Epoch 69 of 200, 9% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 69 of 200, 18% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 69 of 200, 28% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 69 of 200, 37% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 69 of 200, 46% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 69 of 200, 56% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 69 of 200, 65% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 69 of 200, 75% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 69 of 200, 84% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 69 of 200, 93% \t train_loss: 0.07  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 69.\n",
            "Epoch 70 of 200, 9% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 70 of 200, 18% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 70 of 200, 28% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 70 of 200, 37% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 70 of 200, 46% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 70 of 200, 56% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 70 of 200, 65% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 70 of 200, 75% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 70 of 200, 84% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 70 of 200, 93% \t train_loss: 0.07  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 70.\n",
            "Epoch 71 of 200, 9% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 71 of 200, 18% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 71 of 200, 28% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 71 of 200, 37% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 71 of 200, 46% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 71 of 200, 56% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 71 of 200, 65% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 71 of 200, 75% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 71 of 200, 84% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 71 of 200, 93% \t train_loss: 0.07  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 71.\n",
            "Epoch 72 of 200, 9% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 72 of 200, 18% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 72 of 200, 28% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 72 of 200, 37% \t train_loss: 0.12  took: 0.02s\n",
            "Epoch 72 of 200, 46% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 72 of 200, 56% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 72 of 200, 65% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 72 of 200, 75% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 72 of 200, 84% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 72 of 200, 93% \t train_loss: 0.07  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 72.\n",
            "Epoch 73 of 200, 9% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 73 of 200, 18% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 73 of 200, 28% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 73 of 200, 37% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 73 of 200, 46% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 73 of 200, 56% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 73 of 200, 65% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 73 of 200, 75% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 73 of 200, 84% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 73 of 200, 93% \t train_loss: 0.06  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 73.\n",
            "Epoch 74 of 200, 9% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 74 of 200, 18% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 74 of 200, 28% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 74 of 200, 37% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 74 of 200, 46% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 74 of 200, 56% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 74 of 200, 65% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 74 of 200, 75% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 74 of 200, 84% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 74 of 200, 93% \t train_loss: 0.06  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 74.\n",
            "Epoch 75 of 200, 9% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 75 of 200, 18% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 75 of 200, 28% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 75 of 200, 37% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 75 of 200, 46% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 75 of 200, 56% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 75 of 200, 65% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 75 of 200, 75% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 75 of 200, 84% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 75 of 200, 93% \t train_loss: 0.06  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 75.\n",
            "Epoch 76 of 200, 9% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 76 of 200, 18% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 76 of 200, 28% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 76 of 200, 37% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 76 of 200, 46% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 76 of 200, 56% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 76 of 200, 65% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 76 of 200, 75% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 76 of 200, 84% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 76 of 200, 93% \t train_loss: 0.06  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 76.\n",
            "Epoch 77 of 200, 9% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 77 of 200, 18% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 77 of 200, 28% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 77 of 200, 37% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 77 of 200, 46% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 77 of 200, 56% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 77 of 200, 65% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 77 of 200, 75% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 77 of 200, 84% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 77 of 200, 93% \t train_loss: 0.06  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 77.\n",
            "Epoch 78 of 200, 9% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 78 of 200, 18% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 78 of 200, 28% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 78 of 200, 37% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 78 of 200, 46% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 78 of 200, 56% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 78 of 200, 65% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 78 of 200, 75% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 78 of 200, 84% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 78 of 200, 93% \t train_loss: 0.06  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 78.\n",
            "Epoch 79 of 200, 9% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 79 of 200, 18% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 79 of 200, 28% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 79 of 200, 37% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 79 of 200, 46% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 79 of 200, 56% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 79 of 200, 65% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 79 of 200, 75% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 79 of 200, 84% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 79 of 200, 93% \t train_loss: 0.06  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 79.\n",
            "Epoch 80 of 200, 9% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 80 of 200, 18% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 80 of 200, 28% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 80 of 200, 37% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 80 of 200, 46% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 80 of 200, 56% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 80 of 200, 65% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 80 of 200, 75% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 80 of 200, 84% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 80 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 80.\n",
            "Epoch 81 of 200, 9% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 81 of 200, 18% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 81 of 200, 28% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 81 of 200, 37% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 81 of 200, 46% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 81 of 200, 56% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 81 of 200, 65% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 81 of 200, 75% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 81 of 200, 84% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 81 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 81.\n",
            "Epoch 82 of 200, 9% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 82 of 200, 18% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 82 of 200, 28% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 82 of 200, 37% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 82 of 200, 46% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 82 of 200, 56% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 82 of 200, 65% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 82 of 200, 75% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 82 of 200, 84% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 82 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 82.\n",
            "Epoch 83 of 200, 9% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 83 of 200, 18% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 83 of 200, 28% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 83 of 200, 37% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 83 of 200, 46% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 83 of 200, 56% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 83 of 200, 65% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 83 of 200, 75% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 83 of 200, 84% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 83 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 83.\n",
            "Epoch 84 of 200, 9% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 84 of 200, 18% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 84 of 200, 28% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 84 of 200, 37% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 84 of 200, 46% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 84 of 200, 56% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 84 of 200, 65% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 84 of 200, 75% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 84 of 200, 84% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 84 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 84.\n",
            "Epoch 85 of 200, 9% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 85 of 200, 18% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 85 of 200, 28% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 85 of 200, 37% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 85 of 200, 46% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 85 of 200, 56% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 85 of 200, 65% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 85 of 200, 75% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 85 of 200, 84% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 85 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 85.\n",
            "Epoch 86 of 200, 9% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 86 of 200, 18% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 86 of 200, 28% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 86 of 200, 37% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 86 of 200, 46% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 86 of 200, 56% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 86 of 200, 65% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 86 of 200, 75% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 86 of 200, 84% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 86 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 86.\n",
            "Epoch 87 of 200, 9% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 87 of 200, 18% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 87 of 200, 28% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 87 of 200, 37% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 87 of 200, 46% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 87 of 200, 56% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 87 of 200, 65% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 87 of 200, 75% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 87 of 200, 84% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 87 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 87.\n",
            "Epoch 88 of 200, 9% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 88 of 200, 18% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 88 of 200, 28% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 88 of 200, 37% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 88 of 200, 46% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 88 of 200, 56% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 88 of 200, 65% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 88 of 200, 75% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 88 of 200, 84% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 88 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 88.\n",
            "Epoch 89 of 200, 9% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 89 of 200, 18% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 89 of 200, 28% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 89 of 200, 37% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 89 of 200, 46% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 89 of 200, 56% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 89 of 200, 65% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 89 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 89 of 200, 84% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 89 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 89.\n",
            "Epoch 90 of 200, 9% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 90 of 200, 18% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 90 of 200, 28% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 90 of 200, 37% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 90 of 200, 46% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 90 of 200, 56% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 90 of 200, 65% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 90 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 90 of 200, 84% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 90 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 90.\n",
            "Epoch 91 of 200, 9% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 91 of 200, 18% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 91 of 200, 28% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 91 of 200, 37% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 91 of 200, 46% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 91 of 200, 56% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 91 of 200, 65% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 91 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 91 of 200, 84% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 91 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 91.\n",
            "Epoch 92 of 200, 9% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 92 of 200, 18% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 92 of 200, 28% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 92 of 200, 37% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 92 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 92 of 200, 56% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 92 of 200, 65% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 92 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 92 of 200, 84% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 92 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 92.\n",
            "Epoch 93 of 200, 9% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 93 of 200, 18% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 93 of 200, 28% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 93 of 200, 37% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 93 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 93 of 200, 56% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 93 of 200, 65% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 93 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 93 of 200, 84% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 93 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 93.\n",
            "Epoch 94 of 200, 9% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 94 of 200, 18% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 94 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 94 of 200, 37% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 94 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 94 of 200, 56% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 94 of 200, 65% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 94 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 94 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 94 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 94.\n",
            "Epoch 95 of 200, 9% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 95 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 95 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 95 of 200, 37% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 95 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 95 of 200, 56% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 95 of 200, 65% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 95 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 95 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 95 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 95.\n",
            "Epoch 96 of 200, 9% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 96 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 96 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 96 of 200, 37% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 96 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 96 of 200, 56% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 96 of 200, 65% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 96 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 96 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 96 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 96.\n",
            "Epoch 97 of 200, 9% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 97 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 97 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 97 of 200, 37% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 97 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 97 of 200, 56% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 97 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 97 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 97 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 97 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 97.\n",
            "Epoch 98 of 200, 9% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 98 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 98 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 98 of 200, 37% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 98 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 98 of 200, 56% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 98 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 98 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 98 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 98 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 98.\n",
            "Epoch 99 of 200, 9% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 99 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 99 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 99 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 99 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 99 of 200, 56% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 99 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 99 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 99 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 99 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 99.\n",
            "Epoch 100 of 200, 9% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 100 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 100 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 100 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 100 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 100 of 200, 56% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 100 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 100 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 100 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 100 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 100.\n",
            "Epoch 101 of 200, 9% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 101 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 101 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 101 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 101 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 101 of 200, 56% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 101 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 101 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 101 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 101 of 200, 93% \t train_loss: 0.04  took: 0.02s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 101.\n",
            "Epoch 102 of 200, 9% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 102 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 102 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 102 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 102 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 102 of 200, 56% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 102 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 102 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 102 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 102 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 102.\n",
            "Epoch 103 of 200, 9% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 103 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 103 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 103 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 103 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 103 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 103 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 103 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 103 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 103 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 103.\n",
            "Epoch 104 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 104 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 104 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 104 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 104 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 104 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 104 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 104 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 104 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 104 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 104.\n",
            "Epoch 105 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 105 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 105 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 105 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 105 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 105 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 105 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 105 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 105 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 105 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 105.\n",
            "Epoch 106 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 106 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 106 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 106 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 106 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 106 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 106 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 106 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 106 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 106 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 106.\n",
            "Epoch 107 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 107 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 107 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 107 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 107 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 107 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 107 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 107 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 107 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 107 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 107.\n",
            "Epoch 108 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 108 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 108 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 108 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 108 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 108 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 108 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 108 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 108 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 108 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 108.\n",
            "Epoch 109 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 109 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 109 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 109 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 109 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 109 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 109 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 109 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 109 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 109 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 109.\n",
            "Epoch 110 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 110 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 110 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 110 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 110 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 110 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 110 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 110 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 110 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 110 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 110.\n",
            "Epoch 111 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 111 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 111 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 111 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 111 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 111 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 111 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 111 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 111 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 111 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 111.\n",
            "Epoch 112 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 112 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 112 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 112 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 112 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 112 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 112 of 200, 65% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 112 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 112 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 112 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 112.\n",
            "Epoch 113 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 113 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 113 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 113 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 113 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 113 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 113 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 113 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 113 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 113 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 113.\n",
            "Epoch 114 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 114 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 114 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 114 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 114 of 200, 46% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 114 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 114 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 114 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 114 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 114 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 114.\n",
            "Epoch 115 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 115 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 115 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 115 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 115 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 115 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 115 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 115 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 115 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 115 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 115.\n",
            "Epoch 116 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 116 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 116 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 116 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 116 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 116 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 116 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 116 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 116 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 116 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 116.\n",
            "Epoch 117 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 117 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 117 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 117 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 117 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 117 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 117 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 117 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 117 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 117 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 117.\n",
            "Epoch 118 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 118 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 118 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 118 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 118 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 118 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 118 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 118 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 118 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 118 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 118.\n",
            "Epoch 119 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 119 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 119 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 119 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 119 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 119 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 119 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 119 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 119 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 119 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 119.\n",
            "Epoch 120 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 120 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 120 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 120 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 120.\n",
            "Epoch 121 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 121 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 121 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 121 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 121.\n",
            "Epoch 122 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 122 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 122 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 122 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 122.\n",
            "Epoch 123 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 123 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 123 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 123.\n",
            "Epoch 124 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 124 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 124 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 124 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 124 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 124 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 124 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 124 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 124 of 200, 84% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 124 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 124.\n",
            "Epoch 125 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 125 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 125 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 125 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 125.\n",
            "Epoch 126 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 126 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 126 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 126 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 126.\n",
            "Epoch 127 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 127 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 127 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 127 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 127.\n",
            "Epoch 128 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 128 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 128 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 128 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 128 of 200, 46% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 128 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 128 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 128 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 128 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 128 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 128.\n",
            "Epoch 129 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 129 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 129 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 129 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 129 of 200, 46% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 129 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 129 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 129 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 129 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 129 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 129.\n",
            "Epoch 130 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 130 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 130 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 130 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 130 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 130 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 130 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 130 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 130 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 130 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 130.\n",
            "Epoch 131 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 131 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 131 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 131 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 131 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 131 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 131 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 131 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 131 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 131 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 131.\n",
            "Epoch 132 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 132 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 132 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 132 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 132 of 200, 46% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 132 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 132 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 132 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 132 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 132 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 132.\n",
            "Epoch 133 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 133 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 133 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 133 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 133 of 200, 46% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 133 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 133 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 133 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 133 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 133 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 133.\n",
            "Epoch 134 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 134 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 134 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 134 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 134 of 200, 46% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 134 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 134 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 134 of 200, 75% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 134 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 134 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 134.\n",
            "Epoch 135 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 135 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 135 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 135 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 135 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 135 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 135 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 135 of 200, 75% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 135 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 135 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 135.\n",
            "Epoch 136 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 136 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 136 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 136 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 136 of 200, 46% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 136 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 136 of 200, 65% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 136 of 200, 75% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 136 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 136 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 136.\n",
            "Epoch 137 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 137 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 137 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 137 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 137 of 200, 46% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 137 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 137 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 137 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 137 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 137 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 137.\n",
            "Epoch 138 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 138 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 138 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 138 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 138 of 200, 46% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 138 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 138 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 138 of 200, 75% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 138 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 138 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 138.\n",
            "Epoch 139 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 139 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 139 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 139 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 139 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 139 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 139 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 139 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 139 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 139 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 139.\n",
            "Epoch 140 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 140 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 140 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 140 of 200, 46% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 140 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 140 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 140 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 140.\n",
            "Epoch 141 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 141 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 141 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 141 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 141 of 200, 46% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 141 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 75% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 141 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 141.\n",
            "Epoch 142 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 142 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 142 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 142 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 142 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 142 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 142 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 142 of 200, 75% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 142 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 142 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 142.\n",
            "Epoch 143 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 143 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 143 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 143 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 143 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 143 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 143 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 143 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 143 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 143 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 143.\n",
            "Epoch 144 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 144 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 144 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 144 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 144 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 144 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 144 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 144 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 144 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 144 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 144.\n",
            "Epoch 145 of 200, 9% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 145 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 145 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 145 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 145 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 145 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 145 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 145 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 145 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 145 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 145.\n",
            "Epoch 146 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 146 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 146 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 146 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 146 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 146 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 146 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 146 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 146 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 146 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 146.\n",
            "Epoch 147 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 147 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 147 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 147 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 147 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 147 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 147 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 147 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 147 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 147 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 147.\n",
            "Epoch 148 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 148 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 148 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 148 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 148 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 148 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 148 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 148 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 148 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 148 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.26\n",
            "Snapshot saved at epoch 148.\n",
            "Epoch 149 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 149 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 149 of 200, 28% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 149 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 149 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 149 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 149 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 149 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 149 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 149 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.27\n",
            "Snapshot saved at epoch 149.\n",
            "Epoch 150 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 150 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 150 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 150 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 150 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 150 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 150 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 150 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 150 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 150 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.26\n",
            "Snapshot saved at epoch 150.\n",
            "Epoch 151 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 151 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 151 of 200, 28% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 151 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 151 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 151 of 200, 56% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 151 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 151 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 151 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 151 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 151.\n",
            "Epoch 152 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 152 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 152 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 152 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 152 of 200, 46% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 152 of 200, 56% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 152 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 152 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 152 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 152 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.28\n",
            "Snapshot saved at epoch 152.\n",
            "Epoch 153 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 153 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 153 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 153 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 153 of 200, 46% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 153 of 200, 56% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 153 of 200, 65% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 153 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 153 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 153 of 200, 93% \t train_loss: 0.07  took: 0.01s\n",
            "val_loss = 0.31\n",
            "Snapshot saved at epoch 153.\n",
            "Epoch 154 of 200, 9% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 154 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 154 of 200, 28% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 154 of 200, 37% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 154 of 200, 46% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 154 of 200, 56% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 154 of 200, 65% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 154 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 154 of 200, 84% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 154 of 200, 93% \t train_loss: 0.08  took: 0.01s\n",
            "val_loss = 0.30\n",
            "Snapshot saved at epoch 154.\n",
            "Epoch 155 of 200, 9% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 155 of 200, 18% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 155 of 200, 28% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 155 of 200, 37% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 155 of 200, 46% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 155 of 200, 56% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 155 of 200, 65% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 155 of 200, 75% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 155 of 200, 84% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 155 of 200, 93% \t train_loss: 0.09  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 155.\n",
            "Epoch 156 of 200, 9% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 156 of 200, 18% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 156 of 200, 28% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 156 of 200, 37% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 156 of 200, 46% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 156 of 200, 56% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 156 of 200, 65% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 156 of 200, 75% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 156 of 200, 84% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 156 of 200, 93% \t train_loss: 0.19  took: 0.01s\n",
            "val_loss = 0.37\n",
            "Snapshot saved at epoch 156.\n",
            "Epoch 157 of 200, 9% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 157 of 200, 18% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 157 of 200, 28% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 157 of 200, 37% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 157 of 200, 46% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 157 of 200, 56% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 157 of 200, 65% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 157 of 200, 75% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 157 of 200, 84% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 157 of 200, 93% \t train_loss: 0.07  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 157.\n",
            "Epoch 158 of 200, 9% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 158 of 200, 18% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 158 of 200, 28% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 158 of 200, 37% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 158 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 158 of 200, 56% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 158 of 200, 65% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 158 of 200, 75% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 158 of 200, 84% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 158 of 200, 93% \t train_loss: 0.06  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 158.\n",
            "Epoch 159 of 200, 9% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 159 of 200, 18% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 159 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 159 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 159 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 159 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 159 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 159 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 159 of 200, 84% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 159 of 200, 93% \t train_loss: 0.06  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 159.\n",
            "Epoch 160 of 200, 9% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 160 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 160 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 160 of 200, 37% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 160 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 160 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 160 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 160 of 200, 75% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 160 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 160 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 160.\n",
            "Epoch 161 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 161 of 200, 18% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 161 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 161 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 161 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 161 of 200, 56% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 161 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 161 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 161 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 161 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 161.\n",
            "Epoch 162 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 162 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 162 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 162 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 162 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 162 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 162 of 200, 65% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 162 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 162 of 200, 84% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 162 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 162.\n",
            "Epoch 163 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 163 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 163 of 200, 28% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 163 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 163 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 163 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 163 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 163 of 200, 75% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 163 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 163 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 163.\n",
            "Epoch 164 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 164 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 164 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 164 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 164 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 164 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 164 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 164 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 164 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 164 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 164.\n",
            "Epoch 165 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 165 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 165 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 165 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 165 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 165 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 165 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 165 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 165 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 165 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 165.\n",
            "Epoch 166 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 166 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 166 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 166 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 166 of 200, 46% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 166 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 166 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 166 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 166 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 166 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 166.\n",
            "Epoch 167 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 167 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 167 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 167 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 167 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 167 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 167 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 167 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 167 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 167 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 167.\n",
            "Epoch 168 of 200, 9% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 168 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 168 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 168 of 200, 37% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 168 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 168 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 168 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 168 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 168 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 168 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 168.\n",
            "Epoch 169 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 169 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 169 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 169 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 169 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 169 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 169 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 169 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 169 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 169 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 169.\n",
            "Epoch 170 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 170 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 170 of 200, 28% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 170 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 170 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 170 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 170 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 170 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 170 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 170 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 170.\n",
            "Epoch 171 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 171 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 171 of 200, 28% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 171 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 171 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 171 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 171 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 171 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 171 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 171 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 171.\n",
            "Epoch 172 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 172 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 172 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 172 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 172 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 172 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 172 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 172 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 172 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 172 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 172.\n",
            "Epoch 173 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 173 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 173 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 173 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 173 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 173 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 173 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 173 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 173 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 173 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 173.\n",
            "Epoch 174 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 174 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 174 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 174 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 174 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 174 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 174 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 174 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 174 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 174 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 174.\n",
            "Epoch 175 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 175 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 175 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 175 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 175 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 175 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 175 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 175 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 175 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 175 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 175.\n",
            "Epoch 176 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 176 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 176 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 176 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 176 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 176 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 176 of 200, 65% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 176 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 176 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 176 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 176.\n",
            "Epoch 177 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 177 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 177 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 177 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 177 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 177 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 177 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 177 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 177 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 177 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 177.\n",
            "Epoch 178 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 178 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 178 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 178 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 178 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 178 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 178 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 178 of 200, 75% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 178 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 178 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 178.\n",
            "Epoch 179 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 179 of 200, 18% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 179 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 179 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 179 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 179 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 179 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 179 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 179 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 179 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 179.\n",
            "Epoch 180 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 180 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 180 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 180 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 180 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 180 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 180 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 180 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 180 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 180 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 180.\n",
            "Epoch 181 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 181 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 181 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 181 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 181 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 181 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 181 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 181 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 181 of 200, 84% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 181 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 181.\n",
            "Epoch 182 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 182 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 182 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 182 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 182 of 200, 46% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 182 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 182 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 182 of 200, 75% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 182 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 182 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 182.\n",
            "Epoch 183 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 183 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 183 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 183 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 183 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 183 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 183 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 183 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 183 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 183 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 183.\n",
            "Epoch 184 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 184 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 184 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 184 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 184 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 184 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 184 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 184 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 184 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 184 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 184.\n",
            "Epoch 185 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 185 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 185 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 185 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 185 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 185 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 185 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 185 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 185 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 185 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 185.\n",
            "Epoch 186 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 186 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 186 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 186 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 186 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 186 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 186 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 186 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 186 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 186 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 186.\n",
            "Epoch 187 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 187 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 187 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 187 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 187 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 187 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 187 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 187 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 187 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 187 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 187.\n",
            "Epoch 188 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 188 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 188 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 188 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 188 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 188 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 188 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 188 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 188 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 188 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 188.\n",
            "Epoch 189 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 189 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 189 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 189 of 200, 37% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 189 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 189 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 189 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 189 of 200, 75% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 189 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 189 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 189.\n",
            "Epoch 190 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 190 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 190 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 190 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 190 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 190 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 190 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 190 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 190 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 190 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 190.\n",
            "Epoch 191 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 191 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 191 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 191 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 191 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 191.\n",
            "Epoch 192 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 192 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 192 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 192 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 192 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 192.\n",
            "Epoch 193 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 193 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 193 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 193 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 193 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 193.\n",
            "Epoch 194 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 194 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 194 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 194 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 194 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 194.\n",
            "Epoch 195 of 200, 9% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 195 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 195 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 195 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 195 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 195.\n",
            "Epoch 196 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 196 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 196 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 196 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 196 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 196 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 196 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 196 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 196 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 196 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 196.\n",
            "Epoch 197 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 197 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 197 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 197 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 197 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 197 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 197 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 197 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 197 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 197 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 197.\n",
            "Epoch 198 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 198 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 198 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 198 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 198 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 198 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 198 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 198 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 198 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 198 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 198.\n",
            "Epoch 199 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 199 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 199 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 199 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 199 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 199 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 199 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 199 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 199 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 199 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 199.\n",
            "Epoch 200 of 200, 9% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 200 of 200, 18% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 200 of 200, 28% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 200 of 200, 37% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 200 of 200, 46% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 200 of 200, 56% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 200 of 200, 65% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 200 of 200, 75% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 200 of 200, 84% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 200 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 200.\n",
            "Training done! A list of 200 models saved.\n"
          ]
        }
      ],
      "source": [
        "# Train the model and save snapshots regularly\n",
        "save_every = 1    # Save model after every few epoches\n",
        "BM_reg.full_train(save_dir = './content', save_every = save_every)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "HdaHLBzPAh1-",
        "outputId": "78a866c9-8706-4527-e7ea-e4767954086d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot the loss history\n",
        "plot_loss(BM_reg.train_loss_history, BM_reg.val_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa_m9YocAkze",
        "outputId": "50bdd05d-83d9-47f3-d6fb-c4ba417eb440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.20532156030337015\n",
            "./content/model163.pth\n"
          ]
        }
      ],
      "source": [
        "# Check the benchmark models\n",
        "bm_loss, bm_model, loss_history = BM_reg.select_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ3QrZ16AmND",
        "outputId": "6b78ca19-a394-4649-bf24-e02ce8a015d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:24<00:00,  4.02it/s]\n"
          ]
        }
      ],
      "source": [
        "# Split conformal prediction \n",
        "alpha = 0.1\n",
        "\n",
        "coverage_BM = []\n",
        "size_BM = []\n",
        "\n",
        "C_PI = Conformal_PI(mod, device, calib_loader, alpha)\n",
        "\n",
        "for input, response in tqdm(test_loader):\n",
        "  # pi, cal_scores, test_pred, qhat = C_PI.benchmark_ICP(input, calib_loader, bm_model)\n",
        "  benchmarkPI = C_PI.benchmark_ICP(input, bm_model)\n",
        "  size_BM.append(benchmarkPI[0]._measure)\n",
        "  coverage_BM.append(response in benchmarkPI[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The marginal coverage rate is (BM) {}\".format(sum(coverage_BM)/len(coverage_BM)))\n",
        "print(\"The average size is (BM) {}\".format(sum(size_BM)/len(size_BM)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDoan0P8eTcb",
        "outputId": "5b339fad-4697-4702-b6e4-6d4e6dfe365c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The marginal coverage rate is (BM) 0.9\n",
            "The average size is (BM) 1.43916225671768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xe62aWHA53p"
      },
      "source": [
        "## Conforamlized early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1u69aiAA5Yx",
        "outputId": "1f2f792e-ba58-41a8-d2e3-b14182429541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (CES): train (3000, 18), calibration (1000, 18), test (100, 18)\n"
          ]
        }
      ],
      "source": [
        "# specify the number of samples in training, validation, calibration and test datasets\n",
        "n_train = 2000\n",
        "n_val = 1000\n",
        "n_cal = 1000\n",
        "n_test = 100 \n",
        "\n",
        "seed = 233\n",
        "np.random.seed(seed)\n",
        "th.manual_seed(seed)\n",
        "idx = np.random.permutation(n_train+n_val+n_cal)\n",
        "idx_test = np.random.permutation(n_test)\n",
        "\n",
        "# divide the data into proper training set and calibration set\n",
        "idx_train_CES, idx_cal_CES = idx[:n_train+n_val], idx[n_train+n_val:n_train+n_val+n_cal]\n",
        "\n",
        "# load the dataset\n",
        "X, y = datasets.GetDataset('bike', './cqr/datasets/')\n",
        "\n",
        "# split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# # zero mean and unit variance scaling of the train and test features\n",
        "scalerX = StandardScaler()\n",
        "scalerX = scalerX.fit(X_train[idx_train_CES])\n",
        "X_train = scalerX.transform(X_train)\n",
        "X_test = scalerX.transform(X_test[idx_test])\n",
        "\n",
        "# # scale the labels by dividing each by the mean absolute response\n",
        "mean_ytrain = np.mean(np.abs(y_train[idx_train_CES]))\n",
        "y_train = np.squeeze(y_train)/mean_ytrain\n",
        "y_test = np.squeeze(y_test[idx_test])/mean_ytrain\n",
        "\n",
        "# reshape the data\n",
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)\n",
        "X_test = np.asarray(X_test)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "# data splitting\n",
        "X_train_CES, y_train_CES = X_train[idx_train_CES], y_train[idx_train_CES]\n",
        "X_cal_CES, y_cal_CES = X_train[idx_cal_CES], y_train[idx_cal_CES]\n",
        "\n",
        "print(\"Size (CES): train (%d, %d), calibration (%d, %d), test (%d, %d)\" % \\\n",
        "      (X_train_CES.shape[0], X_train_CES.shape[1], X_cal_CES.shape[0], X_cal_CES.shape[1], \n",
        "       X_test.shape[0], X_test.shape[1]))\n",
        "# sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "PLrkgdpmB1Ly"
      },
      "outputs": [],
      "source": [
        "# set model hyperparameter\n",
        "batch_size = 64\n",
        "in_shape = X_train_CES.shape[1]\n",
        "hidden_layer_size = 256\n",
        "dropout = 0\n",
        "num_epochs = 200\n",
        "lr = 0.0005\n",
        "wd = 1e-5\n",
        "num_workers = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBVQ8NKUBzQt",
        "outputId": "9980129d-c222-420a-8bc4-439d850d6d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloader size (BM): train (47), calibration (15), test (100)\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(PrepareData(X_train_CES, y_train_CES, scale_X=False), batch_size=batch_size)\n",
        "calib_loader = DataLoader(PrepareData(X_cal_CES, y_cal_CES, scale_X=False), batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(PrepareData(X_test, y_test, scale_X=False), batch_size= 1, shuffle = False)\n",
        "\n",
        "print(\"Dataloader size (BM): train (%d), calibration (%d), test (%d)\" % \\\n",
        "      (len(train_loader), len(calib_loader), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y5ifscrB_d7",
        "outputId": "e12f61d5-1dd3-4042-d838-0f98da176c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 64\n",
            "n_epochs= 200\n",
            "learning_rate= 0.0005\n",
            "==============================\n"
          ]
        }
      ],
      "source": [
        "# intialize the model\n",
        "mod = mse_model(in_shape = in_shape, hidden_size = hidden_layer_size) #, dropout = dropout\n",
        "optimizer = torch.optim.Adam(mod.parameters(), lr=lr, weight_decay = wd)\n",
        "\n",
        "if th.cuda.is_available():\n",
        "    # Make CuDNN Determinist\n",
        "    th.backends.cudnn.deterministic = True\n",
        "    th.cuda.manual_seed(seed)\n",
        "\n",
        "# Define default device, we should use the GPU (cuda) if available\n",
        "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
        "\n",
        "CES_reg = CES_regression(mod, device, train_loader, batch_size=batch_size, max_epoch = num_epochs, \n",
        "                        learning_rate=lr, val_loader=calib_loader, criterion= MSE_loss, optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6z7HjwCCDvl",
        "outputId": "76bf6789-66ce-4752-a20f-89102c948662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 200, 8% \t train_loss: 1.54  took: 0.02s\n",
            "Epoch 1 of 200, 17% \t train_loss: 1.20  took: 0.02s\n",
            "Epoch 1 of 200, 25% \t train_loss: 0.94  took: 0.01s\n",
            "Epoch 1 of 200, 34% \t train_loss: 0.89  took: 0.02s\n",
            "Epoch 1 of 200, 42% \t train_loss: 0.85  took: 0.02s\n",
            "Epoch 1 of 200, 51% \t train_loss: 0.78  took: 0.02s\n",
            "Epoch 1 of 200, 59% \t train_loss: 0.75  took: 0.01s\n",
            "Epoch 1 of 200, 68% \t train_loss: 0.80  took: 0.01s\n",
            "Epoch 1 of 200, 76% \t train_loss: 0.55  took: 0.01s\n",
            "Epoch 1 of 200, 85% \t train_loss: 0.51  took: 0.01s\n",
            "Epoch 1 of 200, 93% \t train_loss: 0.64  took: 0.02s\n",
            "val_loss = 0.56\n",
            "Snapshot saved at epoch 1.\n",
            "Epoch 2 of 200, 8% \t train_loss: 0.60  took: 0.02s\n",
            "Epoch 2 of 200, 17% \t train_loss: 0.63  took: 0.02s\n",
            "Epoch 2 of 200, 25% \t train_loss: 0.56  took: 0.01s\n",
            "Epoch 2 of 200, 34% \t train_loss: 0.56  took: 0.01s\n",
            "Epoch 2 of 200, 42% \t train_loss: 0.55  took: 0.01s\n",
            "Epoch 2 of 200, 51% \t train_loss: 0.52  took: 0.01s\n",
            "Epoch 2 of 200, 59% \t train_loss: 0.56  took: 0.01s\n",
            "Epoch 2 of 200, 68% \t train_loss: 0.58  took: 0.01s\n",
            "Epoch 2 of 200, 76% \t train_loss: 0.44  took: 0.01s\n",
            "Epoch 2 of 200, 85% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 2 of 200, 93% \t train_loss: 0.56  took: 0.02s\n",
            "val_loss = 0.49\n",
            "Snapshot saved at epoch 2.\n",
            "Epoch 3 of 200, 8% \t train_loss: 0.50  took: 0.01s\n",
            "Epoch 3 of 200, 17% \t train_loss: 0.59  took: 0.01s\n",
            "Epoch 3 of 200, 25% \t train_loss: 0.53  took: 0.02s\n",
            "Epoch 3 of 200, 34% \t train_loss: 0.51  took: 0.01s\n",
            "Epoch 3 of 200, 42% \t train_loss: 0.51  took: 0.02s\n",
            "Epoch 3 of 200, 51% \t train_loss: 0.50  took: 0.01s\n",
            "Epoch 3 of 200, 59% \t train_loss: 0.53  took: 0.01s\n",
            "Epoch 3 of 200, 68% \t train_loss: 0.54  took: 0.02s\n",
            "Epoch 3 of 200, 76% \t train_loss: 0.41  took: 0.01s\n",
            "Epoch 3 of 200, 85% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 3 of 200, 93% \t train_loss: 0.53  took: 0.02s\n",
            "val_loss = 0.47\n",
            "Snapshot saved at epoch 3.\n",
            "Epoch 4 of 200, 8% \t train_loss: 0.46  took: 0.01s\n",
            "Epoch 4 of 200, 17% \t train_loss: 0.56  took: 0.01s\n",
            "Epoch 4 of 200, 25% \t train_loss: 0.50  took: 0.02s\n",
            "Epoch 4 of 200, 34% \t train_loss: 0.48  took: 0.01s\n",
            "Epoch 4 of 200, 42% \t train_loss: 0.48  took: 0.01s\n",
            "Epoch 4 of 200, 51% \t train_loss: 0.48  took: 0.01s\n",
            "Epoch 4 of 200, 59% \t train_loss: 0.50  took: 0.01s\n",
            "Epoch 4 of 200, 68% \t train_loss: 0.51  took: 0.01s\n",
            "Epoch 4 of 200, 76% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 4 of 200, 85% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 4 of 200, 93% \t train_loss: 0.51  took: 0.01s\n",
            "val_loss = 0.44\n",
            "Snapshot saved at epoch 4.\n",
            "Epoch 5 of 200, 8% \t train_loss: 0.43  took: 0.01s\n",
            "Epoch 5 of 200, 17% \t train_loss: 0.53  took: 0.02s\n",
            "Epoch 5 of 200, 25% \t train_loss: 0.47  took: 0.01s\n",
            "Epoch 5 of 200, 34% \t train_loss: 0.44  took: 0.01s\n",
            "Epoch 5 of 200, 42% \t train_loss: 0.45  took: 0.01s\n",
            "Epoch 5 of 200, 51% \t train_loss: 0.46  took: 0.01s\n",
            "Epoch 5 of 200, 59% \t train_loss: 0.47  took: 0.01s\n",
            "Epoch 5 of 200, 68% \t train_loss: 0.48  took: 0.02s\n",
            "Epoch 5 of 200, 76% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 5 of 200, 85% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 5 of 200, 93% \t train_loss: 0.49  took: 0.01s\n",
            "val_loss = 0.42\n",
            "Snapshot saved at epoch 5.\n",
            "Epoch 6 of 200, 8% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 6 of 200, 17% \t train_loss: 0.50  took: 0.01s\n",
            "Epoch 6 of 200, 25% \t train_loss: 0.43  took: 0.01s\n",
            "Epoch 6 of 200, 34% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 6 of 200, 42% \t train_loss: 0.42  took: 0.01s\n",
            "Epoch 6 of 200, 51% \t train_loss: 0.44  took: 0.02s\n",
            "Epoch 6 of 200, 59% \t train_loss: 0.43  took: 0.02s\n",
            "Epoch 6 of 200, 68% \t train_loss: 0.46  took: 0.01s\n",
            "Epoch 6 of 200, 76% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 6 of 200, 85% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 6 of 200, 93% \t train_loss: 0.47  took: 0.02s\n",
            "val_loss = 0.39\n",
            "Snapshot saved at epoch 6.\n",
            "Epoch 7 of 200, 8% \t train_loss: 0.37  took: 0.02s\n",
            "Epoch 7 of 200, 17% \t train_loss: 0.47  took: 0.01s\n",
            "Epoch 7 of 200, 25% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 7 of 200, 34% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 7 of 200, 42% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 7 of 200, 51% \t train_loss: 0.42  took: 0.01s\n",
            "Epoch 7 of 200, 59% \t train_loss: 0.41  took: 0.01s\n",
            "Epoch 7 of 200, 68% \t train_loss: 0.43  took: 0.02s\n",
            "Epoch 7 of 200, 76% \t train_loss: 0.33  took: 0.02s\n",
            "Epoch 7 of 200, 85% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 7 of 200, 93% \t train_loss: 0.45  took: 0.01s\n",
            "val_loss = 0.38\n",
            "Snapshot saved at epoch 7.\n",
            "Epoch 8 of 200, 8% \t train_loss: 0.34  took: 0.02s\n",
            "Epoch 8 of 200, 17% \t train_loss: 0.45  took: 0.02s\n",
            "Epoch 8 of 200, 25% \t train_loss: 0.38  took: 0.01s\n",
            "Epoch 8 of 200, 34% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 8 of 200, 42% \t train_loss: 0.36  took: 0.02s\n",
            "Epoch 8 of 200, 51% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 8 of 200, 59% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 8 of 200, 68% \t train_loss: 0.41  took: 0.01s\n",
            "Epoch 8 of 200, 76% \t train_loss: 0.31  took: 0.02s\n",
            "Epoch 8 of 200, 85% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 8 of 200, 93% \t train_loss: 0.44  took: 0.02s\n",
            "val_loss = 0.37\n",
            "Snapshot saved at epoch 8.\n",
            "Epoch 9 of 200, 8% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 9 of 200, 17% \t train_loss: 0.44  took: 0.01s\n",
            "Epoch 9 of 200, 25% \t train_loss: 0.36  took: 0.01s\n",
            "Epoch 9 of 200, 34% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 9 of 200, 42% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 9 of 200, 51% \t train_loss: 0.39  took: 0.02s\n",
            "Epoch 9 of 200, 59% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 9 of 200, 68% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 9 of 200, 76% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 9 of 200, 85% \t train_loss: 0.26  took: 0.02s\n",
            "Epoch 9 of 200, 93% \t train_loss: 0.42  took: 0.01s\n",
            "val_loss = 0.36\n",
            "Snapshot saved at epoch 9.\n",
            "Epoch 10 of 200, 8% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 10 of 200, 17% \t train_loss: 0.42  took: 0.02s\n",
            "Epoch 10 of 200, 25% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 10 of 200, 34% \t train_loss: 0.31  took: 0.02s\n",
            "Epoch 10 of 200, 42% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 10 of 200, 51% \t train_loss: 0.38  took: 0.01s\n",
            "Epoch 10 of 200, 59% \t train_loss: 0.36  took: 0.01s\n",
            "Epoch 10 of 200, 68% \t train_loss: 0.39  took: 0.02s\n",
            "Epoch 10 of 200, 76% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 10 of 200, 85% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 10 of 200, 93% \t train_loss: 0.41  took: 0.02s\n",
            "val_loss = 0.36\n",
            "Snapshot saved at epoch 10.\n",
            "Epoch 11 of 200, 8% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 11 of 200, 17% \t train_loss: 0.41  took: 0.01s\n",
            "Epoch 11 of 200, 25% \t train_loss: 0.33  took: 0.02s\n",
            "Epoch 11 of 200, 34% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 11 of 200, 42% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 11 of 200, 51% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 11 of 200, 59% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 11 of 200, 68% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 11 of 200, 76% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 11 of 200, 85% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 11 of 200, 93% \t train_loss: 0.40  took: 0.01s\n",
            "val_loss = 0.35\n",
            "Snapshot saved at epoch 11.\n",
            "Epoch 12 of 200, 8% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 12 of 200, 17% \t train_loss: 0.40  took: 0.01s\n",
            "Epoch 12 of 200, 25% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 12 of 200, 34% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 12 of 200, 42% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 12 of 200, 51% \t train_loss: 0.36  took: 0.01s\n",
            "Epoch 12 of 200, 59% \t train_loss: 0.34  took: 0.02s\n",
            "Epoch 12 of 200, 68% \t train_loss: 0.36  took: 0.02s\n",
            "Epoch 12 of 200, 76% \t train_loss: 0.26  took: 0.02s\n",
            "Epoch 12 of 200, 85% \t train_loss: 0.24  took: 0.02s\n",
            "Epoch 12 of 200, 93% \t train_loss: 0.38  took: 0.02s\n",
            "val_loss = 0.35\n",
            "Snapshot saved at epoch 12.\n",
            "Epoch 13 of 200, 8% \t train_loss: 0.27  took: 0.02s\n",
            "Epoch 13 of 200, 17% \t train_loss: 0.39  took: 0.01s\n",
            "Epoch 13 of 200, 25% \t train_loss: 0.31  took: 0.02s\n",
            "Epoch 13 of 200, 34% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 13 of 200, 42% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 13 of 200, 51% \t train_loss: 0.35  took: 0.02s\n",
            "Epoch 13 of 200, 59% \t train_loss: 0.32  took: 0.02s\n",
            "Epoch 13 of 200, 68% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 13 of 200, 76% \t train_loss: 0.25  took: 0.02s\n",
            "Epoch 13 of 200, 85% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 13 of 200, 93% \t train_loss: 0.37  took: 0.01s\n",
            "val_loss = 0.34\n",
            "Snapshot saved at epoch 13.\n",
            "Epoch 14 of 200, 8% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 14 of 200, 17% \t train_loss: 0.38  took: 0.01s\n",
            "Epoch 14 of 200, 25% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 14 of 200, 34% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 14 of 200, 42% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 14 of 200, 51% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 14 of 200, 59% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 14 of 200, 68% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 14 of 200, 76% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 14 of 200, 85% \t train_loss: 0.23  took: 0.02s\n",
            "Epoch 14 of 200, 93% \t train_loss: 0.36  took: 0.01s\n",
            "val_loss = 0.34\n",
            "Snapshot saved at epoch 14.\n",
            "Epoch 15 of 200, 8% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 15 of 200, 17% \t train_loss: 0.37  took: 0.01s\n",
            "Epoch 15 of 200, 25% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 15 of 200, 34% \t train_loss: 0.26  took: 0.02s\n",
            "Epoch 15 of 200, 42% \t train_loss: 0.26  took: 0.02s\n",
            "Epoch 15 of 200, 51% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 15 of 200, 59% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 15 of 200, 68% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 15 of 200, 76% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 15 of 200, 85% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 15 of 200, 93% \t train_loss: 0.35  took: 0.02s\n",
            "val_loss = 0.33\n",
            "Snapshot saved at epoch 15.\n",
            "Epoch 16 of 200, 8% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 16 of 200, 17% \t train_loss: 0.36  took: 0.01s\n",
            "Epoch 16 of 200, 25% \t train_loss: 0.29  took: 0.02s\n",
            "Epoch 16 of 200, 34% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 16 of 200, 42% \t train_loss: 0.25  took: 0.02s\n",
            "Epoch 16 of 200, 51% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 16 of 200, 59% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 16 of 200, 68% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 16 of 200, 76% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 16 of 200, 85% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 16 of 200, 93% \t train_loss: 0.34  took: 0.01s\n",
            "val_loss = 0.33\n",
            "Snapshot saved at epoch 16.\n",
            "Epoch 17 of 200, 8% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 17 of 200, 17% \t train_loss: 0.35  took: 0.01s\n",
            "Epoch 17 of 200, 25% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 17 of 200, 34% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 17 of 200, 42% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 17 of 200, 51% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 17 of 200, 59% \t train_loss: 0.28  took: 0.02s\n",
            "Epoch 17 of 200, 68% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 17 of 200, 76% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 17 of 200, 85% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 17 of 200, 93% \t train_loss: 0.33  took: 0.01s\n",
            "val_loss = 0.32\n",
            "Snapshot saved at epoch 17.\n",
            "Epoch 18 of 200, 8% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 18 of 200, 17% \t train_loss: 0.34  took: 0.01s\n",
            "Epoch 18 of 200, 25% \t train_loss: 0.28  took: 0.02s\n",
            "Epoch 18 of 200, 34% \t train_loss: 0.24  took: 0.02s\n",
            "Epoch 18 of 200, 42% \t train_loss: 0.23  took: 0.02s\n",
            "Epoch 18 of 200, 51% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 18 of 200, 59% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 18 of 200, 68% \t train_loss: 0.31  took: 0.01s\n",
            "Epoch 18 of 200, 76% \t train_loss: 0.20  took: 0.02s\n",
            "Epoch 18 of 200, 85% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 18 of 200, 93% \t train_loss: 0.32  took: 0.01s\n",
            "val_loss = 0.32\n",
            "Snapshot saved at epoch 18.\n",
            "Epoch 19 of 200, 8% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 19 of 200, 17% \t train_loss: 0.33  took: 0.01s\n",
            "Epoch 19 of 200, 25% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 19 of 200, 34% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 19 of 200, 42% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 19 of 200, 51% \t train_loss: 0.31  took: 0.02s\n",
            "Epoch 19 of 200, 59% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 19 of 200, 68% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 19 of 200, 76% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 19 of 200, 85% \t train_loss: 0.20  took: 0.02s\n",
            "Epoch 19 of 200, 93% \t train_loss: 0.31  took: 0.02s\n",
            "val_loss = 0.31\n",
            "Snapshot saved at epoch 19.\n",
            "Epoch 20 of 200, 8% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 20 of 200, 17% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 20 of 200, 25% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 20 of 200, 34% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 20 of 200, 42% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 20 of 200, 51% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 20 of 200, 59% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 20 of 200, 68% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 20 of 200, 76% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 20 of 200, 85% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 20 of 200, 93% \t train_loss: 0.30  took: 0.02s\n",
            "val_loss = 0.31\n",
            "Snapshot saved at epoch 20.\n",
            "Epoch 21 of 200, 8% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 21 of 200, 17% \t train_loss: 0.32  took: 0.01s\n",
            "Epoch 21 of 200, 25% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 21 of 200, 34% \t train_loss: 0.22  took: 0.02s\n",
            "Epoch 21 of 200, 42% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 21 of 200, 51% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 21 of 200, 59% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 21 of 200, 68% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 21 of 200, 76% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 21 of 200, 85% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 21 of 200, 93% \t train_loss: 0.29  took: 0.01s\n",
            "val_loss = 0.30\n",
            "Snapshot saved at epoch 21.\n",
            "Epoch 22 of 200, 8% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 22 of 200, 17% \t train_loss: 0.31  took: 0.02s\n",
            "Epoch 22 of 200, 25% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 22 of 200, 34% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 22 of 200, 42% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 22 of 200, 51% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 22 of 200, 59% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 22 of 200, 68% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 22 of 200, 76% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 22 of 200, 85% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 22 of 200, 93% \t train_loss: 0.28  took: 0.02s\n",
            "val_loss = 0.30\n",
            "Snapshot saved at epoch 22.\n",
            "Epoch 23 of 200, 8% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 23 of 200, 17% \t train_loss: 0.30  took: 0.01s\n",
            "Epoch 23 of 200, 25% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 23 of 200, 34% \t train_loss: 0.21  took: 0.02s\n",
            "Epoch 23 of 200, 42% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 23 of 200, 51% \t train_loss: 0.28  took: 0.02s\n",
            "Epoch 23 of 200, 59% \t train_loss: 0.23  took: 0.02s\n",
            "Epoch 23 of 200, 68% \t train_loss: 0.26  took: 0.03s\n",
            "Epoch 23 of 200, 76% \t train_loss: 0.18  took: 0.03s\n",
            "Epoch 23 of 200, 85% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 23 of 200, 93% \t train_loss: 0.27  took: 0.01s\n",
            "val_loss = 0.29\n",
            "Snapshot saved at epoch 23.\n",
            "Epoch 24 of 200, 8% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 24 of 200, 17% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 24 of 200, 25% \t train_loss: 0.24  took: 0.02s\n",
            "Epoch 24 of 200, 34% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 24 of 200, 42% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 24 of 200, 51% \t train_loss: 0.28  took: 0.02s\n",
            "Epoch 24 of 200, 59% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 24 of 200, 68% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 24 of 200, 76% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 24 of 200, 85% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 24 of 200, 93% \t train_loss: 0.26  took: 0.01s\n",
            "val_loss = 0.28\n",
            "Snapshot saved at epoch 24.\n",
            "Epoch 25 of 200, 8% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 25 of 200, 17% \t train_loss: 0.29  took: 0.01s\n",
            "Epoch 25 of 200, 25% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 25 of 200, 34% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 25 of 200, 42% \t train_loss: 0.18  took: 0.02s\n",
            "Epoch 25 of 200, 51% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 25 of 200, 59% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 25 of 200, 68% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 25 of 200, 76% \t train_loss: 0.17  took: 0.02s\n",
            "Epoch 25 of 200, 85% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 25 of 200, 93% \t train_loss: 0.26  took: 0.01s\n",
            "val_loss = 0.28\n",
            "Snapshot saved at epoch 25.\n",
            "Epoch 26 of 200, 8% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 26 of 200, 17% \t train_loss: 0.28  took: 0.01s\n",
            "Epoch 26 of 200, 25% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 26 of 200, 34% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 26 of 200, 42% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 26 of 200, 51% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 26 of 200, 59% \t train_loss: 0.20  took: 0.02s\n",
            "Epoch 26 of 200, 68% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 26 of 200, 76% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 26 of 200, 85% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 26 of 200, 93% \t train_loss: 0.25  took: 0.01s\n",
            "val_loss = 0.27\n",
            "Snapshot saved at epoch 26.\n",
            "Epoch 27 of 200, 8% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 27 of 200, 17% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 27 of 200, 25% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 27 of 200, 34% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 27 of 200, 42% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 27 of 200, 51% \t train_loss: 0.26  took: 0.01s\n",
            "Epoch 27 of 200, 59% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 27 of 200, 68% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 27 of 200, 76% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 27 of 200, 85% \t train_loss: 0.17  took: 0.02s\n",
            "Epoch 27 of 200, 93% \t train_loss: 0.24  took: 0.02s\n",
            "val_loss = 0.27\n",
            "Snapshot saved at epoch 27.\n",
            "Epoch 28 of 200, 8% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 28 of 200, 17% \t train_loss: 0.27  took: 0.01s\n",
            "Epoch 28 of 200, 25% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 28 of 200, 34% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 28 of 200, 42% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 28 of 200, 51% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 28 of 200, 59% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 28 of 200, 68% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 28 of 200, 76% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 28 of 200, 85% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 28 of 200, 93% \t train_loss: 0.23  took: 0.01s\n",
            "val_loss = 0.26\n",
            "Snapshot saved at epoch 28.\n",
            "Epoch 29 of 200, 8% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 29 of 200, 17% \t train_loss: 0.26  took: 0.02s\n",
            "Epoch 29 of 200, 25% \t train_loss: 0.21  took: 0.02s\n",
            "Epoch 29 of 200, 34% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 29 of 200, 42% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 29 of 200, 51% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 29 of 200, 59% \t train_loss: 0.18  took: 0.02s\n",
            "Epoch 29 of 200, 68% \t train_loss: 0.21  took: 0.02s\n",
            "Epoch 29 of 200, 76% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 29 of 200, 85% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 29 of 200, 93% \t train_loss: 0.22  took: 0.01s\n",
            "val_loss = 0.26\n",
            "Snapshot saved at epoch 29.\n",
            "Epoch 30 of 200, 8% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 30 of 200, 17% \t train_loss: 0.25  took: 0.02s\n",
            "Epoch 30 of 200, 25% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 30 of 200, 34% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 30 of 200, 42% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 30 of 200, 51% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 30 of 200, 59% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 30 of 200, 68% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 30 of 200, 76% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 30 of 200, 85% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 30 of 200, 93% \t train_loss: 0.22  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 30.\n",
            "Epoch 31 of 200, 8% \t train_loss: 0.16  took: 0.02s\n",
            "Epoch 31 of 200, 17% \t train_loss: 0.25  took: 0.01s\n",
            "Epoch 31 of 200, 25% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 31 of 200, 34% \t train_loss: 0.17  took: 0.02s\n",
            "Epoch 31 of 200, 42% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 31 of 200, 51% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 31 of 200, 59% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 31 of 200, 68% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 31 of 200, 76% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 31 of 200, 85% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 31 of 200, 93% \t train_loss: 0.21  took: 0.01s\n",
            "val_loss = 0.25\n",
            "Snapshot saved at epoch 31.\n",
            "Epoch 32 of 200, 8% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 32 of 200, 17% \t train_loss: 0.24  took: 0.01s\n",
            "Epoch 32 of 200, 25% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 32 of 200, 34% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 32 of 200, 42% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 32 of 200, 51% \t train_loss: 0.23  took: 0.02s\n",
            "Epoch 32 of 200, 59% \t train_loss: 0.16  took: 0.02s\n",
            "Epoch 32 of 200, 68% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 32 of 200, 76% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 32 of 200, 85% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 32 of 200, 93% \t train_loss: 0.20  took: 0.01s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 32.\n",
            "Epoch 33 of 200, 8% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 33 of 200, 17% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 33 of 200, 25% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 33 of 200, 34% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 33 of 200, 42% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 33 of 200, 51% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 33 of 200, 59% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 33 of 200, 68% \t train_loss: 0.18  took: 0.02s\n",
            "Epoch 33 of 200, 76% \t train_loss: 0.13  took: 0.02s\n",
            "Epoch 33 of 200, 85% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 33 of 200, 93% \t train_loss: 0.19  took: 0.02s\n",
            "val_loss = 0.24\n",
            "Snapshot saved at epoch 33.\n",
            "Epoch 34 of 200, 8% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 34 of 200, 17% \t train_loss: 0.23  took: 0.01s\n",
            "Epoch 34 of 200, 25% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 34 of 200, 34% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 34 of 200, 42% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 34 of 200, 51% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 34 of 200, 59% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 34 of 200, 68% \t train_loss: 0.18  took: 0.02s\n",
            "Epoch 34 of 200, 76% \t train_loss: 0.12  took: 0.02s\n",
            "Epoch 34 of 200, 85% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 34 of 200, 93% \t train_loss: 0.19  took: 0.01s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 34.\n",
            "Epoch 35 of 200, 8% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 35 of 200, 17% \t train_loss: 0.22  took: 0.01s\n",
            "Epoch 35 of 200, 25% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 35 of 200, 34% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 35 of 200, 42% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 35 of 200, 51% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 35 of 200, 59% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 35 of 200, 68% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 35 of 200, 76% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 35 of 200, 85% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 35 of 200, 93% \t train_loss: 0.18  took: 0.02s\n",
            "val_loss = 0.23\n",
            "Snapshot saved at epoch 35.\n",
            "Epoch 36 of 200, 8% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 36 of 200, 17% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 36 of 200, 25% \t train_loss: 0.17  took: 0.02s\n",
            "Epoch 36 of 200, 34% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 36 of 200, 42% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 36 of 200, 51% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 36 of 200, 59% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 36 of 200, 68% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 36 of 200, 76% \t train_loss: 0.11  took: 0.02s\n",
            "Epoch 36 of 200, 85% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 36 of 200, 93% \t train_loss: 0.17  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 36.\n",
            "Epoch 37 of 200, 8% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 37 of 200, 17% \t train_loss: 0.21  took: 0.01s\n",
            "Epoch 37 of 200, 25% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 37 of 200, 34% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 37 of 200, 42% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 37 of 200, 51% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 37 of 200, 59% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 37 of 200, 68% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 37 of 200, 76% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 37 of 200, 85% \t train_loss: 0.12  took: 0.02s\n",
            "Epoch 37 of 200, 93% \t train_loss: 0.17  took: 0.01s\n",
            "val_loss = 0.22\n",
            "Snapshot saved at epoch 37.\n",
            "Epoch 38 of 200, 8% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 38 of 200, 17% \t train_loss: 0.20  took: 0.02s\n",
            "Epoch 38 of 200, 25% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 38 of 200, 34% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 38 of 200, 42% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 38 of 200, 51% \t train_loss: 0.19  took: 0.01s\n",
            "Epoch 38 of 200, 59% \t train_loss: 0.13  took: 0.02s\n",
            "Epoch 38 of 200, 68% \t train_loss: 0.15  took: 0.02s\n",
            "Epoch 38 of 200, 76% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 38 of 200, 85% \t train_loss: 0.12  took: 0.02s\n",
            "Epoch 38 of 200, 93% \t train_loss: 0.16  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 38.\n",
            "Epoch 39 of 200, 8% \t train_loss: 0.12  took: 0.02s\n",
            "Epoch 39 of 200, 17% \t train_loss: 0.20  took: 0.01s\n",
            "Epoch 39 of 200, 25% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 39 of 200, 34% \t train_loss: 0.13  took: 0.02s\n",
            "Epoch 39 of 200, 42% \t train_loss: 0.12  took: 0.02s\n",
            "Epoch 39 of 200, 51% \t train_loss: 0.18  took: 0.02s\n",
            "Epoch 39 of 200, 59% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 39 of 200, 68% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 39 of 200, 76% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 39 of 200, 85% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 39 of 200, 93% \t train_loss: 0.16  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 39.\n",
            "Epoch 40 of 200, 8% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 40 of 200, 17% \t train_loss: 0.19  took: 0.02s\n",
            "Epoch 40 of 200, 25% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 40 of 200, 34% \t train_loss: 0.13  took: 0.02s\n",
            "Epoch 40 of 200, 42% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 40 of 200, 51% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 40 of 200, 59% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 40 of 200, 68% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 40 of 200, 76% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 40 of 200, 85% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 40 of 200, 93% \t train_loss: 0.15  took: 0.01s\n",
            "val_loss = 0.21\n",
            "Snapshot saved at epoch 40.\n",
            "Epoch 41 of 200, 8% \t train_loss: 0.11  took: 0.02s\n",
            "Epoch 41 of 200, 17% \t train_loss: 0.18  took: 0.01s\n",
            "Epoch 41 of 200, 25% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 41 of 200, 34% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 41 of 200, 42% \t train_loss: 0.11  took: 0.02s\n",
            "Epoch 41 of 200, 51% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 41 of 200, 59% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 41 of 200, 68% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 41 of 200, 76% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 41 of 200, 85% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 41 of 200, 93% \t train_loss: 0.15  took: 0.01s\n",
            "val_loss = 0.20\n",
            "Snapshot saved at epoch 41.\n",
            "Epoch 42 of 200, 8% \t train_loss: 0.11  took: 0.03s\n",
            "Epoch 42 of 200, 17% \t train_loss: 0.18  took: 0.06s\n",
            "Epoch 42 of 200, 25% \t train_loss: 0.13  took: 0.04s\n",
            "Epoch 42 of 200, 34% \t train_loss: 0.12  took: 0.03s\n",
            "Epoch 42 of 200, 42% \t train_loss: 0.11  took: 0.02s\n",
            "Epoch 42 of 200, 51% \t train_loss: 0.17  took: 0.04s\n",
            "Epoch 42 of 200, 59% \t train_loss: 0.11  took: 0.04s\n",
            "Epoch 42 of 200, 68% \t train_loss: 0.13  took: 0.05s\n",
            "Epoch 42 of 200, 76% \t train_loss: 0.09  took: 0.03s\n",
            "Epoch 42 of 200, 85% \t train_loss: 0.10  took: 0.02s\n",
            "Epoch 42 of 200, 93% \t train_loss: 0.14  took: 0.02s\n",
            "val_loss = 0.20\n",
            "Snapshot saved at epoch 42.\n",
            "Epoch 43 of 200, 8% \t train_loss: 0.10  took: 0.04s\n",
            "Epoch 43 of 200, 17% \t train_loss: 0.17  took: 0.04s\n",
            "Epoch 43 of 200, 25% \t train_loss: 0.13  took: 0.04s\n",
            "Epoch 43 of 200, 34% \t train_loss: 0.12  took: 0.02s\n",
            "Epoch 43 of 200, 42% \t train_loss: 0.10  took: 0.02s\n",
            "Epoch 43 of 200, 51% \t train_loss: 0.16  took: 0.03s\n",
            "Epoch 43 of 200, 59% \t train_loss: 0.11  took: 0.02s\n",
            "Epoch 43 of 200, 68% \t train_loss: 0.12  took: 0.04s\n",
            "Epoch 43 of 200, 76% \t train_loss: 0.09  took: 0.03s\n",
            "Epoch 43 of 200, 85% \t train_loss: 0.10  took: 0.02s\n",
            "Epoch 43 of 200, 93% \t train_loss: 0.14  took: 0.02s\n",
            "val_loss = 0.19\n",
            "Snapshot saved at epoch 43.\n",
            "Epoch 44 of 200, 8% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 44 of 200, 17% \t train_loss: 0.17  took: 0.01s\n",
            "Epoch 44 of 200, 25% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 44 of 200, 34% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 44 of 200, 42% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 44 of 200, 51% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 44 of 200, 59% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 44 of 200, 68% \t train_loss: 0.12  took: 0.02s\n",
            "Epoch 44 of 200, 76% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 44 of 200, 85% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 44 of 200, 93% \t train_loss: 0.13  took: 0.01s\n",
            "val_loss = 0.19\n",
            "Snapshot saved at epoch 44.\n",
            "Epoch 45 of 200, 8% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 45 of 200, 17% \t train_loss: 0.16  took: 0.01s\n",
            "Epoch 45 of 200, 25% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 45 of 200, 34% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 45 of 200, 42% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 45 of 200, 51% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 45 of 200, 59% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 45 of 200, 68% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 45 of 200, 76% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 45 of 200, 85% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 45 of 200, 93% \t train_loss: 0.13  took: 0.02s\n",
            "val_loss = 0.19\n",
            "Snapshot saved at epoch 45.\n",
            "Epoch 46 of 200, 8% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 46 of 200, 17% \t train_loss: 0.16  took: 0.02s\n",
            "Epoch 46 of 200, 25% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 46 of 200, 34% \t train_loss: 0.11  took: 0.02s\n",
            "Epoch 46 of 200, 42% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 46 of 200, 51% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 46 of 200, 59% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 46 of 200, 68% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 46 of 200, 76% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 46 of 200, 85% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 46 of 200, 93% \t train_loss: 0.12  took: 0.02s\n",
            "val_loss = 0.19\n",
            "Snapshot saved at epoch 46.\n",
            "Epoch 47 of 200, 8% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 47 of 200, 17% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 47 of 200, 25% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 47 of 200, 34% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 47 of 200, 42% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 47 of 200, 51% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 47 of 200, 59% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 47 of 200, 68% \t train_loss: 0.10  took: 0.02s\n",
            "Epoch 47 of 200, 76% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 47 of 200, 85% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 47 of 200, 93% \t train_loss: 0.12  took: 0.02s\n",
            "val_loss = 0.18\n",
            "Snapshot saved at epoch 47.\n",
            "Epoch 48 of 200, 8% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 48 of 200, 17% \t train_loss: 0.15  took: 0.01s\n",
            "Epoch 48 of 200, 25% \t train_loss: 0.11  took: 0.02s\n",
            "Epoch 48 of 200, 34% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 48 of 200, 42% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 48 of 200, 51% \t train_loss: 0.14  took: 0.01s\n",
            "Epoch 48 of 200, 59% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 48 of 200, 68% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 48 of 200, 76% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 48 of 200, 85% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 48 of 200, 93% \t train_loss: 0.12  took: 0.02s\n",
            "val_loss = 0.18\n",
            "Snapshot saved at epoch 48.\n",
            "Epoch 49 of 200, 8% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 49 of 200, 17% \t train_loss: 0.15  took: 0.02s\n",
            "Epoch 49 of 200, 25% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 49 of 200, 34% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 49 of 200, 42% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 49 of 200, 51% \t train_loss: 0.13  took: 0.02s\n",
            "Epoch 49 of 200, 59% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 49 of 200, 68% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 49 of 200, 76% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 49 of 200, 85% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 49 of 200, 93% \t train_loss: 0.11  took: 0.01s\n",
            "val_loss = 0.18\n",
            "Snapshot saved at epoch 49.\n",
            "Epoch 50 of 200, 8% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 50 of 200, 17% \t train_loss: 0.14  took: 0.02s\n",
            "Epoch 50 of 200, 25% \t train_loss: 0.10  took: 0.02s\n",
            "Epoch 50 of 200, 34% \t train_loss: 0.10  took: 0.02s\n",
            "Epoch 50 of 200, 42% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 50 of 200, 51% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 50 of 200, 59% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 50 of 200, 68% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 50 of 200, 76% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 50 of 200, 85% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 50 of 200, 93% \t train_loss: 0.11  took: 0.02s\n",
            "val_loss = 0.17\n",
            "Snapshot saved at epoch 50.\n",
            "Epoch 51 of 200, 8% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 51 of 200, 17% \t train_loss: 0.14  took: 0.02s\n",
            "Epoch 51 of 200, 25% \t train_loss: 0.10  took: 0.02s\n",
            "Epoch 51 of 200, 34% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 51 of 200, 42% \t train_loss: 0.08  took: 0.03s\n",
            "Epoch 51 of 200, 51% \t train_loss: 0.12  took: 0.02s\n",
            "Epoch 51 of 200, 59% \t train_loss: 0.09  took: 0.03s\n",
            "Epoch 51 of 200, 68% \t train_loss: 0.09  took: 0.03s\n",
            "Epoch 51 of 200, 76% \t train_loss: 0.06  took: 0.04s\n",
            "Epoch 51 of 200, 85% \t train_loss: 0.07  took: 0.03s\n",
            "Epoch 51 of 200, 93% \t train_loss: 0.11  took: 0.02s\n",
            "val_loss = 0.17\n",
            "Snapshot saved at epoch 51.\n",
            "Epoch 52 of 200, 8% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 52 of 200, 17% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 52 of 200, 25% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 52 of 200, 34% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 52 of 200, 42% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 52 of 200, 51% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 52 of 200, 59% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 52 of 200, 68% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 52 of 200, 76% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 52 of 200, 85% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 52 of 200, 93% \t train_loss: 0.10  took: 0.01s\n",
            "val_loss = 0.17\n",
            "Snapshot saved at epoch 52.\n",
            "Epoch 53 of 200, 8% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 53 of 200, 17% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 53 of 200, 25% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 53 of 200, 34% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 53 of 200, 42% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 53 of 200, 51% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 53 of 200, 59% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 53 of 200, 68% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 53 of 200, 76% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 53 of 200, 85% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 53 of 200, 93% \t train_loss: 0.10  took: 0.01s\n",
            "val_loss = 0.17\n",
            "Snapshot saved at epoch 53.\n",
            "Epoch 54 of 200, 8% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 54 of 200, 17% \t train_loss: 0.13  took: 0.01s\n",
            "Epoch 54 of 200, 25% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 54 of 200, 34% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 54 of 200, 42% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 54 of 200, 51% \t train_loss: 0.11  took: 0.02s\n",
            "Epoch 54 of 200, 59% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 54 of 200, 68% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 54 of 200, 76% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 54 of 200, 85% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 54 of 200, 93% \t train_loss: 0.10  took: 0.02s\n",
            "val_loss = 0.17\n",
            "Snapshot saved at epoch 54.\n",
            "Epoch 55 of 200, 8% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 55 of 200, 17% \t train_loss: 0.12  took: 0.02s\n",
            "Epoch 55 of 200, 25% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 55 of 200, 34% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 55 of 200, 42% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 55 of 200, 51% \t train_loss: 0.11  took: 0.02s\n",
            "Epoch 55 of 200, 59% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 55 of 200, 68% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 55 of 200, 76% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 55 of 200, 85% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 55 of 200, 93% \t train_loss: 0.09  took: 0.01s\n",
            "val_loss = 0.16\n",
            "Snapshot saved at epoch 55.\n",
            "Epoch 56 of 200, 8% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 56 of 200, 17% \t train_loss: 0.12  took: 0.01s\n",
            "Epoch 56 of 200, 25% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 56 of 200, 34% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 56 of 200, 42% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 56 of 200, 51% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 56 of 200, 59% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 56 of 200, 68% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 56 of 200, 76% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 56 of 200, 85% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 56 of 200, 93% \t train_loss: 0.09  took: 0.01s\n",
            "val_loss = 0.16\n",
            "Snapshot saved at epoch 56.\n",
            "Epoch 57 of 200, 8% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 57 of 200, 17% \t train_loss: 0.11  took: 0.02s\n",
            "Epoch 57 of 200, 25% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 57 of 200, 34% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 57 of 200, 42% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 57 of 200, 51% \t train_loss: 0.10  took: 0.02s\n",
            "Epoch 57 of 200, 59% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 57 of 200, 68% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 57 of 200, 76% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 57 of 200, 85% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 57 of 200, 93% \t train_loss: 0.09  took: 0.01s\n",
            "val_loss = 0.16\n",
            "Snapshot saved at epoch 57.\n",
            "Epoch 58 of 200, 8% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 58 of 200, 17% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 58 of 200, 25% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 58 of 200, 34% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 58 of 200, 42% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 58 of 200, 51% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 58 of 200, 59% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 58 of 200, 68% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 58 of 200, 76% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 58 of 200, 85% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 58 of 200, 93% \t train_loss: 0.09  took: 0.01s\n",
            "val_loss = 0.16\n",
            "Snapshot saved at epoch 58.\n",
            "Epoch 59 of 200, 8% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 59 of 200, 17% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 59 of 200, 25% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 59 of 200, 34% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 59 of 200, 42% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 59 of 200, 51% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 59 of 200, 59% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 59 of 200, 68% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 59 of 200, 76% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 59 of 200, 85% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 59 of 200, 93% \t train_loss: 0.08  took: 0.01s\n",
            "val_loss = 0.16\n",
            "Snapshot saved at epoch 59.\n",
            "Epoch 60 of 200, 8% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 60 of 200, 17% \t train_loss: 0.11  took: 0.01s\n",
            "Epoch 60 of 200, 25% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 60 of 200, 34% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 60 of 200, 42% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 60 of 200, 51% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 60 of 200, 59% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 60 of 200, 68% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 60 of 200, 76% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 60 of 200, 85% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 60 of 200, 93% \t train_loss: 0.08  took: 0.01s\n",
            "val_loss = 0.15\n",
            "Snapshot saved at epoch 60.\n",
            "Epoch 61 of 200, 8% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 61 of 200, 17% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 61 of 200, 25% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 61 of 200, 34% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 61 of 200, 42% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 61 of 200, 51% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 61 of 200, 59% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 61 of 200, 68% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 61 of 200, 76% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 61 of 200, 85% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 61 of 200, 93% \t train_loss: 0.08  took: 0.01s\n",
            "val_loss = 0.15\n",
            "Snapshot saved at epoch 61.\n",
            "Epoch 62 of 200, 8% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 62 of 200, 17% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 62 of 200, 25% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 62 of 200, 34% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 62 of 200, 42% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 62 of 200, 51% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 62 of 200, 59% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 62 of 200, 68% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 62 of 200, 76% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 62 of 200, 85% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 62 of 200, 93% \t train_loss: 0.08  took: 0.01s\n",
            "val_loss = 0.15\n",
            "Snapshot saved at epoch 62.\n",
            "Epoch 63 of 200, 8% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 63 of 200, 17% \t train_loss: 0.10  took: 0.02s\n",
            "Epoch 63 of 200, 25% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 63 of 200, 34% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 63 of 200, 42% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 63 of 200, 51% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 63 of 200, 59% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 63 of 200, 68% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 63 of 200, 76% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 63 of 200, 85% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 63 of 200, 93% \t train_loss: 0.07  took: 0.01s\n",
            "val_loss = 0.15\n",
            "Snapshot saved at epoch 63.\n",
            "Epoch 64 of 200, 8% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 64 of 200, 17% \t train_loss: 0.10  took: 0.01s\n",
            "Epoch 64 of 200, 25% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 64 of 200, 34% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 64 of 200, 42% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 64 of 200, 51% \t train_loss: 0.08  took: 0.01s\n",
            "Epoch 64 of 200, 59% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 64 of 200, 68% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 64 of 200, 76% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 64 of 200, 85% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 64 of 200, 93% \t train_loss: 0.07  took: 0.02s\n",
            "val_loss = 0.15\n",
            "Snapshot saved at epoch 64.\n",
            "Epoch 65 of 200, 8% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 65 of 200, 17% \t train_loss: 0.09  took: 0.01s\n",
            "Epoch 65 of 200, 25% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 65 of 200, 34% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 65 of 200, 42% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 65 of 200, 51% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 65 of 200, 59% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 65 of 200, 68% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 65 of 200, 76% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 65 of 200, 85% \t train_loss: 0.05  took: 0.03s\n",
            "Epoch 65 of 200, 93% \t train_loss: 0.07  took: 0.02s\n",
            "val_loss = 0.15\n",
            "Snapshot saved at epoch 65.\n",
            "Epoch 66 of 200, 8% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 66 of 200, 17% \t train_loss: 0.09  took: 0.03s\n",
            "Epoch 66 of 200, 25% \t train_loss: 0.06  took: 0.03s\n",
            "Epoch 66 of 200, 34% \t train_loss: 0.06  took: 0.03s\n",
            "Epoch 66 of 200, 42% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 66 of 200, 51% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 66 of 200, 59% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 66 of 200, 68% \t train_loss: 0.05  took: 0.03s\n",
            "Epoch 66 of 200, 76% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 66 of 200, 85% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 66 of 200, 93% \t train_loss: 0.07  took: 0.02s\n",
            "val_loss = 0.15\n",
            "Snapshot saved at epoch 66.\n",
            "Epoch 67 of 200, 8% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 67 of 200, 17% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 67 of 200, 25% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 67 of 200, 34% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 67 of 200, 42% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 67 of 200, 51% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 67 of 200, 59% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 67 of 200, 68% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 67 of 200, 76% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 67 of 200, 85% \t train_loss: 0.05  took: 0.06s\n",
            "Epoch 67 of 200, 93% \t train_loss: 0.07  took: 0.04s\n",
            "val_loss = 0.15\n",
            "Snapshot saved at epoch 67.\n",
            "Epoch 68 of 200, 8% \t train_loss: 0.05  took: 0.04s\n",
            "Epoch 68 of 200, 17% \t train_loss: 0.09  took: 0.02s\n",
            "Epoch 68 of 200, 25% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 68 of 200, 34% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 68 of 200, 42% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 68 of 200, 51% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 68 of 200, 59% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 68 of 200, 68% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 68 of 200, 76% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 68 of 200, 85% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 68 of 200, 93% \t train_loss: 0.07  took: 0.03s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 68.\n",
            "Epoch 69 of 200, 8% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 69 of 200, 17% \t train_loss: 0.08  took: 0.03s\n",
            "Epoch 69 of 200, 25% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 69 of 200, 34% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 69 of 200, 42% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 69 of 200, 51% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 69 of 200, 59% \t train_loss: 0.05  took: 0.03s\n",
            "Epoch 69 of 200, 68% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 69 of 200, 76% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 69 of 200, 85% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 69 of 200, 93% \t train_loss: 0.06  took: 0.05s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 69.\n",
            "Epoch 70 of 200, 8% \t train_loss: 0.05  took: 0.05s\n",
            "Epoch 70 of 200, 17% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 70 of 200, 25% \t train_loss: 0.05  took: 0.03s\n",
            "Epoch 70 of 200, 34% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 70 of 200, 42% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 70 of 200, 51% \t train_loss: 0.07  took: 0.03s\n",
            "Epoch 70 of 200, 59% \t train_loss: 0.05  took: 0.03s\n",
            "Epoch 70 of 200, 68% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 70 of 200, 76% \t train_loss: 0.04  took: 0.04s\n",
            "Epoch 70 of 200, 85% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 70 of 200, 93% \t train_loss: 0.06  took: 0.03s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 70.\n",
            "Epoch 71 of 200, 8% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 71 of 200, 17% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 71 of 200, 25% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 71 of 200, 34% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 71 of 200, 42% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 71 of 200, 51% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 71 of 200, 59% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 71 of 200, 68% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 71 of 200, 76% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 71 of 200, 85% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 71 of 200, 93% \t train_loss: 0.06  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 71.\n",
            "Epoch 72 of 200, 8% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 72 of 200, 17% \t train_loss: 0.08  took: 0.03s\n",
            "Epoch 72 of 200, 25% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 72 of 200, 34% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 72 of 200, 42% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 72 of 200, 51% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 72 of 200, 59% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 72 of 200, 68% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 72 of 200, 76% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 72 of 200, 85% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 72 of 200, 93% \t train_loss: 0.06  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 72.\n",
            "Epoch 73 of 200, 8% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 73 of 200, 17% \t train_loss: 0.08  took: 0.02s\n",
            "Epoch 73 of 200, 25% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 73 of 200, 34% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 73 of 200, 42% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 73 of 200, 51% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 73 of 200, 59% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 73 of 200, 68% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 73 of 200, 76% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 73 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 73 of 200, 93% \t train_loss: 0.06  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 73.\n",
            "Epoch 74 of 200, 8% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 74 of 200, 17% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 74 of 200, 25% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 74 of 200, 34% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 74 of 200, 42% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 74 of 200, 51% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 74 of 200, 59% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 74 of 200, 68% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 74 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 74 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 74 of 200, 93% \t train_loss: 0.06  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 74.\n",
            "Epoch 75 of 200, 8% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 75 of 200, 17% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 75 of 200, 25% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 75 of 200, 34% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 75 of 200, 42% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 75 of 200, 51% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 75 of 200, 59% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 75 of 200, 68% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 75 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 75 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 75 of 200, 93% \t train_loss: 0.06  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 75.\n",
            "Epoch 76 of 200, 8% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 76 of 200, 17% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 76 of 200, 25% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 76 of 200, 34% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 76 of 200, 42% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 76 of 200, 51% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 76 of 200, 59% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 76 of 200, 68% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 76 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 76 of 200, 85% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 76 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 76.\n",
            "Epoch 77 of 200, 8% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 77 of 200, 17% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 77 of 200, 25% \t train_loss: 0.05  took: 0.03s\n",
            "Epoch 77 of 200, 34% \t train_loss: 0.05  took: 0.03s\n",
            "Epoch 77 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 77 of 200, 51% \t train_loss: 0.06  took: 0.05s\n",
            "Epoch 77 of 200, 59% \t train_loss: 0.05  took: 0.05s\n",
            "Epoch 77 of 200, 68% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 77 of 200, 76% \t train_loss: 0.03  took: 0.03s\n",
            "Epoch 77 of 200, 85% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 77 of 200, 93% \t train_loss: 0.05  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 77.\n",
            "Epoch 78 of 200, 8% \t train_loss: 0.04  took: 0.05s\n",
            "Epoch 78 of 200, 17% \t train_loss: 0.07  took: 0.03s\n",
            "Epoch 78 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 78 of 200, 34% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 78 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 78 of 200, 51% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 78 of 200, 59% \t train_loss: 0.05  took: 0.03s\n",
            "Epoch 78 of 200, 68% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 78 of 200, 76% \t train_loss: 0.03  took: 0.03s\n",
            "Epoch 78 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 78 of 200, 93% \t train_loss: 0.05  took: 0.03s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 78.\n",
            "Epoch 79 of 200, 8% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 79 of 200, 17% \t train_loss: 0.07  took: 0.03s\n",
            "Epoch 79 of 200, 25% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 79 of 200, 34% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 79 of 200, 42% \t train_loss: 0.03  took: 0.04s\n",
            "Epoch 79 of 200, 51% \t train_loss: 0.05  took: 0.03s\n",
            "Epoch 79 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 79 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 79 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 79 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 79 of 200, 93% \t train_loss: 0.05  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 79.\n",
            "Epoch 80 of 200, 8% \t train_loss: 0.04  took: 0.04s\n",
            "Epoch 80 of 200, 17% \t train_loss: 0.07  took: 0.02s\n",
            "Epoch 80 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 80 of 200, 34% \t train_loss: 0.05  took: 0.05s\n",
            "Epoch 80 of 200, 42% \t train_loss: 0.03  took: 0.03s\n",
            "Epoch 80 of 200, 51% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 80 of 200, 59% \t train_loss: 0.04  took: 0.04s\n",
            "Epoch 80 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 80 of 200, 76% \t train_loss: 0.03  took: 0.04s\n",
            "Epoch 80 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 80 of 200, 93% \t train_loss: 0.05  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 80.\n",
            "Epoch 81 of 200, 8% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 81 of 200, 17% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 81 of 200, 25% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 81 of 200, 34% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 81 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 81 of 200, 51% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 81 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 81 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 81 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 81 of 200, 85% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 81 of 200, 93% \t train_loss: 0.05  took: 0.03s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 81.\n",
            "Epoch 82 of 200, 8% \t train_loss: 0.04  took: 0.04s\n",
            "Epoch 82 of 200, 17% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 82 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 82 of 200, 34% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 82 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 82 of 200, 51% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 82 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 82 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 82 of 200, 76% \t train_loss: 0.03  took: 0.03s\n",
            "Epoch 82 of 200, 85% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 82 of 200, 93% \t train_loss: 0.05  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 82.\n",
            "Epoch 83 of 200, 8% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 83 of 200, 17% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 83 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 83 of 200, 34% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 83 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 83 of 200, 51% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 83 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 83 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 83 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 83 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 83 of 200, 93% \t train_loss: 0.05  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 83.\n",
            "Epoch 84 of 200, 8% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 84 of 200, 17% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 84 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 84 of 200, 34% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 84 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 84 of 200, 51% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 84 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 84 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 84 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 84 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 84 of 200, 93% \t train_loss: 0.05  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 84.\n",
            "Epoch 85 of 200, 8% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 85 of 200, 17% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 85 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 85 of 200, 34% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 85 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 85 of 200, 51% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 85 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 85 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 85 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 85 of 200, 85% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 85 of 200, 93% \t train_loss: 0.04  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 85.\n",
            "Epoch 86 of 200, 8% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 86 of 200, 17% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 86 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 86 of 200, 34% \t train_loss: 0.04  took: 0.04s\n",
            "Epoch 86 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 86 of 200, 51% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 86 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 86 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 86 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 86 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 86 of 200, 93% \t train_loss: 0.04  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 86.\n",
            "Epoch 87 of 200, 8% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 87 of 200, 17% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 87 of 200, 25% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 87 of 200, 34% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 87 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 87 of 200, 51% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 87 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 87 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 87 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 87 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 87 of 200, 93% \t train_loss: 0.04  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 87.\n",
            "Epoch 88 of 200, 8% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 88 of 200, 17% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 88 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 88 of 200, 34% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 88 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 88 of 200, 51% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 88 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 88 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 88 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 88 of 200, 85% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 88 of 200, 93% \t train_loss: 0.04  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 88.\n",
            "Epoch 89 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 89 of 200, 17% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 89 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 89 of 200, 34% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 89 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 89 of 200, 51% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 89 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 89 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 89 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 89 of 200, 85% \t train_loss: 0.04  took: 0.03s\n",
            "Epoch 89 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 89.\n",
            "Epoch 90 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 90 of 200, 17% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 90 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 90 of 200, 34% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 90 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 90 of 200, 51% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 90 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 90 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 90 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 90 of 200, 85% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 90 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 90.\n",
            "Epoch 91 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 91 of 200, 17% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 91 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 91 of 200, 34% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 91 of 200, 42% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 91 of 200, 51% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 91 of 200, 59% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 91 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 91 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 91 of 200, 85% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 91 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 91.\n",
            "Epoch 92 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 92 of 200, 17% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 92 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 92 of 200, 34% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 92 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 92 of 200, 51% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 92 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 92 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 92 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 92 of 200, 85% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 92 of 200, 93% \t train_loss: 0.04  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 92.\n",
            "Epoch 93 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 93 of 200, 17% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 93 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 93 of 200, 34% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 93 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 93 of 200, 51% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 93 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 93 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 93 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 93 of 200, 85% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 93 of 200, 93% \t train_loss: 0.04  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 93.\n",
            "Epoch 94 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 94 of 200, 17% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 94 of 200, 25% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 94 of 200, 34% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 94 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 94 of 200, 51% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 94 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 94 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 94 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 94 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 94 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 94.\n",
            "Epoch 95 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 95 of 200, 17% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 95 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 95 of 200, 34% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 95 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 95 of 200, 51% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 95 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 95 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 95 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 95 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 95 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 95.\n",
            "Epoch 96 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 96 of 200, 17% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 96 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 96 of 200, 34% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 96 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 96 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 96 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 96 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 96 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 96 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 96 of 200, 93% \t train_loss: 0.04  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 96.\n",
            "Epoch 97 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 97 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 97 of 200, 25% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 97 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 97 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 97 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 97 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 97 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 97 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 97 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 97 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 97.\n",
            "Epoch 98 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 98 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 98 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 98 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 98 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 98 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 98 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 98 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 98 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 98 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 98 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 98.\n",
            "Epoch 99 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 99 of 200, 17% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 99 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 99 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 99 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 99 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 99 of 200, 59% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 99 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 99 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 99 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 99 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 99.\n",
            "Epoch 100 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 100 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 100 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 100 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 100 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 100 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 100 of 200, 59% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 100 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 100 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 100 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 100 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 100.\n",
            "Epoch 101 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 101 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 101 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 101 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 101 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 101 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 101 of 200, 59% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 101 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 101 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 101 of 200, 85% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 101 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 101.\n",
            "Epoch 102 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 102 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 102 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 102 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 102 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 102 of 200, 51% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 102 of 200, 59% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 102 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 102 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 102 of 200, 85% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 102 of 200, 93% \t train_loss: 0.03  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 102.\n",
            "Epoch 103 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 103 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 103 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 103 of 200, 34% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 103 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 103 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 103 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 103 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 103 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 103 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 103 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 103.\n",
            "Epoch 104 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 104 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 104 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 104 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 104 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 104 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 104 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 104 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 104 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 104 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 104 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 104.\n",
            "Epoch 105 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 105 of 200, 17% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 105 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 105 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 105 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 105 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 105 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 105 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 105 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 105 of 200, 85% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 105 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 105.\n",
            "Epoch 106 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 106 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 106 of 200, 25% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 106 of 200, 34% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 106 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 106 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 106 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 106 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 106 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 106 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 106 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 106.\n",
            "Epoch 107 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 107 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 107 of 200, 25% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 107 of 200, 34% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 107 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 107 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 107 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 107 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 107 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 107 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 107 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 107.\n",
            "Epoch 108 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 108 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 108 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 108 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 108 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 108 of 200, 51% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 108 of 200, 59% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 108 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 108 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 108 of 200, 85% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 108 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 108.\n",
            "Epoch 109 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 109 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 109 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 109 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 109 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 109 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 109 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 109 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 109 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 109 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 109 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 109.\n",
            "Epoch 110 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 110 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 110 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 110 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 110 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 110 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 110 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 110 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 110 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 110 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 110 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 110.\n",
            "Epoch 111 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 111 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 111 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 111 of 200, 34% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 111 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 111 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 111 of 200, 59% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 111 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 111 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 111 of 200, 85% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 111 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 111.\n",
            "Epoch 112 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 112 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 112 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 112 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 112 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 112 of 200, 51% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 112 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 112 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 112 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 112 of 200, 85% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 112 of 200, 93% \t train_loss: 0.03  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 112.\n",
            "Epoch 113 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 113 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 113 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 113 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 113 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 113 of 200, 51% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 113 of 200, 59% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 113 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 113 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 113 of 200, 85% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 113 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 113.\n",
            "Epoch 114 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 114 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 114 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 114 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 114 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 114 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 114 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 114 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 114 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 114 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 114 of 200, 93% \t train_loss: 0.03  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 114.\n",
            "Epoch 115 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 115 of 200, 17% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 115 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 115 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 115 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 115 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 115 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 115 of 200, 68% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 115 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 115 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 115 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 115.\n",
            "Epoch 116 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 116 of 200, 17% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 116 of 200, 25% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 116 of 200, 34% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 116 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 116 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 116 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 116 of 200, 68% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 116 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 116 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 116 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 116.\n",
            "Epoch 117 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 117 of 200, 17% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 117 of 200, 25% \t train_loss: 0.02  took: 0.03s\n",
            "Epoch 117 of 200, 34% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 117 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 117 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 117 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 117 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 117 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 117 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 117 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 117.\n",
            "Epoch 118 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 118 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 118 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 118 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 118 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 118 of 200, 51% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 118 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 118 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 118 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 118 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 118 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 118.\n",
            "Epoch 119 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 119 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 119 of 200, 25% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 119 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 119 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 119 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 119 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 119 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 119 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 119 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 119 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 119.\n",
            "Epoch 120 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 120 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 120 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 120 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 68% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 120 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 120 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 120.\n",
            "Epoch 121 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 121 of 200, 51% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 121 of 200, 59% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 121 of 200, 68% \t train_loss: 0.03  took: 0.03s\n",
            "Epoch 121 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 121 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 121.\n",
            "Epoch 122 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 122 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 122 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 122 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 122.\n",
            "Epoch 123 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 17% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 123 of 200, 25% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 123 of 200, 34% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 123 of 200, 42% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 59% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 123 of 200, 68% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 123 of 200, 76% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 123 of 200, 85% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 123 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 123.\n",
            "Epoch 124 of 200, 8% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 124 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 124 of 200, 25% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 124 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 124 of 200, 42% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 124 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 124 of 200, 59% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 124 of 200, 68% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 124 of 200, 76% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 124 of 200, 85% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 124 of 200, 93% \t train_loss: 0.05  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 124.\n",
            "Epoch 125 of 200, 8% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 125 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 125 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 125 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 125 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 125 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 125.\n",
            "Epoch 126 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 17% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 126 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 126 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 126 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 126 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 126 of 200, 85% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 126 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 126.\n",
            "Epoch 127 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 127 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 127 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 127 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 127 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 127 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 127 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 127.\n",
            "Epoch 128 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 128 of 200, 17% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 128 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 128 of 200, 34% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 128 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 128 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 128 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 128 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 128 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 128 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 128 of 200, 93% \t train_loss: 0.03  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 128.\n",
            "Epoch 129 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 129 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 129 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 129 of 200, 34% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 129 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 129 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 129 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 129 of 200, 68% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 129 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 129 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 129 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.15\n",
            "Snapshot saved at epoch 129.\n",
            "Epoch 130 of 200, 8% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 130 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 130 of 200, 25% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 130 of 200, 34% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 130 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 130 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 130 of 200, 59% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 130 of 200, 68% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 130 of 200, 76% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 130 of 200, 85% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 130 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.15\n",
            "Snapshot saved at epoch 130.\n",
            "Epoch 131 of 200, 8% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 131 of 200, 17% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 131 of 200, 25% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 131 of 200, 34% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 131 of 200, 42% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 131 of 200, 51% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 131 of 200, 59% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 131 of 200, 68% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 131 of 200, 76% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 131 of 200, 85% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 131 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 131.\n",
            "Epoch 132 of 200, 8% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 132 of 200, 17% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 132 of 200, 25% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 132 of 200, 34% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 132 of 200, 42% \t train_loss: 0.06  took: 0.02s\n",
            "Epoch 132 of 200, 51% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 132 of 200, 59% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 132 of 200, 68% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 132 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 132 of 200, 85% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 132 of 200, 93% \t train_loss: 0.06  took: 0.01s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 132.\n",
            "Epoch 133 of 200, 8% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 133 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 133 of 200, 25% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 133 of 200, 34% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 133 of 200, 42% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 133 of 200, 51% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 133 of 200, 59% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 133 of 200, 68% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 133 of 200, 76% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 133 of 200, 85% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 133 of 200, 93% \t train_loss: 0.04  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 133.\n",
            "Epoch 134 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 134 of 200, 17% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 134 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 134 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 134 of 200, 42% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 134 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 134 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 134 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 134 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 134 of 200, 85% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 134 of 200, 93% \t train_loss: 0.03  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 134.\n",
            "Epoch 135 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 135 of 200, 17% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 135 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 135 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 135 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 135 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 135 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 135 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 135 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 135 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 135 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 135.\n",
            "Epoch 136 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 136 of 200, 17% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 136 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 136 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 136 of 200, 42% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 136 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 136 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 136 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 136 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 136 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 136 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 136.\n",
            "Epoch 137 of 200, 8% \t train_loss: 0.02  took: 0.03s\n",
            "Epoch 137 of 200, 17% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 137 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 137 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 137 of 200, 42% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 137 of 200, 51% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 137 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 137 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 137 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 137 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 137 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 137.\n",
            "Epoch 138 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 138 of 200, 17% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 138 of 200, 25% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 138 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 138 of 200, 42% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 138 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 138 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 138 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 138 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 138 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 138 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 138.\n",
            "Epoch 139 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 139 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 139 of 200, 25% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 139 of 200, 34% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 139 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 139 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 139 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 139 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 139 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 139 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 139 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 139.\n",
            "Epoch 140 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 140 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 51% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 140 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 140 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 140.\n",
            "Epoch 141 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 141 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 141 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 141 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 141.\n",
            "Epoch 142 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 142 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 142 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 142 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 142 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 142 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 142 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 142 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 142 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 142 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 142 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 142.\n",
            "Epoch 143 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 143 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 143 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 143 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 143 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 143 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 143 of 200, 59% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 143 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 143 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 143 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 143 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 143.\n",
            "Epoch 144 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 144 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 144 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 144 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 144 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 144 of 200, 51% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 144 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 144 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 144 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 144 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 144 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 144.\n",
            "Epoch 145 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 145 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 145 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 145 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 145 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 145 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 145 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 145 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 145 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 145 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 145 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 145.\n",
            "Epoch 146 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 146 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 146 of 200, 25% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 146 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 146 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 146 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 146 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 146 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 146 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 146 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 146 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 146.\n",
            "Epoch 147 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 147 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 147 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 147 of 200, 34% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 147 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 147 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 147 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 147 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 147 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 147 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 147 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 147.\n",
            "Epoch 148 of 200, 8% \t train_loss: 0.02  took: 0.03s\n",
            "Epoch 148 of 200, 17% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 148 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 148 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 148 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 148 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 148 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 148 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 148 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 148 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 148 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 148.\n",
            "Epoch 149 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 149 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 149 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 149 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 149 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 149 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 149 of 200, 59% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 149 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 149 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 149 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 149 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 149.\n",
            "Epoch 150 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 150 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 150 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 150 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 150 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 150 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 150 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 150 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 150 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 150 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 150 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 150.\n",
            "Epoch 151 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 151 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 151 of 200, 25% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 151 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 151 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 151 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 151 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 151 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 151 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 151 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 151 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 151.\n",
            "Epoch 152 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 152 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 152 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 152 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 152 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 152 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 152 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 152 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 152 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 152 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 152 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 152.\n",
            "Epoch 153 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 153 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 153 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 153 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 153 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 153 of 200, 51% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 153 of 200, 59% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 153 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 153 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 153 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 153 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 153.\n",
            "Epoch 154 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 154 of 200, 17% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 154 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 154 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 154 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 154 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 154 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 154 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 154 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 154 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 154 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 154.\n",
            "Epoch 155 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 155 of 200, 17% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 155 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 155 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 155 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 155 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 155 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 155 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 155 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 155 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 155 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 155.\n",
            "Epoch 156 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 156 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 156 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 156 of 200, 34% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 156 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 156 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 156 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 156 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 156 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 156 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 156 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 156.\n",
            "Epoch 157 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 157 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 157 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 157 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 157 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 157 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 157 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 157 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 157 of 200, 76% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 157 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 157 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 157.\n",
            "Epoch 158 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 158 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 158 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 158 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 158 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 158 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 158 of 200, 59% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 158 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 158 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 158 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 158 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 158.\n",
            "Epoch 159 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 159 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 159 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 159 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 159 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 159 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 159 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 159 of 200, 68% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 159 of 200, 76% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 159 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 159 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 159.\n",
            "Epoch 160 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 160 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 160 of 200, 25% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 160 of 200, 34% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 160 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 160 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 160 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 160 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 160 of 200, 76% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 160 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 160 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 160.\n",
            "Epoch 161 of 200, 8% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 161 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 161 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 161 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 161 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 161 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 161 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 161 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 161 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 161 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 161 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 161.\n",
            "Epoch 162 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 162 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 162 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 162 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 162 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 162 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 162 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 162 of 200, 68% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 162 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 162 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 162 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 162.\n",
            "Epoch 163 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 163 of 200, 17% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 163 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 163 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 163 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 163 of 200, 51% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 163 of 200, 59% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 163 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 163 of 200, 76% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 163 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 163 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 163.\n",
            "Epoch 164 of 200, 8% \t train_loss: 0.01  took: 0.03s\n",
            "Epoch 164 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 164 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 164 of 200, 34% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 164 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 164 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 164 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 164 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 164 of 200, 76% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 164 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 164 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 164.\n",
            "Epoch 165 of 200, 8% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 165 of 200, 17% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 165 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 165 of 200, 34% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 165 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 165 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 165 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 165 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 165 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 165 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 165 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 165.\n",
            "Epoch 166 of 200, 8% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 166 of 200, 17% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 166 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 166 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 166 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 166 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 166 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 166 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 166 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 166 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 166 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 166.\n",
            "Epoch 167 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 167 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 167 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 167 of 200, 34% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 167 of 200, 42% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 167 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 167 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 167 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 167 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 167 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 167 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 167.\n",
            "Epoch 168 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 168 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 168 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 168 of 200, 34% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 168 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 168 of 200, 51% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 168 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 168 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 168 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 168 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 168 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 168.\n",
            "Epoch 169 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 169 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 169 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 169 of 200, 34% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 169 of 200, 42% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 169 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 169 of 200, 59% \t train_loss: 0.01  took: 0.03s\n",
            "Epoch 169 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 169 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 169 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 169 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 169.\n",
            "Epoch 170 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 170 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 170 of 200, 25% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 170 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 170 of 200, 42% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 170 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 170 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 170 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 170 of 200, 76% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 170 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 170 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 170.\n",
            "Epoch 171 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 171 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 171 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 171 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 171 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 171 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 171 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 171 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 171 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 171 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 171 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 171.\n",
            "Epoch 172 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 172 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 172 of 200, 25% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 172 of 200, 34% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 172 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 172 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 172 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 172 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 172 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 172 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 172 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 172.\n",
            "Epoch 173 of 200, 8% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 173 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 173 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 173 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 173 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 173 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 173 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 173 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 173 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 173 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 173 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 173.\n",
            "Epoch 174 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 174 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 174 of 200, 25% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 174 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 174 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 174 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 174 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 174 of 200, 68% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 174 of 200, 76% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 174 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 174 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 174.\n",
            "Epoch 175 of 200, 8% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 175 of 200, 17% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 175 of 200, 25% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 175 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 175 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 175 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 175 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 175 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 175 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 175 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 175 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 175.\n",
            "Epoch 176 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 176 of 200, 17% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 176 of 200, 25% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 176 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 176 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 176 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 176 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 176 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 176 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 176 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 176 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 176.\n",
            "Epoch 177 of 200, 8% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 177 of 200, 17% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 177 of 200, 25% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 177 of 200, 34% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 177 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 177 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 177 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 177 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 177 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 177 of 200, 85% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 177 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 177.\n",
            "Epoch 178 of 200, 8% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 178 of 200, 17% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 178 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 178 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 178 of 200, 42% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 178 of 200, 51% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 178 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 178 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 178 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 178 of 200, 85% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 178 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 178.\n",
            "Epoch 179 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 179 of 200, 17% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 179 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 179 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 179 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 179 of 200, 51% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 179 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 179 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 179 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 179 of 200, 85% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 179 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 179.\n",
            "Epoch 180 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 180 of 200, 17% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 180 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 180 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 180 of 200, 42% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 180 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 180 of 200, 59% \t train_loss: 0.01  took: 0.03s\n",
            "Epoch 180 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 180 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 180 of 200, 85% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 180 of 200, 93% \t train_loss: 0.01  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 180.\n",
            "Epoch 181 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 181 of 200, 17% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 181 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 181 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 181 of 200, 42% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 181 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 181 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 181 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 181 of 200, 76% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 181 of 200, 85% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 181 of 200, 93% \t train_loss: 0.01  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 181.\n",
            "Epoch 182 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 182 of 200, 17% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 182 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 182 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 182 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 182 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 182 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 182 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 182 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 182 of 200, 85% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 182 of 200, 93% \t train_loss: 0.01  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 182.\n",
            "Epoch 183 of 200, 8% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 183 of 200, 17% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 183 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 183 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 183 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 183 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 183 of 200, 59% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 183 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 183 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 183 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 183 of 200, 93% \t train_loss: 0.01  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 183.\n",
            "Epoch 184 of 200, 8% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 184 of 200, 17% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 184 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 184 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 184 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 184 of 200, 51% \t train_loss: 0.01  took: 0.02s\n",
            "Epoch 184 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 184 of 200, 68% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 184 of 200, 76% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 184 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 184 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 184.\n",
            "Epoch 185 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 185 of 200, 17% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 185 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 185 of 200, 34% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 185 of 200, 42% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 185 of 200, 51% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 185 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 185 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 185 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 185 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 185 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 185.\n",
            "Epoch 186 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 186 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 186 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 186 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 186 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 186 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 186 of 200, 59% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 186 of 200, 68% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 186 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 186 of 200, 85% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 186 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 186.\n",
            "Epoch 187 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 187 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 187 of 200, 25% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 187 of 200, 34% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 187 of 200, 42% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 187 of 200, 51% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 187 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 187 of 200, 68% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 187 of 200, 76% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 187 of 200, 85% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 187 of 200, 93% \t train_loss: 0.05  took: 0.01s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 187.\n",
            "Epoch 188 of 200, 8% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 188 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 188 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 188 of 200, 34% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 188 of 200, 42% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 188 of 200, 51% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 188 of 200, 59% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 188 of 200, 68% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 188 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 188 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 188 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 188.\n",
            "Epoch 189 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 189 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 189 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 189 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 189 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 189 of 200, 51% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 189 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 189 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 189 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 189 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 189 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.12\n",
            "Snapshot saved at epoch 189.\n",
            "Epoch 190 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 190 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 190 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 190 of 200, 34% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 190 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 190 of 200, 51% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 190 of 200, 59% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 190 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 190 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 190 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 190 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 190.\n",
            "Epoch 191 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 191 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 191 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 191 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 191 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 191.\n",
            "Epoch 192 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 192 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 192 of 200, 93% \t train_loss: 0.02  took: 0.02s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 192.\n",
            "Epoch 193 of 200, 8% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 17% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 193 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 193 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 193 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 193.\n",
            "Epoch 194 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 194 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 25% \t train_loss: 0.01  took: 0.01s\n",
            "Epoch 194 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 68% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 194 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 194 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 194.\n",
            "Epoch 195 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 195 of 200, 17% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 195 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 34% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 195 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 195 of 200, 85% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 195 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 195.\n",
            "Epoch 196 of 200, 8% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 196 of 200, 17% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 196 of 200, 25% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 196 of 200, 34% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 196 of 200, 42% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 196 of 200, 51% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 196 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 196 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 196 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 196 of 200, 85% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 196 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 196.\n",
            "Epoch 197 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 197 of 200, 17% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 197 of 200, 25% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 197 of 200, 34% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 197 of 200, 42% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 197 of 200, 51% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 197 of 200, 59% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 197 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 197 of 200, 76% \t train_loss: 0.02  took: 0.02s\n",
            "Epoch 197 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 197 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 197.\n",
            "Epoch 198 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 198 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 198 of 200, 25% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 198 of 200, 34% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 198 of 200, 42% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 198 of 200, 51% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 198 of 200, 59% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 198 of 200, 68% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 198 of 200, 76% \t train_loss: 0.02  took: 0.01s\n",
            "Epoch 198 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 198 of 200, 93% \t train_loss: 0.03  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 198.\n",
            "Epoch 199 of 200, 8% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 199 of 200, 17% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 199 of 200, 25% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 199 of 200, 34% \t train_loss: 0.05  took: 0.02s\n",
            "Epoch 199 of 200, 42% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 199 of 200, 51% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 199 of 200, 59% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 199 of 200, 68% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 199 of 200, 76% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 199 of 200, 85% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 199 of 200, 93% \t train_loss: 0.02  took: 0.01s\n",
            "val_loss = 0.13\n",
            "Snapshot saved at epoch 199.\n",
            "Epoch 200 of 200, 8% \t train_loss: 0.03  took: 0.02s\n",
            "Epoch 200 of 200, 17% \t train_loss: 0.03  took: 0.01s\n",
            "Epoch 200 of 200, 25% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 200 of 200, 34% \t train_loss: 0.06  took: 0.01s\n",
            "Epoch 200 of 200, 42% \t train_loss: 0.05  took: 0.01s\n",
            "Epoch 200 of 200, 51% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 200 of 200, 59% \t train_loss: 0.07  took: 0.01s\n",
            "Epoch 200 of 200, 68% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 200 of 200, 76% \t train_loss: 0.04  took: 0.01s\n",
            "Epoch 200 of 200, 85% \t train_loss: 0.04  took: 0.02s\n",
            "Epoch 200 of 200, 93% \t train_loss: 0.03  took: 0.02s\n",
            "val_loss = 0.14\n",
            "Snapshot saved at epoch 200.\n",
            "Training done! A list of 200 models saved.\n"
          ]
        }
      ],
      "source": [
        "# Train the model and save snapshots regularly\n",
        "save_every = 1    # Save model after every few epoches\n",
        "CES_reg.full_train(save_dir = './content', save_every = save_every)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(CES_reg.train_loss_history, CES_reg.val_loss_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8dy3XDxq_5LG",
        "outputId": "ae6f4f98-5106-41c6-8826-076183ff49d1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5wU9fnA8c+z9Xrh7ugIR1fa0VUEsUVUAnYlNmI3MRr9RaPGQkxMYmI3GjX2ii0SImDvjY5Il3L0cr2XLd/fHzN3LsfdcXfc3h7s8+Z1L3anPjs7O898y8yIMQallFLRyxHpAJRSSkWWJgKllIpymgiUUirKaSJQSqkop4lAKaWinCYCpZSKcpoIwkxEjIj0beG840VkbWvH1IT1DhCRZSJSIiLXNXGeFn/OcBCRlSIysbWnjZTQ7SsiT4jIHU2ZtgXruUBEPmhpnG1FRLJF5MR2EMcMEXk50nEcKFekA2gvRCQb6AQEQgY/b4y5tg1jMEA/Y8x6AGPMl8CAtlp/iJuBT40xWfWNFJHPgJeNMU+39opFpBewCXAbY/wtXY4xZlA4pm0PjDFXt8Zy6tvWxphXgFdaY/mRIiLPA9uMMbcf4HJ60Qr74sFAE8Hefm6M+SjSQbQDPYGZkQ6iISLiOtR/mEq1KWOM/llXV2cDJ9Yz3AsUAoNDhmUAFUBH+/0VwHogH5gNdA2Z1gB97defAZeHjJsOfGW//sKetgwoBc4DJmKd2dRMf7i9jEJgJTAlZNzzwGPAHKAEmA/0aeTzTrGXUWgv83B7+CdYpaJKO47+dea7p874f4Z8zquBH+1lPgZIyHyXAquBAuB9oGcDcW2xl1Vq/x1lb6evgQeBPODPQB871jwgF+ssNqW+7xOYAbwBvGhvm5XAqBZOOwJYao97E3gd+HMT9q+xwC7AGTLsDGC5/XoM8K297XYC/wQ8DexHz4euE7jJnmeHvZ1Dpz3NjrcY2ArMaMK2/ipkmqOBhUCR/f/RIeM+A/5kfzclwAdAegOfPxV4F8ix94F3ge5NXRZwEbDZ/r7/QMO/1ysBH1Btf6b/2cO7Am/b698EXBcyzxhgkb2NdgMPNLR96lnfDKzScaO/K3vc74Ht9udbC5zQ2Prb9PjX1itsr38N7Vj2uGeBe0Le/xp4z359PNaBaARW0ngU+CJk2iYlgrrT2u8nYicCwI2VbG4DPPZ6S4AB9vjn7R/JGKyS3ivAzAY+T3+shHOSvdyb7WV76ouznvn3GW/H/i6QAhxm/+Am2eOm2ss/3I7tduCbBpbdy16Wq8528gO/seePBfra8XuxEvMXwEP1fZ/2j7USOBVwAn8FvmvutPZ23wxcb2+3M7EOOPtNBPb8G4CTQt6/Cdxivx4JHGl/vl5YSfO3DexHz9esE5iEdfAYDMQDr9aZdiIwBKs9cKg97en72dY1JycdsA7aF9lxTbPfp4XsBxuw9qdY+/3fGvjsacBZQByQaH/2WXX2qXqXBRyBdSCeYH/fD9j7Q0O/19rtY793AIuBO+3vsDewETjZHv8tcJH9OgE4sqHtU8+6ZmAnAhr5XWFV8W7FPkm0l92nsfW35Z82Fu9tlogUhvxdYQ9/FTg/ZLpf2MMALgCeNcYsMcZUAbcCR9n1i63pSKyd5G/GmGpjzCdYB95pIdO8Y4xZYKxqk1eAeuv4sUobc4wxHxpjfMB9WD++ow8wxr8ZYwqNMVuAT0PWfzXwV2PMaju2vwBZItKzGcveYYx51BjjN8ZUGGPW2/FXGWNysA4OxzYy/1fGmLnGmADwEjCsBdPWHKgfMcb4jDH/ARY04zO8hv19iUgiVrJ5DcAYs9gY8539+bKBJ/fzeWqcCzxnjFlhjCnDOjDVMsZ8Zoz5wRgTNMYst9fXlOWCVZr40Rjzkh3Xa8Aa4Och0zxnjFlnjKnAKknVu88ZY/KMMW8bY8qNMSVYJcu6cTS0rLOBd40xX9i/sTuAYBM/A8BoIMMYc7f929kI/JufftM+oK+IpBtjSo0x3zVj2aEa+10FsJLYESLiNsZkG2M2tPL6W0wTwd5ON8akhPz92x7+KRAnImPtA3wW8I49rivWWSIAxphSrDPzbq0cW1dgqzEm9Aewuc56doW8LsdKHA0tKzTmINbZyoHG3ND6ewIP1yRYrCo0aeb6toa+EZFOIjJTRLaLSDHwMpDejNhiRKShNrKGpu0KbDf2qVt9ce3Hq8CZIuLFKk0sMcZstj9PfxF5V0R22Z/nL/v5PDW61olhc+hIe5/9VERyRKQIKyk3Zbk1y95cZ1iL9jkRiRORJ0Vks/35vgBSRMTZhGXt9RnthJfXxM8A1v7XNfQkD6tk3ckefxnW2fwaEVkoIpObsexQDf6ujNUB5LdYiXqPve92beX1t5gmgiawzwzfwDqbm4Z1dlJij96BtaMBICLxWMXg7fUsqgyraFyjczPC2AH0EJHQ7+ywBtbTlGWFxixAj2Ysq7m3rN0KXFUnycYaY75pxrLrDv+LPWyIMSYJuBAruYTTTqCbvb1q9GjqzMaYVVgHilPYu1QJ8C+ss+1+9ue5jaZ9np11YjiszvhXsdqtehhjkoEnQpa7v+9xr/0kZPkt2ef+D6t6ZKz9+SbYw5v9GUUkDus31pC6n2srsKnO/pdojDkVwBjzozFmGtARuBd4y/4dN3c/b/R3ZYx51RhzjD2NsdfV2PrbjCaCpnsVq+h3AXv/gF8DfikiWfaZ3l+A+Xbxvq5lWGeEcXY/78vqjN+NVX9Zn/lYZ0k3i4jb7vf+c1rWu+cN4DQROUFE3Fg/0iqgvgNzfRqLsz5PALeKyCAAEUkWkXMamDYHq9i/v+UnYtUbF4lIN6wG03D7FquIf62IuERkKlabTC27D//ERpbxKlYbwwSsevIaiViNhaUiMhC4pokxvQFMF5Ej7APkXXXGJwL5xphKERmDlYBq7G9bzwX6i8gv7M97HlZ9/btNjK1uHBVAoYh0qCfOxrwFTBaRY0TEA9xN48euuvvnAqBERH4vIrEi4hSRwSIyGkBELhSRDPsMvtCeJ0jT98UaDf6u7GtzjrePEZVY2yK4n/W3GU0Ee/ufiJSG/NVU/2CMmY91Rt8VmBcy/COsOsu3sc5c+rB3e0KoB7EaF3cDL7Bvf+0ZwAt28fXc0BHGmGqsA/8pWI3TjwMXG2PWNPdDGmPWYp1BP2ov6+dYXWerm7iIh4GzRaRARB5pwvrewTrTmWlXC6ywP0d905Zj1R9/bW+HIxtY7B+xGuiLsHpK/aeJsbeYvX3OxErghVjb8F2sHzsi0gOrAf+HRhZTU0f/iTEmN2T477AO0iVY9devNzGmecBDWD2o1tv/h/oVcLeIlGA1lr4RMm+j29oYkwdMxjqg5WE1fk6uE3dTPYRVX54LfAe819QZjTErsTpovIr1GysAtjUyyzNYdfGFIjLLLtFPxqrS3WTH8DSQbE8/CVgpIqVY+/b5djtUU/fFmjgb+115gb/Zw3dhnf3f2tj6m7Z1WofsXd2plGoOEZkPPGGMeU5ELgQGGWNu3d98SrUnmgiUagYRORarD3guVjXhE0BvY8zOiAam1AHQK4uVap4BWNUr8Vh90c/WJKAOdloiUEqpKKeNxUopFeUOuqqh9PR006tXr0iHoZRSB5XFixfnGmMy6ht30CWCXr16sWjRokiHoZRSBxURqXuVeC2tGlJKqSiniUAppaKcJgKllIpyB10bgVKq7fl8PrZt20ZlZWWkQ1H7ERMTQ/fu3XG73U2eRxOBUmq/tm3bRmJiIr169WLvm6+q9sQYQ15eHtu2bSMzM7PJ82nVkFJqvyorK0lLS9Mk0M6JCGlpac0uuWkiUEo1iSaBg0NLvqeoSQR/nbeac578hiVbCiIdilJKtStRkwh+3F3KwuwC8suaest9pVR7kZeXR1ZWFllZWXTu3Jlu3brVvq+ubvw3vWjRIq677rr9ruPoow/0kd2Wzz77jMmT2/xpkwckahqLXU6ruOQPtOmDf5RSrSAtLY1ly5YBMGPGDBISEvjd735XO97v9+Ny1X84GzVqFKNGjdrvOr75pqkP6Dv0RE2JwO20Pmp1QO+2qtShYPr06Vx99dWMHTuWm2++mQULFnDUUUcxfPhwjj76aNauXQvsfYY+Y8YMLr30UiZOnEjv3r155JGfHrCXkJBQO/3EiRM5++yzGThwIBdccAE1d2meO3cuAwcOZOTIkVx33XX7PfPPz8/n9NNPZ+jQoRx55JEsX74cgM8//7y2RDN8+HBKSkrYuXMnEyZMICsri8GDB/Pll1+2+jZrSNSUCNxaIlCqVfS6dU5Ylpv919OaPc+2bdv45ptvcDqdFBcX8+WXX+Jyufjoo4+47bbbePvtt/eZZ82aNXz66aeUlJQwYMAArrnmmn363C9dupSVK1fStWtXxo0bx9dff82oUaO46qqr+OKLL8jMzGTatGn7je+uu+5i+PDhzJo1i08++YSLL76YZcuWcd999/HYY48xbtw4SktLiYmJ4amnnuLkk0/mD3/4A4FAgPLy8mZvj5aKokRglQj8QS0RKHWoOOecc3A6nQAUFRVxySWX8OOPPyIi+Hy+euc57bTT8Hq9eL1eOnbsyO7du+nevfte04wZM6Z2WFZWFtnZ2SQkJNC7d+/a/vnTpk3jqaeeajS+r776qjYZHX/88eTl5VFcXMy4ceO48cYbueCCCzjzzDPp3r07o0eP5tJLL8Xn83H66aeTlZV1QNumOaImEbhqq4a0RKDUgWjJmXu4xMfH176+4447OO6443jnnXfIzs5m4sSJ9c7j9XprXzudTvx+f4umORC33HILp512GnPnzmXcuHG8//77TJgwgS+++II5c+Ywffp0brzxRi6++OJWXW9DoqeNwKFVQ0odyoqKiujWrRsAzz//fKsvf8CAAWzcuJHs7GwAXn/99f3OM378eF555RXAantIT08nKSmJDRs2MGTIEH7/+98zevRo1qxZw+bNm+nUqRNXXHEFl19+OUuWLGn1z9CQ6EkEdonAp43FSh2Sbr75Zm699VaGDx/e6mfwALGxsTz++ONMmjSJkSNHkpiYSHJycqPzzJgxg8WLFzN06FBuueUWXnjhBQAeeughBg8ezNChQ3G73Zxyyil89tlnDBs2jOHDh/P6669z/fXXt/pnaEhYn1ksIpOAhwEn8LQx5m91xh8GvACk2NPcYoyZ29gyR40aZVryYJq/zlvNk19s5OaTB/CriX2bPb9S0Wz16tUcfvjhkQ4j4kpLS0lISMAYw69//Wv69evHDTfcEOmw9lHf9yUii40x9fajDVuJQEScwGPAKcARwDQROaLOZLcDbxhjhgPnA4+HKx5PTWOxlgiUUi3073//m6ysLAYNGkRRURFXXXVVpENqFeFsLB4DrDfGbAQQkZnAVGBVyDQGSLJfJwM7whWMq7ZqSNsIlFItc8MNN7TLEsCBCmcbQTdga8j7bfawUDOAC0VkGzAX+E19CxKRK0VkkYgsysnJaVEwNdcR+LT7qFJK7SXSjcXTgOeNMd2BU4GXRGSfmIwxTxljRhljRmVkZLRoRbWNxX4tESilVKhwJoLtQI+Q993tYaEuA94AMMZ8C8QA6eEIxlXTfTSoiUAppUKFMxEsBPqJSKaIeLAag2fXmWYLcAKAiByOlQhaVvezH26X3mtIKaXqE7ZEYIzxA9cC7wOrsXoHrRSRu0Vkij3Z/wFXiMj3wGvAdBOm/qx6QZlSB6/jjjuO999/f69hDz30ENdcc02D80ycOJGaruannnoqhYWF+0wzY8YM7rvvvkbXPWvWLFat+qmPy5133slHH33UnPDr1Z5uVx3WW0zY1wTMrTPszpDXq4Bx4Yyhhlu7jyp10Jo2bRozZ87k5JNPrh02c+ZM/v73vzdp/rlzG708qVGzZs1i8uTJHHGE1fv97rvvbvGy2qtINxa3Gb3XkFIHr7PPPps5c+bUPoQmOzubHTt2MH78eK655hpGjRrFoEGDuOuuu+qdv1evXuTm5gJwzz330L9/f4455pjaW1WDdY3A6NGjGTZsGGeddRbl5eV88803zJ49m5tuuomsrCw2bNjA9OnTeeuttwD4+OOPGT58OEOGDOHSSy+lqqqqdn133XUXI0aMYMiQIaxZs6bRzxfp21VHzU3nPE5tLFaqNYx6YUhYlrvokh8aHNehQwfGjBnDvHnzmDp1KjNnzuTcc89FRLjnnnvo0KEDgUCAE044geXLlzN06NB6l7N48WJmzpzJsmXL8Pv9jBgxgpEjRwJw5plncsUVVwBw++2388wzz/Cb3/yGKVOmMHnyZM4+++y9llVZWcn06dP5+OOP6d+/PxdffDH/+te/+O1vfwtAeno6S5Ys4fHHH+e+++7j6aefbvDzRfp21VFXIvD5tWpIqYNRTfUQWNVCNc8DeOONNxgxYgTDhw9n5cqVe9Xn1/Xll19yxhlnEBcXR1JSElOmTKkdt2LFCsaPH8+QIUN45ZVXWLlyZaPxrF27lszMTPr37w/AJZdcwhdffFE7/swzzwRg5MiRtTeqa8hXX33FRRddBNR/u+pHHnmEwsJCXC4Xo0eP5rnnnmPGjBn88MMPJCYmNrrspoiaEkFN91GflgiUOiCNnbmH09SpU7nhhhtYsmQJ5eXljBw5kk2bNnHfffexcOFCUlNTmT59OpWVlS1a/vTp05k1axbDhg3j+eef57PPPjugeGtuZX0gt7Fuq9tVR02JwOPSxmKlDmYJCQkcd9xxXHrppbWlgeLiYuLj40lOTmb37t3Mmzev0WVMmDCBWbNmUVFRQUlJCf/73/9qx5WUlNClSxd8Pl/traMBEhMTKSkp2WdZAwYMIDs7m/Xr1wPw0ksvceyxx7bos0X6dtVRVCLQew0pdbCbNm0aZ5xxRm0VUc1tmwcOHEiPHj0YN67xTogjRozgvPPOY9iwYXTs2JHRo0fXjvvTn/7E2LFjycjIYOzYsbUH//PPP58rrriCRx55pLaRGCAmJobnnnuOc845B7/fz+jRo7n66qtb9LlqnqU8dOhQ4uLi9rpd9aefforD4WDQoEGccsopzJw5k3/84x+43W4SEhJ48cUXW7TOUGG9DXU4tPQ21Eu3FHDGv75hWPcU/vvrNumxqtQhQ29DfXBpN7ehbm/cevdRpZSqV9QlAu0+qpRSe4uaROCquQ21dh9VqkUOtmrkaNWS7ylqEkFt1ZCWCJRqtpiYGPLy8jQZtHPGGPLy8oiJiWnWfFHTa6jmwTTafVSp5uvevTvbtm2jpQ+GUm0nJiaG7t27N2ueqEkE2n1UqZZzu91kZmZGOgwVJlFTNVRzQZkmAqWU2lvUJILaW0xo1ZBSSu0lehKB3n1UKaXqFTWJwF3bRmC054NSSoWImkTgcAjO2gfYayJQSqkaUZMIQLuQKqVUfaIrETj0cZVKKVVXdCWC2mcSaCJQSqkaUZUItAupUkrtK6oSgd5vSCml9hVliUAbi5VSqq6oSgQufTiNUkrtI6oSgT6lTCml9hVdiUAbi5VSah/RlQi0+6hSSu0jqhJBbfdRvcWEUkrViqpEUNtG4NcSgVJK1YiyRKC3olZKqbqiKhHUdB+t1sZipZSqFVWJwOPUxmKllKorqhLBT/ca0kSglFI1oioRuF0/PaVMKaWUJboSgT6hTCml9hFVicCl3UeVUmofUZUI9DbUSim1r7AmAhGZJCJrRWS9iNzSwDTnisgqEVkpIq+GM56a6wi0jUAppX7iCteCRcQJPAacBGwDForIbGPMqpBp+gG3AuOMMQUi0jFc8cBPJQLtPqqUUj8JZ4lgDLDeGLPRGFMNzASm1pnmCuAxY0wBgDFmTxjj0UdVKqVUPcKZCLoBW0Peb7OHheoP9BeRr0XkOxGZVN+CRORKEVkkIotycnJaHNBP3Ue1RKCUUjUi3VjsAvoBE4FpwL9FJKXuRMaYp4wxo4wxozIyMlq8sp+6j2oiUEqpGuFMBNuBHiHvu9vDQm0DZhtjfMaYTcA6rMQQFj91H9WqIaWUqhHORLAQ6CcimSLiAc4HZteZZhZWaQARSceqKtoYroC0+6hSSu0rbInAGOMHrgXeB1YDbxhjVorI3SIyxZ7sfSBPRFYBnwI3GWPywhXTT91HNREopVSNsHUfBTDGzAXm1hl2Z8hrA9xo/4XdT91HtWpIKaVqRLqxuE1p91GllNpXVCUCj3YfVUqpfURVInA57KohbSxWSqlaYW0jaE+e/v4JPtm0AKf3aKr9Lb8WQSmlDjVRUyJYmbuSdUULcbrztESglFIhoiYRpMelA+BwlWqvIaWUChE9iSDWqg5yuIqp1sZipZSqFUWJoKZEUKK3oVZKqRBRkwjSQhJBSaU/wtEopVT7ETWJ4KeqoRK2FJRTUR2IcERKKdU+RE8iiLMSgdtTijGwbndJhCNSSqn2IWoSQVpMGgDGUQIEWauJQCmlgChKBG6nm2RvChBEnGWs3lkc6ZCUUqpdiJpEAHv3HFqzS0sESikFUZcIfmowXrOrGOsu2EopFd2iKxHYDcZxsWUUlPvIKamKcERKKRV50ZUI7KqhjsnVAKzW6iGllIquRFBzUVlyQgUA328tjGQ4SinVLkRVIqhpI4iNLQNg0eaCSIajlFLtQpQlAqtEgMPqOrp0SwHBoDYYK6WiW1QlgsOSegKwuXg9XVPclFT5WbdH2wmUUtEtqhJBelwGvZP7UO4vp1+PPECrh5RSKqoSAcDYrkcBEJuwHoAlmgiUUlEu6hLBkV2PBiAv8AOgJQKllIq6RDCi00jcDjfZxWuIj6lkS345e0oqIx2WUkpFTNQlglh3HFkdR2Aw9O6+A9DqIaVUdIu6RAAwqssYABKSNgNaPaSUim5NSgQiEi8iDvt1fxGZIiLu8IYWPiM7jwag2KwBYLEmAqVUFGtqieALIEZEugEfABcBz4crqHAblDYYrzOG3RWbcbhKWbGjiEqfPrpSKRWdmpoIxBhTDpwJPG6MOQcYFL6wwsvtdDOs4zAAenbZiS9g+GF7UYSjUkqpyGhyIhCRo4ALgDn2MGd4QmobIzpZ1UMpqVsAbSdQSkWvpiaC3wK3Au8YY1aKSG/g0/CFFX4jO48CoELWAbBkiyYCpVR0cjVlImPM58DnAHajca4x5rpwBhZug9KH4HV6ya3ajDhLWbrFgzEGEYl0aEop1aaa2mvoVRFJEpF4YAWwSkRuCm9o4eVxehiakQVAaupWckur2VpQEeGolFKq7TW1augIY0wxcDowD8jE6jl0UBvReSQAHdO3AXphmVIqOjU1Ebjt6wZOB2YbY3zAQX8j/5F2g3HAbd+ATtsJlFJRqKmJ4EkgG4gHvhCRnkBxuIJqK4MyhuBxeCjwbUacZZoIlFJRqUmJwBjziDGmmzHmVGPZDBwX5tjCzuv0MsS+niAmPptVO4spqfRFOCqllGpbTW0sThaRB0Rkkf13P1bp4KA3urN136FOGdkEDSzMzo9wREop1baaWjX0LFACnGv/FQPP7W8mEZkkImtFZL2I3NLIdGeJiBGRUU2Mp9Uc3W08AEHvasDw7ca8tg5BKaUiqknXEQB9jDFnhbz/o4gsa2wGEXECjwEnAduAhSIy2xizqs50icD1wPymh916BqYdToeYDuRX5uL07OHbDcmRCEMppSKmqSWCChE5puaNiIwD9tfpfgyw3hiz0RhTDcwEptYz3Z+Ae4GIPB3GIQ6O7DoOgJjEdazcWUxRhbYTKKWiR1MTwdXAYyKSLSLZwD+Bq/YzTzdga8j7bfawWiIyAuhhjJlDI0Tkypr2iZycnCaG3HRHd7NyXIcOGzAG5m/S6iGlVPRoaq+h740xw4ChwFBjzHDg+ANZsX2rigeA/2vC+p8yxowyxozKyMg4kNXW68iuR+MUJ5XOdThcRXy2tvWTjVJKtVfNekKZMabYvsIY4Mb9TL4d6BHyvrs9rEYiMBj4zC5lHAnMjkSDcUpMCscddgKGIDEp8/lg1S4CwYP+ejmllGqSA3lU5f7uzrYQ6CcimSLiAc4HZteMNMYUGWPSjTG9jDG9gO+AKcaYRQcQU4udO3AaAHEdFpJbVq5PLVNKRY0DSQSNnjIbY/zAtcD7wGrgDfsW1neLyJQDWG9YDO80kn6p/cFRgjdpCe+t3BXpkJRSqk00mghEpEREiuv5KwG67m/hxpi5xpj+xpg+xph77GF3GmNm1zPtxEiVBgBEhIsH/xKA+I5zmbdqNUGtHlJKRYFGE4ExJtEYk1TPX6IxpqnXIBw0JmWexvjux+JwVlKW8CJfrNdSgVLq0HcgVUOHHBHh9qNn4HUk4YnfyJ+/+z2+gF5ToJQ6tGkiqCMtNp17JzxGMBBLoVnKrz+4htLq0kiHpZRSYaOJoB7H9MxigONmgv4EluyZz5XvTWdP2e5Ih6WUUmGhiaABVx45gcLN14A/g3UFa/nlvAtZm78m0mEppVSr00TQgIkDMujXoRd5G6+mW9zh7C7bxfQ5v+ClFc8TNMFIh6eUUq1GE0EDRIQrJ/TGBOMp3XYFZ/U/F1/Qx8OL7+dXH1zBrjLtUaSUOjRoImjElGFd6ZYSy4Y91RwecykPHv9PUmM6sGjXAqbNPpMPs9+LdIhKKXXANBE0wu10cP0J/QC4/8O1jO0ynplT3uaY7hMoqS7h1s9v4sGF/8Af9Ec4UqWUajlNBPtx1oju9OuYwNaCCl76bjNpsek8ePw/uXnsbTjFxSurXuT6j35FcVVRpENVSqkW0USwH06H8PtJAwF46KN17CmuREQ4d+A0njj5aVJjOjB/57dcMucXbCzcEOFolVKq+TQRNMEJAzty/ICOlFT5uWfu6trhwzuN5MXTXqN/h4FsLdnCL+dewBdbP4tcoEop1QKaCJpARPjjlEHEuB389/sdfL0+t3Zcl4SuPDPpBU7qdTJlvjL+75PreGHFsxijN6xTSh0cNBE0UY8OcfzmOKvh+I7ZK6jyB2rHxbrj+MuEf3B11rUYDI8ufpA/fn071YHqSIWrlFJNpomgGa4Y35s+GfFszCnjic837jVORLh82FXcO/EBYlyxvLthNtd8cDn5Ffr8Y6VU+6aJoBk8Lgd/Pn0IAI988iPLthbuM80JPSdZnFoAACAASURBVE/i6Ukv0CmuE9/vWcolc37Buvy1bR2qUko1mSaCZjqqdxqXH5NJIGi4fuZSSqv2vYZgYNrhvHDaawxOH8rOsh38cu6FvLdxbgSiVUqp/dNE0AI3nTyAw7sksTm/nD/+b2W906THZfDkpGf5eZ+pVAUquf3L3/PQwvv04jOlVLujiaAFvC4nj5yXhdfl4M3F23h3+Y76p3N6uXPcn/j92D/gFBcvr3qB33x4NYWVBW0csVJKNUwTQQv165TI7aceDsDv317O+j31P7xGRDhn4Pk8cfLTdIjpwMJd87no3fNZk7eqLcNVSqkGaSI4ABce2ZPJQ7tQVh3gqpcXUVLZ8GMth3cayUuTX2dQ+hB2lu3gsnkXM2/ju20YrVJK1U8TwQEQEe49cyj9OyWwIaeMm95a3uiFZJ3iO/PUpOeY0vcMqgJV3PHlrdy/4F5tN1BKRZQmggMU73Xx5IWjSPS6eG/lLh7/vPH7DXmdXu44+o/ccuQduBwuXlv9Mr/+8EptN1BKRYwmglaQmR7Pg+dlAXDfB2t5b2XjD60REc4ecC5PnPwsaTFpLN61kCvfv5S8itxG51NKqXDQRNBKTjy8EzefPABj4IbXl7Fi+/5vS53VcTgvTX6d3sl92Fi4nive+yXbire2QbRKKfUTTQSt6Jpj+3DWiO5U+AJc9uJCdhVV7neejvGdeHLSs/RPHcCW4mymz72AZXuWtkG0Sill0UTQikSEv5wxmDG9OrC7uIpLX1hIcSM9iWqkxnTgqUnPc3S3YyisKuCa9y/THkVKqTajiaCVeV1OnrhwJJlp8azaWczlLy6i0hfY73wJngQeOP5Rzh04DV/Qxx1f3sqTyx7X21krpcJOE0EYdIj38NJlY+icFMOCTflc+9oS/IHgfudzOVzcPPY2fjfmFhzi4N/f/4vbv/w9VYGqNohaKRWtNBGESffUOF66dAwpsW4+Wr2Hm99eTjDYtLP78w+/gAeOf5Q4Vxzvb5rHNe9fTkFlfpgjVkpFK00EYdSvUyLPTR9NnMfJf5Zu589zVze5queY7hN45pQX6RTfmeU5y5g+5xdsKFgf5oiVUtFIE0GYDT8slScvHInbKTz79SYe/Ghdk+ft12EAL5z6KkekDWJ76XYumfsL5mz4XxijVUpFI00EbWB8vwwePm84TofwyCfrm5UM0uMyeGrSc5zS+zQq/RXc9dVtPLzoAYJm/20OSinVFJoI2sipQ7rw0HlZOAQe/vhHHmpGMohxxXL3MX/ltqPuxCkuXlr5HDd+8hu9Elkp1So0EbShnw/tykPnDcch8NDHP/Lwxz82eV4R4cz+5/DIiY+T6Enkq21fcN5/z+STzR+FMWKlVDTQRNDGpgzryoPnWiWDBz9axyPNSAYAY7sexWtT/sOYLmMprCrg5s9u4K6v/kBpdUmYIlZKHeo0EUTA1KxutcnggY/W8egnzUsGneM788+TnuKmMbfidcYwZ8Nszpt9Jgt3zg9TxEqpQ5kmggiZmtWN+88ZhkPg/g/X8eBH65p1FbFDHJx3+C945edvcETaYHaX7eKaDy7n/gX3Uunf/z2OlFKqRlgTgYhMEpG1IrJeRG6pZ/yNIrJKRJaLyMci0jOc8bQ3ZwzvXpsMHv74R+5pxnUGNXolZ/LsqS9xVdavcIqT11a/zEXvnsfX277U21MopZokbIlARJzAY8ApwBHANBE5os5kS4FRxpihwFvA38MVT3t1xvDu/HPaCNxO4emvNnHrOz8QaOIVyDVcDhdXDLuG5059hV7JmWwq2sj1H/+KK9+bzuq8lWGKXCl1qAhniWAMsN4Ys9EYUw3MBKaGTmCM+dQYU26//Q7oHsZ42q1Th3ThqYtG4XU5mLlwK9e/vhRfE+5NVNcR6YN4efIbXD/y/0jxprJ0zxIufncad399J7na1VQp1YBwJoJuQOhTVrbZwxpyGTCvvhEicqWILBKRRTk5Oa0YYvtx3ICOvHjpGBK8Lt5dvpOrXlrcpLuW1hXjiuGiwdOZdeYcLjziEpwOJ7PXv8PUtydx73d/1gffKKX20S4ai0XkQmAU8I/6xhtjnjLGjDLGjMrIyGjb4NrQ2Mw0Xr18LKlxbj5Zu4fpzy+gtKplD7ZP8CTy29G/442pszi2x3FUBap4c+3rnDlrMrd89n+sytUqI6WUJZyJYDvQI+R9d3vYXkTkROAPwBRjTNTfb3lo9xRev/IoOiZ6+W5jPhc8PZ/C8uoWL++wpJ7cf/wjzJzyHyb3mYJDHHy0+QMunnM+V79/Gd9s/0oblZWKchKug4CIuIB1wAlYCWAh8AtjzMqQaYZjNRJPMsY0qTP9qFGjzKJFi8IQcfuyOa+MC56Zz7aCCgZ2TuTFS8fQMTHmgJe7u2wXM1e/wn/WvUmZrwyAvqn9uGjQLzk5cxIuh/uA16GUan9EZLExZlS948J5NigipwIPAU7gWWPMPSJyN7DIGDNbRD4ChgA77Vm2GGOmNLbMaEkEADuLKrjwmflsyCmjV1ocL182lu6pca2y7JLqYt5e+yYzV79CboXV7pIR25FJvU9lSt8zyEzp3SrrUUq1DxFLBOEQTYkAILe0ioufXcCqncV0SvLy/PQxHN4lqdWWXx2oZt7GOby08jmyizbVDh/b5ShOzjyFYw87nmRvcqutTykVGZoIDnJFFT6ueGkRCzblk+B18eSFIxnXN71V12GMYXnO97y74b/M3fAuVQHr6mSnuBjTZSwn9PoZE3scT0pMSquuVynVNjQRHAIqfQH+783vmfPDTtxO4e9nDeWM4eG57KKoqoiPst/n480fsnjXQgLG6sbqFCejOo/hxF4/47jDTiAlJjUs61dKtT5NBIeIYNDwl3mreforqwrnppMH8Ktj+yAiYVtnQWU+n235hI83f8jCnfP3SgojO4/mhJ4ncWyP40iPO3S79Sp1KNBEcIh55qtN/HnuKoyBC8cexh+nDMbpCF8yqFFYWcjnWz/l483vM3/HfALmp2scMpN7M6rzaEZ1GcvITqO1CkmpdkYTwSFozg87ueGNZVT7g5x4eCcePX84sR5nm62/uKrITgpW9VGFv2Kv8f1TBzCy82hGdxnLiE4jSfAktllsav/eXvsGi3YtIN6dwC+OuIjeKX0iHZIKM00Eh6gFm/K54qVFFFX4yOqRwlMXjqRj0oFfa9Bc/qCPlbkrWbhzPot3LeT7PUupDv50EZxDHPRN7U+flL70SelD75S+9EnpS5eErjikXVzcHlV+yPmeX869sPb9EWmDeP60V/W7OMRpIjiErd9TwiXPLWR7YQXpCV4eOT+Lo/u0bo+i5qoKVPFDznIW7ZzPol0L+SFn+V7VSDViXLH0Tu5N75Dk0CelL53iO4e13SOa+YN+Lp4zjXX5a/h5n6l8u+MbcityuGfC3zk585RIh3fIMMYwd+O7HJ52RLspbWkiOMTtKankuplL+W5jPg6BG0/qz6+O7YujDdoNmqLCV86PBevYWLiBDYXr2VC4no2FG2ovZKsr3h1PZnIfeqf0oU9KX3om9yLGFUuSJ4lO8Z1J8iRpomjE/B3fkuhJ4oj0QfuMm7n6Fe5b8De6xHflzdNn8d7Gufz52xn29k3kVyOuZ3KfRq/pVE3w3fZvuPajq+iZ1Iu3Tp99wPtrIBjgiWX/5LyBv2hxxwxNBFHAHwjy8Mc/8uin6wE4tn8GD56bRYd4T4Qja1hRVREbC9ezoXADG+3ksKFwPQWV+Y3OF+OKpWNcJzrHd6JjXCcy4jqS4k0lNSaVOHc8QRMkwZNAqjeVlJhUUrypuJ3RceuMpbsXc8V70xGEK7Ou4bKhV9VW+eSW53DWrJ9T5ivjgeMfZUKPifiDfi6Z8wvW5q8GrEb/N0//byQ/wiHhL9/ezX/WvQnAs6e8xNCOWftM4w/6+WDTPN7fNI9le5YQMEEOSzyMcwaez+Q+U2v3WWMM986/h7fWvk7/DgN5efLrLarG00QQRT5bu4cb3lhGQbmPTkle7j8ni2Na+eKzcCuozN8rOWwr2Up1oIrCykJ2l++qvUdScyS4E0mJSSE1JpUEd2JtskiLTSfWFYvXGYPX5SXeFU+8J544VzzxngTi3XHEuxOIc8eT4I7H64xpt6URYwyXzbuI5Tnf1w47qus4/jT+ryR4Ern185v4dMtHTOgxkQeOf7R2mkp/BTtLd3LZvIsori7mrdP/S69kvcVISwVNkNPePImcij0AnNH/bP5w1F18vuVTXl75PJP7ng7AiyueZXNxdr3LGN15LP847iHi3fE8vvRRnvvh33gcHv550pOM6FzvsXy/NBFEmR2FFVw3cymLNhcAcPkxmfzuZwOIcbddr6JwKq0uZXfZLnaX72J32S7yKnIpqCwgvzKfSn8lTnFQ4iuhoLKAwsp8CqsKCZrmP+inPg5x4Ha4iXHFkGyXQpK9ySR6kkj0JJLoSSTenYAxBoOhY1xHnA4nvoCPGFcsca44PE4PfuOnOlCNL+DDF/QB1rMkuif2oGNcJ1wOJzGu2CbFVFRVxGNLHmZL8WYW7VpAakwHbj3yDu759o8UVRWS6EmkS0I31uWvIcYVyxtT36Frwr6PBrnrqz8wZ8Nsfj3ien455PJW2V7RaGXuCi6ZM414dwJlvlLi3QnMOnMO5/73jH1Ku90Te3DRoOlM6DGRWFcsX277nIcW3U9eRS7dE3vQI/Ewvt3xNQ5xcO+xD3BczxNaHJcmgijkDwT51+cbeOjjHwkEDf07JXDvmUMZflj0XQ0cNEFKqksoqMynsLKAUl8pDnFQXFVMQWU+VYFKqgJVVPorKfOVUeYrpdxXTpmvlLLa/8so95VRFWi7O6UnehLpndKXsV2OomtCV1JjOtC/wwDSYzNqSyWrcldy+5e3sCXkzPLmsbdx7sBp7CrbxV1f3cbiXQsBSItN568T/tHgGeVnWz7hd59eT5+Uvpze7yx+yFnO7vJdJHoS6ZF4GP07DKB/h4Gkeq19SEQIBANUBaqoDlTVXmxYV4wrloy4jpRUFVPhryDOLmW5HE7KfeW4HC5iXLG4HW4q/BVUB6pI9qbULt/paN4JjDGGgPFTFaimOlCF4CDJm0R1oJpyXxkepweP04vb4W60dFfpr2BbyTYKKwsIEsQpTrYWbyG3IpeA8dMxrhOHJfWkZ1Iv0mLTERGMMTyw8O+8tvplzhlwHitzV7IqbwWd4juzu2wXvZIz8Ti9xDi9nDXgvHrv+Lu9ZBu/+eia2u801hXLn8b/jYmHHd+s7VCXJoIotmxrITe8voxNeWWIwCVH9eKmnw0g3uuKdGgHJX/Qhz8YoMJfTmFloZVcqgoprS6hpLqEUl8ppdUltQeFnPI9GAxuh5tKfyUV/gqqAlW4HC48TjcuhxuPw2rHKfeXsbkom/zKfPxBf21JoS6nOEn0JOF1ethdvhuwrtu4bNhVeBwejuk+Ya8D3Oq8lSzcuYBT+/yc9NiGqwkr/ZWc+PoEKutcE9JWBMFgHY+SPEkEjaHUV0KiJxGPw0PABAmaACKCU5w4xInT4cSBA1/QR3WgqvbgX7OcGg5x7FMqdDlcdIrrjC9YTVFVMcneJFwON76Aj+pgNcVVRfsspyEd4zrSN7UfueW5rCtYC8ATP3uGGFcsv/7wSsp8pQA8efKzjOw8er/Lqw5Us2DndyzdvZhTep9G39T+TYqjMZoIolylL8BDH//Iv7/cSCBo6JYSy59PH8xxAzpGOjTVAGMM+ZV5rMj5gUW7FlBYVcjusp2sL/iR4uri2umSPEmc1mcKVw+/lnh3/AGv94UVz/Lhpvfo32EggzOGcFhSL0qri9lUtIl1+WtYl7+Wcl85xv7ncrjw2mfXDT3LorS6hNyKHBI9ScS54ym3S1f+oJ9YdxxBE6DSX4kv6MPr9OJyuFrUDhTKKS68Tg9up4dAMECprwS3w028O6E2aTSUaEOX0S2xO2kxHXA6XFQHqumW2I3O8V1xioOdZTvZUpzNpsJNlPpKaudL9qZwTda1nD3wPMAqtd36+e8Y1WUMdxz9xwP6XAdCE4ECYMWOIm55ezkrdlgHkhMP78TNJw+gfye96vdg4gv4KK4uorS6lM4JXfA6vZEOqVUEgoHa3jD5lXk4xUWiJ5GS6hL8QR8OceAQJ2AImACBYICgCRIwgdrqHq/Tg9vh2ac6yR/04RTXXiWlSn8lu8p24HF6SfamUFxVRNAE7aTmIskuIexP0ATZWLiBXWU78Tg9DEofsk9SrjnORrKjgSYCVcsfCPLcN9k88OE6KnwBHAJnjejODSf2p2tK0xonlVIHH00Eah97Sip59JP1vLZgC/6gweNycMlRPfnVsX1JbcfXHiilWkYTgWpQdm4Z9324lneXW08LTYxxcem4TC45qle7vhhNKdU8mgjUfv2wvYi/v7eGL9fnAhDjdnD+qMO4bHwmPVrpOclKqcjRRKCabP6mPJ74fAOfrrXuA+R0CJOHdOGKCb0Z3FWfXazUwUoTgWq21TuLeeqLjcxevoNA0NpHjuqdxuXHZHJs/wxcTr1lsVIHE00EqsW2FZTz3NfZzFy4hbJq68rR9AQvk4d24fSsbgzrntxu772jlPqJJgJ1wIoqfMxcuIXXFmwhO6+8dnjPDnFMzerKlGHd6NsxIYIRKqUao4lAtRpjDD9sL2LWsh38b/kOckp+uvfOoK5JnJ7VjclDu9AlWa9JUKo90USgwiIQNHy3MY//fr+deSt2UVJpPYVMBMZmduDUwV04uk8afTIStPpIqQjTRKDCrtIX4LN1Ofx32XY+XrOHav9PN/hKT/ByZO8OHNk7jaN6p9E7PV4Tg1JtTBOBalPFlT7eX7mLz9fl8N3GfHJL9751c0ailyMz0ziqTxpHZnYgUxODUmGniUBFjDGGDTllfLsxj+825jF/Ux65pdV7TdMpyUoMR/a2/nqlxWliUKqVaSJQ7YYxhvV7SvluYx7fbcrnu4155JXtnRg6xHs4oksSg7om2f8nk5kej9OhySFcjDGs2VVC344JuPUakUOSJgLVbhlj+LEmMdjJIb9OYgCIdTsZ2DmRQV2T6J2RQGZaPL3S4+meGqsHrgNUUFbNzf9ZzoerdnPm8G48cO6+D1pXkWWM4a0l2/j50K4tfuSsJgJ10DDGsKOokpU7ili5o5iVO4pZtaOIHUWV9U7vdAg9UmPpZSeGzLR4eqbFkZkeT7eU2Ki9AvrzdTk8/eVG7p46mMz0hh9YU+kLMPWxr1m723qwigh8+NsJ9O2oz6hoT/6zZBs3vvk9I3um8tZVR7Wo6rSxRKDPK1TtiojQLSWWbimx/OyIzrXDC8qqWbWzmNU7i9mUV0Z2bhnZeeXsKKogO6/cushtXc5ey3I7hR6pcfSyk0PXlFg6J8fQJSmGzskxdEqKOSRLE2t3lXDNK4sprw7wj/fX8PgFIxuc9m/vrWHt7hJ6p8czoHMi81bs4rFPN/DgeVoqaC92F1cy438rATh/dI+wtJ9pIlAHhdR4D+P6pjOu797P3K30BdiaX16bHDblldtJooydRZVszC1jY279jz0UgYwEL12SY+iSbCeJ5Bg6J8XUJo1OiTF4XAdPssgtreKKlxZRbt8OZN7KXWzMKaV3xr5Xfb++cAvPf5ONyyE8cv5wkuPcfLhqN//9fju/mtiHfvrkuharqA7w9/fX0CHewzkje9A5OabFy/nt68sorvRz/ICOnD2ieytHatGqIXXIqqgOsDnfKjlszS9nZ1Elu4oq2FFUya6iSvaUVBLcz+4vAmnxXjomeslI9JKeYP2fkeAlPcFDRqI1Lj3BS3KsO2K9nQJBw/bCCn796hJ+2F7EkG7J9M1I4J1l2zltSBf+ftZQ4r3WeV9OSRUPfLSO1xZsAeC2UwZy5YQ+ANw+6wdenr+FsZkdmHnFkdp7q4X+9O4qnvl6EwBel4PnfzmGo3qnNWsZ+WXVXPnSIhZtLiAt3sPc68bTKallCQW0jUCpevkCQXJKqthZVMnOogp2FVXaSaLCHta0ZFHD7RTS4r2kxLlJjfOQGucmOc5DSqyblDg3ybFuUmKtYbWvY93Eup04Wtgjav2eUl6Zv5n/LN1OUYX1MPaeHeJ46+qjKa3yc+KDnxMIGmLdTtISPASDhtzSaqoDQdxO4c9TB3Pe6MNql1dU4eP4+z8jr6ya647vy5UT+pDg1YqD5liUnc85T32LQ4QjMzvw9YY8OifFMO+68U16+p8xhs/W5XDLf5azu7iKrskxvHjp2AO+l5cmAqVayB8IklNaRU5JFbn2/zmlVeSWVFvDS6vILbGGl1T5W7yeGLeDOI+LeI+TxBg3CTEuEr0uErwuEmNcJMS4SfS6iPc6qfAF2VVUwQ/bi1iypbB2GR0TvQzqmsQfpwzmsA7Ww4S+WJfDw5/8yOLNBXut78TDO/K7nw1gYOekfWJ5Z+k2bnjj+9r3iV4XSXbSSop10SHOQ4d4D2kJXtLiPaTGe0iwY42v+d/jJN7rwutyRFWpoqjCx+RHv2RrQQW/ntiHG07sz3n//o7Fmws4qnca/7pgBClx+yaDYNCwJb+crzbk8vbibSzdan2vo3ul8vB5w1vleeKaCJRqA5W+ALmlVRSW+ygor6ag3EdRhY+iimqKKnwUlvsorLCH2eMKK6qp9AX3v/AGxLqdnJ7VlQvG9mRwt4YfHJRXWmW1GwjWAT3G3ehy31u5i2e/2sTCzfkcyCHC5ZCfkoPXSbzHShZxHiexbiexHicxbut1nMd6X5MQa17XTBfrdu712u2UdpVk/IEgv3p1CR+s2s3grkm8fc3ReF1OthaUc/pjX5NXVk23lFgmDsjAHzBsLSinoNxHcYWP3NIqqkJuy5Ia5+bqY/tw2bjMVuv5polAqXYsGDRU+YOUVfspq/JTUuWnpNJPaaWf0iofJZXWMOu9v7aap1/HBEb16rDfg/qBCAQNpVV+O6FZf/ll1eSXVZFfVk1uaTUF5dWUVlmxl1UFaj9HWVWA6kDLk9z+OB1CnNtJjJ0YYtwO3E4HHqcDjyvkf5c93P7fW/ta8Licta+9TgfukPncdZcTMt5rjw8YQ15pFd9vK+KFb7NZv6eUxBgXc34zvrZUBtZzPa5+eTErdhQ3+Hk6JXkZ2j2Fkw7vxGlDutS26bQWTQRKqYio9gcpq/JTWpsc/JRWBajwBaistv6v8AWoqA5QXu2nrLrmdYAKn9/6356u0lcz3HrtC7S/Y1eP1FjuPWsoR/dJ32dctT/I/E15rNtditsp9EyLJy3eQ7LdphTutpiIXUcgIpOAhwEn8LQx5m91xnuBF4GRQB5wnjEmO5wxKaXajnVG7mlSI2lz+QLBvRJKpS9IdSBItf+n/30172uGNTTc/n/v4cb+30o6NcN9gSBV9vQOgdQ4DwM6JTKubzqnZ3VrsLuxx+VgfL8MxvfLaPVtcaDClghExAk8BpwEbAMWishsY8yqkMkuAwqMMX1F5HzgXuC8cMWklDp0uJ1W9Uw4q8aiRTivlBkDrDfGbDTGVAMzgal1ppkKvGC/fgs4QdpT649SSkWBcCaCbsDWkPfb7GH1TmOM8QNFwD5XXYjIlSKySEQW5eTk1B2tlFLqABwU184bY54yxowyxozKyGh/9WtKKXUwC2ci2A70CHnf3R5W7zQi4gKSsRqNlVJKtZFwJoKFQD8RyRQRD3A+MLvONLOBS+zXZwOfmIOtP6tSSh3kwtZryBjjF5Frgfexuo8+a4xZKSJ3A4uMMbOBZ4CXRGQ9kI+VLJRSSrWhsF5HYIyZC8ytM+zOkNeVwDnhjEEppVTjDorGYqWUUuFz0N1iQkRygM0tmDUdyG3lcFqDxtU87TUuaL+xaVzN017jggOLracxpt5ulwddImgpEVnU0H02Iknjap72Ghe039g0ruZpr3FB+GLTqiGllIpymgiUUirKRVMieCrSATRA42qe9hoXtN/YNK7maa9xQZhii5o2AqWUUvWLphKBUkqpemgiUEqpKHfIJwIRmSQia0VkvYjcEsE4eojIpyKySkRWisj19vAZIrJdRJbZf6dGKL5sEfnBjmGRPayDiHwoIj/a/6e2cUwDQrbLMhEpFpHfRmKbicizIrJHRFaEDKt3+4jlEXufWy4iIyIQ2z9EZI29/ndEJMUe3ktEKkK23RNtHFeD352I3Gpvs7UicnIbx/V6SEzZIrLMHt6W26uhY0T49zNjzCH7h3WPow1Ab8ADfA8cEaFYugAj7NeJwDrgCGAG8Lt2sK2ygfQ6w/4O3GK/vgW4N8Lf5S6gZyS2GTABGAGs2N/2AU4F5gECHAnMj0BsPwNc9ut7Q2LrFTpdBOKq97uzfwvfA14g0/7dOtsqrjrj7wfujMD2augYEfb97FAvETTlKWltwhiz0xizxH5dAqxm3wf1tDehT5B7ATg9grGcAGwwxrTkqvIDZoz5AuvGiKEa2j5TgReN5TsgRUS6tGVsxpgPjPWwJ4DvsG4D36Ya2GYNmQrMNMZUGWM2Aeuxfr9tGpeICHAu8Fo41t2YRo4RYd/PDvVE0JSnpLU5EekFDAfm24OutYt2z7Z19UsIA3wgIotF5Ep7WCdjzE779S6gU2RCA6w704b+ONvDNmto+7S3/e5SrDPHGpkislREPheR8RGIp77vrr1ss/HAbmPMjyHD2nx71TlGhH0/O9QTQbsjIgnA28BvjTHFwL+APkAWsBOrWBoJxxhjRgCnAL8WkQmhI41VFo1IX2OxnmcxBXjTHtRetlmtSG6fxojIHwA/8Io9aCdwmDFmOHAj8KqIJLVhSO3uu6tjGnufcLT59qrnGFErXPvZoZ4ImvKUtDYjIm6sL/gVY8x/AIwxu40xAWNMEPg3YSoO748xZrv9/x7gHTuO3TVFTfv/PZGIDSs5LTHG7LZjbBfbjIa3T7vY70RkOjAZuMA+gGBXveTZrxdj1cX3b6uYGvnuIr7NxHpKpXvr4wAAAw9JREFU4pnA6zXD2np71XeMoA32s0M9ETTlKWltwq57fAZYbYx5IGR4aJ3eGcCKuvO2QWzxIpJY8xqroXEFez9B7hLgv20dm22vs7T2sM1sDW2f2cDFdq+OI4GikKJ9mxCRScDNwBRjTHnI8AwRcdqvewP9gI1tGFdD391s4HwR8YpIph3XgraKy3YisMYYs61mQFtur4aOEbTFftYWreGR/MNqWV+Hlcn/EME4jsEq0i0Hltl/pwIvAT/Yw2cDXSIQW2/+v727Z40iigIw/B6iRVAIGsFGJIWpxI8ilaWdhZVFECtJYwqxEgtbKyuJBkQL9V+IGkEEBQsxSgpRxC5CUigIEkI4FvcG1nUXE0h2gvM+sOzs2WG4c3fYM3Nn5ky5YmMeWFjvJ2AUmAM+Ac+A/Q20bQ/lOdYjHbGB9xklES0Cq5Sx2Kl+/UO5imO2bnMfgIkG2vaZMn68vq3drfOeq7/xO+AtcHbA7er72wHXa599BM4Msl01/hC41DXvIPur33/Etm9nlpiQpJb734eGJEn/YCKQpJYzEUhSy5kIJKnlTASS1HImAqlLRKzFn1VPt6xqba1m2dR9D1JPu5pugLQD/crMk003QhoUjwikDap16m9GeW7Dm4g4UuNjEfG8FlKbi4jDNX4wyrMA5uvrVF3UUETcrzXnn0TEcGMrJWEikHoZ7hoamuz47kdmHgPuALdq7DbwKDOPU4q7zdT4DPAiM09Q6t8v1Pg4MJuZR4HvlLtXpcZ4Z7HUJSJ+ZubeHvGvwOnM/FKLg33LzNGIWKaUSlit8cXMPBARS8ChzFzpWMYY8DQzx+vna8DuzLyx/Wsm9eYRgbQ52Wd6M1Y6ptfwXJ0aZiKQNmey4/11nX5FqWwLcAF4WafngGmAiBiKiJFBNVLaDPdEpL8NR314efU4M9cvId0XEe8pe/Xna+wy8CAirgJLwMUavwLci4gpyp7/NKXqpbSjeI5A2qB6jmAiM5ebbou0lRwakqSW84hAklrOIwJJajkTgSS1nIlAklrORCBJLWcikKSW+w0NfvSoJrikUgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# allowing empty intervals\n",
        "alpha = 0.1\n",
        "\n",
        "coverage_CES = []\n",
        "size_CES = []\n",
        "\n",
        "C_PI = Conformal_PI(mod, device, calib_loader, alpha)\n",
        "\n",
        "for input, response in tqdm(test_loader):\n",
        "  # find the best models\n",
        "  best_models = CES_reg.select_model(input)\n",
        "  # do ICP using the best models\n",
        "  CESPI = C_PI.CES_icp(input, best_models, method = 'union')\n",
        "  # compute the size of the prediction interval\n",
        "  size_single = sum([intv._measure for intv in CESPI])\n",
        "  # compute the coverage of the prediction interval\n",
        "  coverage_single = sum([response in intv for intv in CESPI]) > 0\n",
        "  coverage_CES.append(coverage_single)\n",
        "  size_CES.append(size_single)\n",
        "  # print(coverage_single)\n",
        "  # print(size_single)\n",
        "  # print('average coverage: {}'.format(sum(coverage_CES)/len(coverage_CES)))\n",
        "  # print('average size: {}'.format(sum(size_CES)/len(size_CES)))\n",
        "\n",
        "print('seed {}'.format(seed))\n",
        "print(sum(coverage_CES)/len(coverage_CES))\n",
        "print(sum(size_CES)/len(size_CES))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrVWSupOwDi6",
        "outputId": "1ade1fb3-18c1-4b38-bc21-76260d40c929"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.502753257751465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|‚ñè         | 2/100 [00:48<39:46, 24.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.92698836326599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|‚ñé         | 3/100 [01:13<39:33, 24.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.48019313812256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|‚ñç         | 4/100 [01:37<38:43, 24.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.72367238998413\n",
            "elapse time (selecting best models):23.927976846694946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|‚ñå         | 6/100 [02:26<38:21, 24.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.89662790298462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|‚ñã         | 7/100 [02:51<38:10, 24.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.752416133880615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|‚ñä         | 8/100 [03:15<37:30, 24.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.907259225845337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|‚ñâ         | 9/100 [03:39<37:04, 24.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.227741479873657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|‚ñà         | 10/100 [04:04<36:36, 24.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.172003269195557\n",
            "elapse time (selecting best models):24.11321473121643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|‚ñà         | 11/100 [04:28<36:11, 24.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.18523073196411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|‚ñà‚ñè        | 12/100 [04:53<35:47, 24.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.02079200744629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|‚ñà‚ñç        | 14/100 [05:41<35:03, 24.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.449467182159424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|‚ñà‚ñå        | 15/100 [06:06<34:44, 24.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.604501247406006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|‚ñà‚ñå        | 16/100 [06:31<34:20, 24.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.414260625839233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|‚ñà‚ñã        | 17/100 [06:55<33:54, 24.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.315541982650757\n",
            "elapse time (selecting best models):24.417768001556396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|‚ñà‚ñâ        | 19/100 [07:44<33:00, 24.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.164339065551758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|‚ñà‚ñà        | 20/100 [08:09<32:44, 24.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.639827013015747\n",
            "elapse time (selecting best models):24.694446086883545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|‚ñà‚ñà        | 21/100 [08:34<32:30, 24.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.39753246307373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|‚ñà‚ñà‚ñé       | 23/100 [09:23<31:36, 24.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.40596914291382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|‚ñà‚ñà‚ñç       | 24/100 [09:47<31:09, 24.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.329864025115967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|‚ñà‚ñà‚ñå       | 25/100 [10:12<30:38, 24.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.27389931678772\n",
            "elapse time (selecting best models):24.380237817764282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|‚ñà‚ñà‚ñå       | 26/100 [10:36<30:16, 24.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.443968772888184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|‚ñà‚ñà‚ñã       | 27/100 [11:01<29:56, 24.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.992445945739746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|‚ñà‚ñà‚ñâ       | 29/100 [11:50<28:52, 24.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.10011315345764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|‚ñà‚ñà‚ñà       | 30/100 [12:15<28:42, 24.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.981358528137207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|‚ñà‚ñà‚ñà       | 31/100 [12:40<28:25, 24.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.76607322692871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [13:04<28:00, 24.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.586087226867676\n",
            "elapse time (selecting best models):24.27868127822876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [13:53<26:57, 24.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.98800826072693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [14:17<26:25, 24.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.031550407409668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [14:42<26:08, 24.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.751052379608154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [15:06<25:38, 24.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.02620840072632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [15:30<25:07, 24.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.000014543533325\n",
            "elapse time (selecting best models):24.290215492248535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [16:19<24:24, 24.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.260059356689453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [16:43<23:55, 24.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.034814596176147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [17:08<23:29, 24.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.121254682540894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [17:31<22:57, 24.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.80374002456665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [17:56<22:36, 24.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.206573963165283\n",
            "elapse time (selecting best models):24.228748083114624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [18:45<21:51, 24.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.14400053024292\n",
            "elapse time (selecting best models):24.282269716262817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [19:34<21:09, 24.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.33076286315918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [19:59<20:53, 24.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.80866575241089\n",
            "elapse time (selecting best models):24.609957933425903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [20:48<20:12, 24.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.744778156280518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [21:13<19:49, 24.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.665689945220947\n",
            "elapse time (selecting best models):24.24122405052185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [22:02<18:47, 24.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.99919319152832\n",
            "elapse time (selecting best models):23.81133270263672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [22:26<18:16, 24.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.788430213928223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [22:50<17:47, 24.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.88164734840393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [23:14<17:22, 24.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.714996337890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [24:02<16:28, 24.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.78829073905945\n",
            "elapse time (selecting best models):23.730052709579468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [24:50<15:35, 24.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.653462886810303\n",
            "elapse time (selecting best models):23.811094522476196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [25:14<15:12, 24.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.224207401275635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [26:03<14:36, 24.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.6548011302948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [26:27<14:08, 24.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.94181728363037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [26:51<13:44, 24.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.09352207183838\n",
            "elapse time (selecting best models):24.035791873931885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [27:40<12:53, 24.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.82932758331299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [28:04<12:30, 24.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.122825860977173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [28:28<12:05, 24.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.021000862121582\n",
            "elapse time (selecting best models):23.91539478302002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [28:52<11:41, 24.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.933427333831787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [29:41<10:52, 24.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.026337385177612\n",
            "elapse time (selecting best models):24.230488777160645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [30:29<10:03, 24.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.84918451309204\n",
            "elapse time (selecting best models):24.776118516921997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [31:19<09:23, 24.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.685526609420776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [31:43<09:00, 24.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.657062530517578\n",
            "elapse time (selecting best models):25.948398113250732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [32:10<08:46, 25.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):25.32307243347168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [33:00<07:54, 24.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.357651472091675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [33:25<07:29, 24.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.731438398361206\n",
            "elapse time (selecting best models):25.284408807754517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [34:15<06:41, 25.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.8868248462677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [34:40<06:16, 25.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):25.007867336273193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [35:05<05:50, 25.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.71243453025818\n",
            "elapse time (selecting best models):24.9071147441864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [35:30<05:26, 25.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):25.42593026161194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [36:21<04:36, 25.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.75557017326355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [36:46<04:11, 25.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.91109347343445\n",
            "elapse time (selecting best models):24.683347463607788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [37:11<03:45, 25.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.324782848358154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [38:00<02:53, 24.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.375710487365723\n",
            "elapse time (selecting best models):24.264711618423462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [38:25<02:28, 24.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.494967937469482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [38:50<02:03, 24.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.106484174728394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [39:38<01:13, 24.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.99971103668213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [40:02<00:48, 24.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.027642965316772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [40:26<00:24, 24.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.01591968536377\n",
            "elapse time (selecting best models):24.660690307617188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [40:51<00:00, 24.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed 233\n",
            "0.91\n",
            "1.33746396950654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not allowing for empty intervals\n",
        "alpha = 0.1\n",
        "\n",
        "coverage_CES = []\n",
        "size_CES = []\n",
        "\n",
        "C_PI = Conformal_PI(mod, device, calib_loader, alpha)\n",
        "\n",
        "for input, response in tqdm(test_loader):\n",
        "  # find the best models\n",
        "  best_models = CES_reg.select_model(input)\n",
        "  # do ICP using the best models\n",
        "  CESPI = C_PI.CES_icp(input, best_models, method = 'union', no_empty = True, mod = CES_reg)\n",
        "  # compute the size of the prediction interval\n",
        "  size_single = sum([intv._measure for intv in CESPI])\n",
        "  # compute the coverage of the prediction interval\n",
        "  coverage_single = sum([response in intv for intv in CESPI]) > 0\n",
        "  coverage_CES.append(coverage_single)\n",
        "  size_CES.append(size_single)\n",
        "  # print(coverage_single)\n",
        "  # print(size_single)\n",
        "  # print('average coverage: {}'.format(sum(coverage_CES)/len(coverage_CES)))\n",
        "  # print('average size: {}'.format(sum(size_CES)/len(size_CES)))\n",
        "\n",
        "print('seed {}'.format(seed))\n",
        "print(sum(coverage_CES)/len(coverage_CES))\n",
        "print(sum(size_CES)/len(size_CES))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHGyN2pdv9n7",
        "outputId": "dd98e2dc-6502-4322-932b-07629bf09720"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.42138934135437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2it [00:49, 24.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.32201313972473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [01:13, 24.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.149508953094482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [01:37, 24.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.166152715682983\n",
            "elapse time (selecting best models):24.31527590751648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6it [02:26, 24.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.04364037513733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [02:50, 24.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.01366400718689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [03:14, 24.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.363300800323486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [03:37, 23.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.478981494903564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [04:01, 23.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.576066255569458\n",
            "elapse time (selecting best models):23.56976008415222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [04:25, 23.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.709135055541992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [04:49, 23.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.939732789993286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14it [05:37, 23.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.482287883758545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [06:00, 23.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.416670322418213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [06:24, 23.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.530170917510986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [06:48, 23.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.59208869934082\n",
            "elapse time (selecting best models):23.486912965774536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19it [07:35, 23.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.53239130973816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20it [07:58, 23.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.33541440963745\n",
            "elapse time (selecting best models):23.306163549423218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [08:22, 23.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.344200134277344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23it [09:09, 23.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.282171964645386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r24it [09:32, 23.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.267483949661255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r25it [09:56, 23.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.55085849761963\n",
            "elapse time (selecting best models):23.732519388198853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r26it [10:20, 23.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.662318468093872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r27it [10:44, 23.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.043187379837036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "29it [11:32, 23.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.79392647743225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r30it [11:56, 23.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.47006583213806\n",
            "elapse time (selecting best models):23.485605478286743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [12:43, 23.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.341874837875366\n",
            "elapse time (selecting best models):23.377331733703613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "34it [13:30, 23.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.358050107955933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r35it [13:53, 23.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.287320375442505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r36it [14:17, 23.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.664689302444458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r37it [14:41, 23.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.374460220336914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r38it [15:04, 23.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.652878046035767\n",
            "elapse time (selecting best models):23.88084101676941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [15:52, 23.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.47573709487915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r41it [16:16, 23.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.44873070716858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r42it [16:39, 23.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.516021490097046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r43it [17:03, 23.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.336992979049683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r44it [17:26, 23.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.496173620224\n",
            "elapse time (selecting best models):23.28065800666809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "46it [18:13, 23.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.3016517162323\n",
            "elapse time (selecting best models):23.295066356658936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [19:00, 23.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.28181481361389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r49it [19:24, 23.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.27585196495056\n",
            "elapse time (selecting best models):23.611230850219727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "51it [20:11, 23.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.49220848083496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r52it [20:35, 23.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.64350724220276\n",
            "elapse time (selecting best models):23.928760051727295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "54it [21:23, 23.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.83857011795044\n",
            "elapse time (selecting best models):24.012101411819458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r55it [21:47, 23.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.961899518966675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r56it [22:12, 24.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.649477243423462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r57it [22:36, 24.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.788014888763428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "59it [23:23, 23.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.670955419540405\n",
            "elapse time (selecting best models):23.84453248977661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [24:12, 23.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.759474992752075\n",
            "elapse time (selecting best models):23.883318662643433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r62it [24:36, 24.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.715240478515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [25:24, 24.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.136167526245117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r65it [25:48, 24.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.961143493652344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r66it [26:12, 24.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.975937604904175\n",
            "elapse time (selecting best models):23.851511478424072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r67it [26:36, 24.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.683390855789185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "69it [27:24, 24.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.766356945037842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r70it [27:48, 23.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.900752067565918\n",
            "0.11996455639600753\n",
            "./content/model184.pth\n",
            "avoided empty interval, final pi is [Interval(-2.85826325416565, 3.33703494071960)]\n",
            "elapse time (selecting best models):24.08921527862549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r71it [28:12, 24.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.931687116622925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "73it [29:00, 24.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.87274742126465\n",
            "elapse time (selecting best models):23.914393663406372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "75it [29:49, 24.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.905778169631958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r76it [30:13, 24.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.33964228630066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r77it [30:37, 24.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.103862524032593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r78it [31:02, 24.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.44200849533081\n",
            "elapse time (selecting best models):24.33996033668518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r79it [31:26, 24.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.21416687965393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "81it [32:15, 24.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.172157526016235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r82it [32:40, 24.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.387973308563232\n",
            "elapse time (selecting best models):24.1908438205719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "84it [33:29, 24.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.402177810668945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r85it [33:53, 24.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.353809118270874\n",
            "0.11996455639600753\n",
            "./content/model184.pth\n",
            "avoided empty interval, final pi is [Interval(-2.86087822914124, 3.33441996574402)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r86it [34:18, 24.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.269078969955444\n",
            "elapse time (selecting best models):24.11678123474121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "88it [35:06, 24.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.105542182922363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r89it [35:31, 24.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.453436851501465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r90it [35:55, 24.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.089346885681152\n",
            "elapse time (selecting best models):24.62543559074402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r91it [36:20, 24.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):24.354917526245117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "93it [37:08, 24.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.63493013381958\n",
            "elapse time (selecting best models):23.56989336013794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r94it [37:32, 24.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.53272581100464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r95it [37:56, 24.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.517109155654907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r96it [38:20, 24.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.325227737426758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "98it [39:07, 23.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.470550775527954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r99it [39:31, 23.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.467724084854126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [39:54, 23.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapse time (selecting best models):23.548448085784912\n",
            "seed 233\n",
            "0.93\n",
            "1.46136993340425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7vXcdOIwOhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n05m17yHvyUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8iWRBvfRicH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}