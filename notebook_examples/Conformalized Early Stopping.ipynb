{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "89c990a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af907b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Colors from Colorbrewer Paired_12\n",
    "colors = [[31, 120, 180], [51, 160, 44], [250,159,181]]\n",
    "colors = [(r / 255, g / 255, b / 255) for (r, g, b) in colors]\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img, norm):\n",
    "    \"\"\"\n",
    "    :param img: (PyTorch Tensor)\n",
    "    \"\"\"\n",
    "    if norm:\n",
    "        # unnormalize\n",
    "        img = img / 2 + 0.5    \n",
    "        \n",
    "    # Convert tensor to numpy array\n",
    "    npimg = img.numpy()\n",
    "    # Color channel first -> color channel last\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def get_image(img):\n",
    "    \"\"\"\n",
    "    convert a tensor to images suitable for plotting\n",
    "    :param img: (PyTorch Tensor)\n",
    "    \"\"\"\n",
    "    # unnormalize\n",
    "    img = img / 2 + 0.5     \n",
    "    # Convert tensor to numpy array\n",
    "    npimg = img.numpy()\n",
    "    # Color channel first -> color channel last\n",
    "    return np.transpose(npimg, (1, 2, 0))\n",
    "\n",
    "def plot_loss_acc(train_loss, val_loss, train_acc, val_acc):\n",
    "    x = np.arange(1, len(train_loss) + 1)\n",
    "\n",
    "    fig,axs = plt.subplots(1, 2, figsize=(16,6))\n",
    "    axs[0].plot(x, train_loss, color=colors[0], label=\"Training loss\", linewidth=2)\n",
    "    axs[0].plot(x, val_loss, color=colors[1], label=\"Validation loss\", linewidth=2)\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend(loc='upper right')\n",
    "    axs[0].set_title(\"Evolution of the training, validation and test loss\")\n",
    "\n",
    "    axs[1].plot(x, train_acc, color=colors[0], label=\"Training accuracy\", linewidth=2)\n",
    "    axs[1].plot(x, val_acc, color=colors[1], label=\"Validation accuracy\", linewidth=2)\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].legend(loc='lower right')\n",
    "    axs[1].set_title(\"Evolution of the training, validation and test accuracy\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_loss(train_loss, val_loss):\n",
    "    x = np.arange(1, len(train_loss) + 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, train_loss, color=colors[0], label=\"Training loss\", linewidth=2)\n",
    "    plt.plot(x, val_loss, color=colors[1], label=\"Validation loss\", linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Evolution of the training, validation and test loss\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_pvals(pvals, labels):\n",
    "    idx_in = np.where(labels==0)[0]\n",
    "    idx_out = np.where(labels==1)[0]\n",
    "\n",
    "    pvals_in = np.array(pvals)[idx_in]\n",
    "    pvals_out = np.array(pvals)[idx_out]\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.hist(pvals_in, bins=100, alpha=0.5, label=\"inliers\")\n",
    "    plt.hist(pvals_out, bins=100, alpha=0.5, label=\"outliers\")\n",
    "    plt.legend()\n",
    "    plt.show\n",
    "\n",
    "    print('Average p-value for inliers is {:3f}, average p-value for outliers is {:3f}.'\\\n",
    "          .format(np.mean(pvals_in), np.mean(pvals_out)))\n",
    "    \n",
    "\n",
    "def evaluate_bh(pvals, labels, alpha):\n",
    "    idx_in = np.where(labels==0)[0]\n",
    "    idx_out = np.where(labels==1)[0]\n",
    "    \n",
    "    # Apply BH\n",
    "    purity_test = len(idx_in)/len(pvals)\n",
    "    reject, _, _, _ = multipletests(pvals, alpha=alpha/(1-purity_test), method='fdr_bh')\n",
    "\n",
    "    # Evaluate FDP and Power\n",
    "    rejections = np.sum(reject)\n",
    "    if rejections > 0:\n",
    "        fdp = np.sum(reject[idx_in])/reject.shape[0] \n",
    "        power = np.sum(reject[idx_out])/len(idx_out)\n",
    "    else:\n",
    "        fdp = 0\n",
    "        power = 0\n",
    "    return fdp, power\n",
    "\n",
    "def evaluate_predictions(S, y):\n",
    "    coverage = np.mean([y[i] in S[i] for i in range(len(y))])\n",
    "    length = np.mean([len(S[i]) for i in range(len(y))])\n",
    "    idx_cover = np.where([y[i] in S[i] for i in range(len(y))])[0]\n",
    "    length_cover = np.mean([len(S[i]) for i in idx_cover])\n",
    "    return coverage, length, length_cover\n",
    "\n",
    "def evaluate_marginal(S, y):\n",
    "    coverage, length, length_cover = evaluate_predictions(S, y)\n",
    "    print('Marginal coverage:       {:2.3%}'.format(coverage))\n",
    "    print('Average size:            {:2.3f}'.format(length))\n",
    "    print('Average size | coverage: {:2.3f}'.format(length_cover))\n",
    "\n",
    "def evaluate_conditional(S, y):\n",
    "    n_class = len(np.unique(y))\n",
    "    for i in range(n_class):\n",
    "        label = i\n",
    "        idx = np.where(y==label)[0]\n",
    "        coverage, length, length_cover = evaluate_predictions(np.array(S, dtype=object)[idx], np.array(y)[idx])\n",
    "        print('Conditional coverage for label {}:       {:2.3%}'.format(classes[label], coverage))\n",
    "        print('Average size:            {:2.3f}'.format(length))\n",
    "        print('Average size | coverage: {:2.3f}'.format(length_cover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8f3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import sys, os\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "sys.path.append('../ConformalizedES')\n",
    "sys.path.append('../third_party')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0b1132",
   "metadata": {},
   "source": [
    "# Experiment 1: CES for anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef027e",
   "metadata": {},
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0c50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST Dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=0.5, std=0.5)])\n",
    "\n",
    "train_set_full = datasets.MNIST(root = \"./data\", train = True, download = True, transform=transform)\n",
    "test_set_full = datasets.MNIST(root = \"./data\", train = False, download = True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd1674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of available training data is: 5923.\n",
      "total number of test data is 1954 in which 980 are label 0 test data, 974 are label 8 test data.\n"
     ]
    }
   ],
   "source": [
    "from datasetMaker import get_class_i, DatasetMaker\n",
    "\n",
    "x_train_full = train_set_full.data\n",
    "y_train_full = train_set_full.targets\n",
    "x_test_full = test_set_full.data\n",
    "y_test_full = test_set_full.targets\n",
    "\n",
    "# Train set composed only of number 0\n",
    "train_set = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train_full, y_train_full, 0)]\n",
    "    )\n",
    "\n",
    "# Test set is a mixture of number 0 and 8\n",
    "test_set = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_test_full, y_test_full, 0),\n",
    "        get_class_i(x_test_full, y_test_full, 8),\n",
    "]\n",
    "    )\n",
    "\n",
    "print('total number of available training data is: {:d}.'.format(len(train_set)))\n",
    "print('total number of test data is {:d} in which {:d} are label 0 test data, {:d} are label 8 test data.'\\\n",
    "      .format(len(test_set), test_set.lengths[0],test_set.lengths[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d79ef3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some sample test data\n",
    "example_loader = th.utils.data.DataLoader(test_set, shuffle=True, batch_size=4, num_workers=0)\n",
    "dataiter = iter(example_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images), norm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86fabe3",
   "metadata": {},
   "source": [
    "### Benchmark data-splitting vs CES data-splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "928a84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "num_workers = 0\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "# MNIST is a simple dataset, hence we only take 300 inlier data to demonstrate\n",
    "# Benchmark data splitting: equally split the data into 3 sets\n",
    "n_full = len(train_set)\n",
    "#n_data = 300\n",
    "n_data = n_train_bm + n_val_bm + n_cal_bm\n",
    "n_train_bm = 100\n",
    "n_val_bm = 100\n",
    "n_cal_bm = 100\n",
    "\n",
    "train_set_bm, val_set_bm, cal_set_bm, _ = th.utils.data.random_split(train_set,\\\n",
    "                                 [n_train_bm, n_val_bm, n_cal_bm, n_full-n_data])\n",
    "\n",
    "# CES data splitting: calibration set is not needed, merge back to the training set\n",
    "n_train_ces = 200\n",
    "n_val_ces = 100\n",
    "\n",
    "train_set_ces, val_set_ces, _ = th.utils.data.random_split(train_set,\\\n",
    "                                 [n_train_ces, n_val_ces, n_full-n_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8c4397fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader objects\n",
    "# For benchmarks\n",
    "batch_size = 10\n",
    "num_workers = 0\n",
    "\n",
    "train_loader_bm = th.utils.data.DataLoader(train_set_bm, batch_size=batch_size,\n",
    "                                          num_workers=num_workers)\n",
    "\n",
    "val_loader_bm = th.utils.data.DataLoader(val_set_bm, batch_size=n_val_bm,\n",
    "                                          num_workers=num_workers)\n",
    "\n",
    "cal_loader_bm = th.utils.data.DataLoader(cal_set_bm, batch_size=n_cal_bm,\n",
    "                                          num_workers=num_workers)\n",
    "\n",
    "# For CES\n",
    "train_loader_ces = th.utils.data.DataLoader(train_set_ces, batch_size=batch_size,\n",
    "                                          num_workers=num_workers)\n",
    "\n",
    "val_loader_ces = th.utils.data.DataLoader(val_set_ces, batch_size=n_val_ces,\n",
    "                                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a44a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loader\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "n_test_samples = 1800\n",
    "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))\n",
    "test_loader = th.utils.data.DataLoader(test_set, batch_size=n_test_samples, sampler=test_sampler,\n",
    "                                         num_workers=num_workers)\n",
    "\n",
    "# get all test images\n",
    "dataiter = iter(test_loader)\n",
    "inputs, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b3078",
   "metadata": {},
   "source": [
    "### Define Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "07df66bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from method import CES_oneClass\n",
    "from networks import ConvAutoencoder\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model parameters\n",
    "\n",
    "lr = 0.1\n",
    "n_epoch = 200\n",
    "\n",
    "# Create loss and optimizer\n",
    "# CES_oneClass object will assume criterion takes three parameters: output, input and target, \n",
    "# create wrapper function to modify the criterion.\n",
    "net_bm = ConvAutoencoder()\n",
    "Loss = th.nn.MSELoss()\n",
    "def criterion(outputs, inputs, targets):\n",
    "    return Loss(outputs, inputs)\n",
    "optimizer_bm = optim.Adam(net_bm.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52421200",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "if th.cuda.is_available():\n",
    "    # Make CuDNN Determinist\n",
    "    th.backends.cudnn.deterministic = True\n",
    "    th.cuda.manual_seed(seed)\n",
    "\n",
    "# Define default device, we should use the GPU (cuda) if available\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")### Define subset of the dataset (so it is faster to train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb336f0e",
   "metadata": {},
   "source": [
    "### Train benchmark models and compute conformal p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13d7f197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 10\n",
      "n_epochs= 200\n",
      "learning_rate= 0.1\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "# Initialize the CES class with model parameters\n",
    "CES_oc_bm = CES_oneClass(net_bm, device, train_loader_bm, batch_size=batch_size, max_epoch=n_epoch, \n",
    "                        learning_rate=lr, val_loader=val_loader_bm, criterion=criterion,optimizer=optimizer_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e7eda8d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 200, 10% \t train_loss: 0.21  took: 0.06s\n",
      "Epoch 1 of 200, 20% \t train_loss: 0.16  took: 0.03s\n",
      "Epoch 1 of 200, 30% \t train_loss: 0.11  took: 0.03s\n",
      "Epoch 1 of 200, 40% \t train_loss: 0.15  took: 0.03s\n",
      "Epoch 1 of 200, 50% \t train_loss: 0.09  took: 0.05s\n",
      "Epoch 1 of 200, 60% \t train_loss: 0.10  took: 0.07s\n",
      "Epoch 1 of 200, 70% \t train_loss: 0.10  took: 0.03s\n",
      "Epoch 1 of 200, 80% \t train_loss: 0.09  took: 0.05s\n",
      "Epoch 1 of 200, 90% \t train_loss: 0.09  took: 0.03s\n",
      "Epoch 1 of 200, 100% \t train_loss: 0.08  took: 0.03s\n",
      "val_loss = 0.08\n",
      "Snapshot saved at epoch 1.\n",
      "Epoch 2 of 200, 10% \t train_loss: 0.08  took: 0.04s\n",
      "Epoch 2 of 200, 20% \t train_loss: 0.07  took: 0.03s\n",
      "Epoch 2 of 200, 30% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 2 of 200, 40% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 2 of 200, 50% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 2 of 200, 60% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 2 of 200, 70% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 2 of 200, 80% \t train_loss: 0.06  took: 0.05s\n",
      "Epoch 2 of 200, 90% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 2 of 200, 100% \t train_loss: 0.06  took: 0.03s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 2.\n",
      "Epoch 3 of 200, 10% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 3 of 200, 20% \t train_loss: 0.07  took: 0.02s\n",
      "Epoch 3 of 200, 30% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 3 of 200, 40% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 3 of 200, 50% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 3 of 200, 60% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 3 of 200, 70% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 3 of 200, 80% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 3 of 200, 90% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 3 of 200, 100% \t train_loss: 0.06  took: 0.03s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 3.\n",
      "Epoch 4 of 200, 10% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 4 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 4 of 200, 30% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 4 of 200, 40% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 4 of 200, 50% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 4 of 200, 60% \t train_loss: 0.06  took: 0.05s\n",
      "Epoch 4 of 200, 70% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 4 of 200, 80% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 4 of 200, 90% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 4 of 200, 100% \t train_loss: 0.06  took: 0.03s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 4.\n",
      "Epoch 5 of 200, 10% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 5 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 5 of 200, 30% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 5 of 200, 40% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 5 of 200, 50% \t train_loss: 0.06  took: 0.01s\n",
      "Epoch 5 of 200, 60% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 5 of 200, 70% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 5 of 200, 80% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 5 of 200, 90% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 5 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 5.\n",
      "Epoch 6 of 200, 10% \t train_loss: 0.06  took: 0.01s\n",
      "Epoch 6 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 6 of 200, 30% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 6 of 200, 40% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 6 of 200, 50% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 6 of 200, 60% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 6 of 200, 70% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 6 of 200, 80% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 6 of 200, 90% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 6 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 6.\n",
      "Epoch 7 of 200, 10% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 7 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 7 of 200, 30% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 7 of 200, 40% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 7 of 200, 50% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 7 of 200, 60% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 7 of 200, 70% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 7 of 200, 80% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 7 of 200, 90% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 7 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 7.\n",
      "Epoch 8 of 200, 10% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 8 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 8 of 200, 30% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 8 of 200, 40% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 8 of 200, 50% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 8 of 200, 60% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 8 of 200, 70% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 8 of 200, 80% \t train_loss: 0.06  took: 0.01s\n",
      "Epoch 8 of 200, 90% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 8 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 8.\n",
      "Epoch 9 of 200, 10% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 9 of 200, 20% \t train_loss: 0.06  took: 0.04s\n",
      "Epoch 9 of 200, 30% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 9 of 200, 40% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 9 of 200, 50% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 9 of 200, 60% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 9 of 200, 70% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 9 of 200, 80% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 9 of 200, 90% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 9 of 200, 100% \t train_loss: 0.05  took: 0.04s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 9.\n",
      "Epoch 10 of 200, 10% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 10 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 10 of 200, 30% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 10 of 200, 40% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 10 of 200, 50% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 10 of 200, 60% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 10 of 200, 70% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 10 of 200, 80% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 10 of 200, 90% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 10 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 10.\n",
      "Epoch 11 of 200, 10% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 11 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 11 of 200, 30% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 11 of 200, 40% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 11 of 200, 50% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 11 of 200, 60% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 11 of 200, 70% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 11 of 200, 80% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 11 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 11 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 11.\n",
      "Epoch 12 of 200, 10% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 12 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 12 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 12 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 12 of 200, 50% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 12 of 200, 60% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 12 of 200, 70% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 12 of 200, 80% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 12 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 12 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 12.\n",
      "Epoch 13 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 13 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 13 of 200, 30% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 13 of 200, 40% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 13 of 200, 50% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 13 of 200, 60% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 13 of 200, 70% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 13 of 200, 80% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 13 of 200, 90% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 13 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 13.\n",
      "Epoch 14 of 200, 10% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 14 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 14 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 14 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 14 of 200, 50% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 14 of 200, 60% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 14 of 200, 70% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 14 of 200, 80% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 14 of 200, 90% \t train_loss: 0.05  took: 0.01s\n",
      "Epoch 14 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 14.\n",
      "Epoch 15 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 15 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 15 of 200, 30% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 15 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 15 of 200, 50% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 15 of 200, 60% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 15 of 200, 70% \t train_loss: 0.05  took: 0.03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 of 200, 80% \t train_loss: 0.06  took: 0.04s\n",
      "Epoch 15 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 15 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 15.\n",
      "Epoch 16 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 16 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 16 of 200, 30% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 16 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 16 of 200, 50% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 16 of 200, 60% \t train_loss: 0.06  took: 0.01s\n",
      "Epoch 16 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 16 of 200, 80% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 16 of 200, 90% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 16 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 16.\n",
      "Epoch 17 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 17 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 17 of 200, 30% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 17 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 17 of 200, 50% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 17 of 200, 60% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 17 of 200, 70% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 17 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 17 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 17 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 17.\n",
      "Epoch 18 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 18 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 18 of 200, 30% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 18 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 18 of 200, 50% \t train_loss: 0.06  took: 0.04s\n",
      "Epoch 18 of 200, 60% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 18 of 200, 70% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 18 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 18 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 18 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 18.\n",
      "Epoch 19 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 19 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 19 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 19 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 19 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 19 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 19 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 19 of 200, 80% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 19 of 200, 90% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 19 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 19.\n",
      "Epoch 20 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 20 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 20 of 200, 30% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 20 of 200, 40% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 20 of 200, 50% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 20 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 20 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 20 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 20 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 20 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.06\n",
      "Snapshot saved at epoch 20.\n",
      "Epoch 21 of 200, 10% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 21 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 21 of 200, 30% \t train_loss: 0.06  took: 0.01s\n",
      "Epoch 21 of 200, 40% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 21 of 200, 50% \t train_loss: 0.06  took: 0.05s\n",
      "Epoch 21 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 21 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 21 of 200, 80% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 21 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 21 of 200, 100% \t train_loss: 0.05  took: 0.01s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 21.\n",
      "Epoch 22 of 200, 10% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 22 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 22 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 22 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 22 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 22 of 200, 60% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 22 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 22 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 22 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 22 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 22.\n",
      "Epoch 23 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 23 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 23 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 23 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 23 of 200, 50% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 23 of 200, 60% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 23 of 200, 70% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 23 of 200, 80% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 23 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 23 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 23.\n",
      "Epoch 24 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 24 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 24 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 24 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 24 of 200, 50% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 24 of 200, 60% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 24 of 200, 70% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 24 of 200, 80% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 24 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 24 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 24.\n",
      "Epoch 25 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 25 of 200, 20% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 25 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 25 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 25 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 25 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 25 of 200, 70% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 25 of 200, 80% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 25 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 25 of 200, 100% \t train_loss: 0.05  took: 0.01s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 25.\n",
      "Epoch 26 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 26 of 200, 20% \t train_loss: 0.06  took: 0.01s\n",
      "Epoch 26 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 26 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 26 of 200, 50% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 26 of 200, 60% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 26 of 200, 70% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 26 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 26 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 26 of 200, 100% \t train_loss: 0.05  took: 0.04s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 26.\n",
      "Epoch 27 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 27 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 27 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 27 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 27 of 200, 50% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 27 of 200, 60% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 27 of 200, 70% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 27 of 200, 80% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 27 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 27 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 27.\n",
      "Epoch 28 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 28 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 28 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 28 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 28 of 200, 50% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 28 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 28 of 200, 70% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 28 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 28 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 28 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 28.\n",
      "Epoch 29 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 29 of 200, 20% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 29 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 29 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 29 of 200, 50% \t train_loss: 0.06  took: 0.02s\n",
      "Epoch 29 of 200, 60% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 29 of 200, 70% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 29 of 200, 80% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 29 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 29 of 200, 100% \t train_loss: 0.05  took: 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 29.\n",
      "Epoch 30 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 30 of 200, 20% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 30 of 200, 30% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 30 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 30 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 30 of 200, 60% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 30 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 30 of 200, 80% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 30 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 30 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 30.\n",
      "Epoch 31 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 31 of 200, 20% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 31 of 200, 30% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 31 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 31 of 200, 50% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 31 of 200, 60% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 31 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 31 of 200, 80% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 31 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 31 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 31.\n",
      "Epoch 32 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 32 of 200, 20% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 32 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 32 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 32 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 32 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 32 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 32 of 200, 80% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 32 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 32 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 32.\n",
      "Epoch 33 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 33 of 200, 20% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 33 of 200, 30% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 33 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 33 of 200, 50% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 33 of 200, 60% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 33 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 33 of 200, 80% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 33 of 200, 90% \t train_loss: 0.05  took: 0.06s\n",
      "Epoch 33 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 33.\n",
      "Epoch 34 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 34 of 200, 20% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 34 of 200, 30% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 34 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 34 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 34 of 200, 60% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 34 of 200, 70% \t train_loss: 0.05  took: 0.01s\n",
      "Epoch 34 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 34 of 200, 90% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 34 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 34.\n",
      "Epoch 35 of 200, 10% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 35 of 200, 20% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 35 of 200, 30% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 35 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 35 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 35 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 35 of 200, 70% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 35 of 200, 80% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 35 of 200, 90% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 35 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 35.\n",
      "Epoch 36 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 36 of 200, 20% \t train_loss: 0.06  took: 0.04s\n",
      "Epoch 36 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 36 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 36 of 200, 50% \t train_loss: 0.06  took: 0.01s\n",
      "Epoch 36 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 36 of 200, 70% \t train_loss: 0.05  took: 0.01s\n",
      "Epoch 36 of 200, 80% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 36 of 200, 90% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 36 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 36.\n",
      "Epoch 37 of 200, 10% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 37 of 200, 20% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 37 of 200, 30% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 37 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 37 of 200, 50% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 37 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 37 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 37 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 37 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 37 of 200, 100% \t train_loss: 0.05  took: 0.04s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 37.\n",
      "Epoch 38 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 38 of 200, 20% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 38 of 200, 30% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 38 of 200, 40% \t train_loss: 0.05  took: 0.01s\n",
      "Epoch 38 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 38 of 200, 60% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 38 of 200, 70% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 38 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 38 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 38 of 200, 100% \t train_loss: 0.05  took: 0.02s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 38.\n",
      "Epoch 39 of 200, 10% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 39 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 39 of 200, 30% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 39 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 39 of 200, 50% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 39 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 39 of 200, 70% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 39 of 200, 80% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 39 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 39 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 39.\n",
      "Epoch 40 of 200, 10% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 40 of 200, 20% \t train_loss: 0.06  took: 0.03s\n",
      "Epoch 40 of 200, 30% \t train_loss: 0.06  took: 0.04s\n",
      "Epoch 40 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 40 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 40 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 40 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 40 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 40 of 200, 90% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 40 of 200, 100% \t train_loss: 0.05  took: 0.03s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 40.\n",
      "Epoch 41 of 200, 10% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 41 of 200, 20% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 41 of 200, 30% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 41 of 200, 40% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 41 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 41 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 41 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 41 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 41 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 41 of 200, 100% \t train_loss: 0.05  took: 0.04s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 41.\n",
      "Epoch 42 of 200, 10% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 42 of 200, 20% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 42 of 200, 30% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 42 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 42 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 42 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 42 of 200, 70% \t train_loss: 0.05  took: 0.06s\n",
      "Epoch 42 of 200, 80% \t train_loss: 0.05  took: 0.02s\n",
      "Epoch 42 of 200, 90% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 42 of 200, 100% \t train_loss: 0.04  took: 0.02s\n",
      "val_loss = 0.05\n",
      "Snapshot saved at epoch 42.\n",
      "Epoch 43 of 200, 10% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 43 of 200, 20% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 43 of 200, 30% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 43 of 200, 40% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 43 of 200, 50% \t train_loss: 0.05  took: 0.06s\n",
      "Epoch 43 of 200, 60% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 43 of 200, 70% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 43 of 200, 80% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 43 of 200, 90% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 43 of 200, 100% \t train_loss: 0.04  took: 0.03s\n",
      "val_loss = 0.04\n",
      "Snapshot saved at epoch 43.\n",
      "Epoch 44 of 200, 10% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 44 of 200, 20% \t train_loss: 0.05  took: 0.01s\n",
      "Epoch 44 of 200, 30% \t train_loss: 0.05  took: 0.04s\n",
      "Epoch 44 of 200, 40% \t train_loss: 0.04  took: 0.05s\n",
      "Epoch 44 of 200, 50% \t train_loss: 0.05  took: 0.03s\n",
      "Epoch 44 of 200, 60% \t train_loss: 0.05  took: 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 of 200, 70% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 44 of 200, 80% \t train_loss: 0.04  took: 0.04s\n",
      "Epoch 44 of 200, 90% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 44 of 200, 100% \t train_loss: 0.04  took: 0.02s\n",
      "val_loss = 0.04\n",
      "Snapshot saved at epoch 44.\n",
      "Epoch 45 of 200, 10% \t train_loss: 0.04  took: 0.05s\n",
      "Epoch 45 of 200, 20% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 45 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 45 of 200, 40% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 45 of 200, 50% \t train_loss: 0.04  took: 0.01s\n",
      "Epoch 45 of 200, 60% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 45 of 200, 70% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 45 of 200, 80% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 45 of 200, 90% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 45 of 200, 100% \t train_loss: 0.04  took: 0.03s\n",
      "val_loss = 0.04\n",
      "Snapshot saved at epoch 45.\n",
      "Epoch 46 of 200, 10% \t train_loss: 0.04  took: 0.05s\n",
      "Epoch 46 of 200, 20% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 46 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 46 of 200, 40% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 46 of 200, 50% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 46 of 200, 60% \t train_loss: 0.04  took: 0.04s\n",
      "Epoch 46 of 200, 70% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 46 of 200, 80% \t train_loss: 0.04  took: 0.01s\n",
      "Epoch 46 of 200, 90% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 46 of 200, 100% \t train_loss: 0.04  took: 0.03s\n",
      "val_loss = 0.04\n",
      "Snapshot saved at epoch 46.\n",
      "Epoch 47 of 200, 10% \t train_loss: 0.04  took: 0.05s\n",
      "Epoch 47 of 200, 20% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 47 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 47 of 200, 40% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 47 of 200, 50% \t train_loss: 0.04  took: 0.04s\n",
      "Epoch 47 of 200, 60% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 47 of 200, 70% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 47 of 200, 80% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 47 of 200, 90% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 47 of 200, 100% \t train_loss: 0.04  took: 0.04s\n",
      "val_loss = 0.04\n",
      "Snapshot saved at epoch 47.\n",
      "Epoch 48 of 200, 10% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 48 of 200, 20% \t train_loss: 0.04  took: 0.06s\n",
      "Epoch 48 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 48 of 200, 40% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 48 of 200, 50% \t train_loss: 0.04  took: 0.04s\n",
      "Epoch 48 of 200, 60% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 48 of 200, 70% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 48 of 200, 80% \t train_loss: 0.04  took: 0.01s\n",
      "Epoch 48 of 200, 90% \t train_loss: 0.04  took: 0.06s\n",
      "Epoch 48 of 200, 100% \t train_loss: 0.04  took: 0.05s\n",
      "val_loss = 0.04\n",
      "Snapshot saved at epoch 48.\n",
      "Epoch 49 of 200, 10% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 49 of 200, 20% \t train_loss: 0.04  took: 0.01s\n",
      "Epoch 49 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 49 of 200, 40% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 49 of 200, 50% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 49 of 200, 60% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 49 of 200, 70% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 49 of 200, 80% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 49 of 200, 90% \t train_loss: 0.04  took: 0.04s\n",
      "Epoch 49 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.04\n",
      "Snapshot saved at epoch 49.\n",
      "Epoch 50 of 200, 10% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 50 of 200, 20% \t train_loss: 0.04  took: 0.05s\n",
      "Epoch 50 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 50 of 200, 40% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 50 of 200, 50% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 50 of 200, 60% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 50 of 200, 70% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 50 of 200, 80% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 50 of 200, 90% \t train_loss: 0.04  took: 0.05s\n",
      "Epoch 50 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.04\n",
      "Snapshot saved at epoch 50.\n",
      "Epoch 51 of 200, 10% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 51 of 200, 20% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 51 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 51 of 200, 40% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 51 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 51 of 200, 60% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 51 of 200, 70% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 51 of 200, 80% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 51 of 200, 90% \t train_loss: 0.04  took: 0.05s\n",
      "Epoch 51 of 200, 100% \t train_loss: 0.03  took: 0.01s\n",
      "val_loss = 0.04\n",
      "Snapshot saved at epoch 51.\n",
      "Epoch 52 of 200, 10% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 52 of 200, 20% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 52 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 52 of 200, 40% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 52 of 200, 50% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 52 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 52 of 200, 70% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 52 of 200, 80% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 52 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 52 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 52.\n",
      "Epoch 53 of 200, 10% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 53 of 200, 20% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 53 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 53 of 200, 40% \t train_loss: 0.04  took: 0.06s\n",
      "Epoch 53 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 53 of 200, 60% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 53 of 200, 70% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 53 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 53 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 53 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 53.\n",
      "Epoch 54 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 54 of 200, 20% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 54 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 54 of 200, 40% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 54 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 54 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 54 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 54 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 54 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 54 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 54.\n",
      "Epoch 55 of 200, 10% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 55 of 200, 20% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 55 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 55 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 55 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 55 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 55 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 55 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 55 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 55 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 55.\n",
      "Epoch 56 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 56 of 200, 20% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 56 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 56 of 200, 40% \t train_loss: 0.04  took: 0.05s\n",
      "Epoch 56 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 56 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 56 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 56 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 56 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 56 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 56.\n",
      "Epoch 57 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 57 of 200, 20% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 57 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 57 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 57 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 57 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 57 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 57 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 57 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 57 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 57.\n",
      "Epoch 58 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 58 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 58 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 58 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 58 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 58 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 58 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 58 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 58 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 58 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 58.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 59 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 59 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 59 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 59 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 59 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 59 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 59 of 200, 80% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 59 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 59 of 200, 100% \t train_loss: 0.03  took: 0.01s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 59.\n",
      "Epoch 60 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 60 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 60 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 60 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 60 of 200, 50% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 60 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 60 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 60 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 60 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 60 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 60.\n",
      "Epoch 61 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 61 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 61 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 61 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 61 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 61 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 61 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 61 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 61 of 200, 90% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 61 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 61.\n",
      "Epoch 62 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 62 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 62 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 62 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 62 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 62 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 62 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 62 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 62 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 62 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 62.\n",
      "Epoch 63 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 63 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 63 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 63 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 63 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 63 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 63 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 63 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 63 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 63 of 200, 100% \t train_loss: 0.03  took: 0.01s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 63.\n",
      "Epoch 64 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 64 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 64 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 64 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 64 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 64 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 64 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 64 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 64 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 64 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 64.\n",
      "Epoch 65 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 65 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 65 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 65 of 200, 40% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 65 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 65 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 65 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 65 of 200, 80% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 65 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 65 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 65.\n",
      "Epoch 66 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 66 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 66 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 66 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 66 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 66 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 66 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 66 of 200, 80% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 66 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 66 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 66.\n",
      "Epoch 67 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 67 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 67 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 67 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 67 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 67 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 67 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 67 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 67 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 67 of 200, 100% \t train_loss: 0.03  took: 0.04s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 67.\n",
      "Epoch 68 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 68 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 68 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 68 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 68 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 68 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 68 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 68 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 68 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 68 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 68.\n",
      "Epoch 69 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 69 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 69 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 69 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 69 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 69 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 69 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 69 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 69 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 69 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 69.\n",
      "Epoch 70 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 70 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 70 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 70 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 70 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 70 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 70 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 70 of 200, 80% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 70 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 70 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 70.\n",
      "Epoch 71 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 71 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 71 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 71 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 71 of 200, 50% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 71 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 71 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 71 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 71 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 71 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 71.\n",
      "Epoch 72 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 72 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 72 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 72 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 72 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 72 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 72 of 200, 70% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 72 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 72 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 72 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 72.\n",
      "Epoch 73 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 73 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 73 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 73 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 73 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 73 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 73 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 73 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 73 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 73 of 200, 100% \t train_loss: 0.03  took: 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 73.\n",
      "Epoch 74 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 74 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 74 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 74 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 74 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 74 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 74 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 74 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 74 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 74 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 74.\n",
      "Epoch 75 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 75 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 75 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 75 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 75 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 75 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 75 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 75 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 75 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 75 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 75.\n",
      "Epoch 76 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 76 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 76 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 76 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 76 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 76 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 76 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 76 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 76 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 76 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 76.\n",
      "Epoch 77 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 77 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 77 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 77 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 77 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 77 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 77 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 77 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 77 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 77 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 77.\n",
      "Epoch 78 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 78 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 78 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 78 of 200, 40% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 78 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 78 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 78 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 78 of 200, 80% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 78 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 78 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 78.\n",
      "Epoch 79 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 79 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 79 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 79 of 200, 40% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 79 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 79 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 79 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 79 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 79 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 79 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 79.\n",
      "Epoch 80 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 80 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 80 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 80 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 80 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 80 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 80 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 80 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 80 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 80 of 200, 100% \t train_loss: 0.03  took: 0.04s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 80.\n",
      "Epoch 81 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 81 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 81 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 81 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 81 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 81 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 81 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 81 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 81 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 81 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 81.\n",
      "Epoch 82 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 82 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 82 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 82 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 82 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 82 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 82 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 82 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 82 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 82 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 82.\n",
      "Epoch 83 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 83 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 83 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 83 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 83 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 83 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 83 of 200, 70% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 83 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 83 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 83 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 83.\n",
      "Epoch 84 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 84 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 84 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 84 of 200, 40% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 84 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 84 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 84 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 84 of 200, 80% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 84 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 84 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 84.\n",
      "Epoch 85 of 200, 10% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 85 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 85 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 85 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 85 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 85 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 85 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 85 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 85 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 85 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 85.\n",
      "Epoch 86 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 86 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 86 of 200, 30% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 86 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 86 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 86 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 86 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 86 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 86 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 86 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 86.\n",
      "Epoch 87 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 87 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 87 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 87 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 87 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 87 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 87 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 87 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 87 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 87 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 87.\n",
      "Epoch 88 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 88 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 88 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 88 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 88 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 88 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 88 of 200, 70% \t train_loss: 0.03  took: 0.03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 of 200, 80% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 88 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 88 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 88.\n",
      "Epoch 89 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 89 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 89 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 89 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 89 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 89 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 89 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 89 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 89 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 89 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 89.\n",
      "Epoch 90 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 90 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 90 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 90 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 90 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 90 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 90 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 90 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 90 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 90 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 90.\n",
      "Epoch 91 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 91 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 91 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 91 of 200, 40% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 91 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 91 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 91 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 91 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 91 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 91 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 91.\n",
      "Epoch 92 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 92 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 92 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 92 of 200, 40% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 92 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 92 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 92 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 92 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 92 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 92 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 92.\n",
      "Epoch 93 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 93 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 93 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 93 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 93 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 93 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 93 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 93 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 93 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 93 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 93.\n",
      "Epoch 94 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 94 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 94 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 94 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 94 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 94 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 94 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 94 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 94 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 94 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 94.\n",
      "Epoch 95 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 95 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 95 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 95 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 95 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 95 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 95 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 95 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 95 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 95 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 95.\n",
      "Epoch 96 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 96 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 96 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 96 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 96 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 96 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 96 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 96 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 96 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 96 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 96.\n",
      "Epoch 97 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 97 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 97 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 97 of 200, 40% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 97 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 97 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 97 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 97 of 200, 80% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 97 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 97 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 97.\n",
      "Epoch 98 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 98 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 98 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 98 of 200, 40% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 98 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 98 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 98 of 200, 70% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 98 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 98 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 98 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 98.\n",
      "Epoch 99 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 99 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 99 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 99 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 99 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 99 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 99 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 99 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 99 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 99 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 99.\n",
      "Epoch 100 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 100 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 100 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 100 of 200, 40% \t train_loss: 0.03  took: 0.07s\n",
      "Epoch 100 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 100 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 100 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 100 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 100 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 100 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 100.\n",
      "Epoch 101 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 101 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 101 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 101 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 101 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 101 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 101 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 101 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 101 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 101 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 101.\n",
      "Epoch 102 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 102 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 102 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 102 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 102 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 102 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 102 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 102 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 102 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 102 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 102.\n",
      "Epoch 103 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 103 of 200, 20% \t train_loss: 0.03  took: 0.03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 103 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 103 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 103 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 103 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 103 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 103 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 103 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 103.\n",
      "Epoch 104 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 104 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 104 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 104 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 104 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 104 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 104 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 104 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 104 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 104 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 104.\n",
      "Epoch 105 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 105 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 105 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 105 of 200, 40% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 105 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 105 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 105 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 105 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 105 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 105 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 105.\n",
      "Epoch 106 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 106 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 106 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 106 of 200, 40% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 106 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 106 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 106 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 106 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 106 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 106 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 106.\n",
      "Epoch 107 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 107 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 107 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 107 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 107 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 107 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 107 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 107 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 107 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 107 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 107.\n",
      "Epoch 108 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 108 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 108 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 108 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 108 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 108 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 108 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 108 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 108 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 108 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 108.\n",
      "Epoch 109 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 109 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 109 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 109 of 200, 40% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 109 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 109 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 109 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 109 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 109 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 109 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 109.\n",
      "Epoch 110 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 110 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 110 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 110 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 110 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 110 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 110 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 110 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 110 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 110 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 110.\n",
      "Epoch 111 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 111 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 111 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 111 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 111 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 111 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 111 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 111 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 111 of 200, 90% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 111 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 111.\n",
      "Epoch 112 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 112 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 112 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 112 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 112 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 112 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 112 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 112 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 112 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 112 of 200, 100% \t train_loss: 0.03  took: 0.06s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 112.\n",
      "Epoch 113 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 113 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 113 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 113 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 113 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 113 of 200, 60% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 113 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 113 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 113 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 113 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 113.\n",
      "Epoch 114 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 114 of 200, 20% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 114 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 114 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 114 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 114 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 114 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 114 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 114 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 114 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 114.\n",
      "Epoch 115 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 115 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 115 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 115 of 200, 40% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 115 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 115 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 115 of 200, 70% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 115 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 115 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 115 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 115.\n",
      "Epoch 116 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 116 of 200, 20% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 116 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 116 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 116 of 200, 50% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 116 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 116 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 116 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 116 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 116 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 116.\n",
      "Epoch 117 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 117 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 117 of 200, 30% \t train_loss: 0.03  took: 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 117 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 117 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 117 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 117 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 117 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 117 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 117.\n",
      "Epoch 118 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 118 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 118 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 118 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 118 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 118 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 118 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 118 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 118 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 118 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 118.\n",
      "Epoch 119 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 119 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 119 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 119 of 200, 40% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 119 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 119 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 119 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 119 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 119 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 119 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 119.\n",
      "Epoch 120 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 120 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 120 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 120 of 200, 40% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 120 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 120 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 120 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 120 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 120 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 120 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 120.\n",
      "Epoch 121 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 121 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 121 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 121 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 121 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 121 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 121 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 121 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 121 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 121 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 121.\n",
      "Epoch 122 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 122 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 122 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 122 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 122 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 122 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 122 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 122 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 122 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 122 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 122.\n",
      "Epoch 123 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 123 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 123 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 123 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 123 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 123 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 123 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 123 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 123 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 123 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 123.\n",
      "Epoch 124 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 124 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 124 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 124 of 200, 40% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 124 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 124 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 124 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 124 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 124 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 124 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 124.\n",
      "Epoch 125 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 125 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 125 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 125 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 125 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 125 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 125 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 125 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 125 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 125 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 125.\n",
      "Epoch 126 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 126 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 126 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 126 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 126 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 126 of 200, 60% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 126 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 126 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 126 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 126 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 126.\n",
      "Epoch 127 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 127 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 127 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 127 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 127 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 127 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 127 of 200, 70% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 127 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 127 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 127 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 127.\n",
      "Epoch 128 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 128 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 128 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 128 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 128 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 128 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 128 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 128 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 128 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 128 of 200, 100% \t train_loss: 0.03  took: 0.04s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 128.\n",
      "Epoch 129 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 129 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 129 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 129 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 129 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 129 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 129 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 129 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 129 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 129 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 129.\n",
      "Epoch 130 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 130 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 130 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 130 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 130 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 130 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 130 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 130 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 130 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 130 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 130.\n",
      "Epoch 131 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 131 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 131 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 131 of 200, 40% \t train_loss: 0.03  took: 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 131 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 131 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 131 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 131 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 131 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 131.\n",
      "Epoch 132 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 132 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 132 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 132 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 132 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 132 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 132 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 132 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 132 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 132 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 132.\n",
      "Epoch 133 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 133 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 133 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 133 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 133 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 133 of 200, 60% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 133 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 133 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 133 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 133 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 133.\n",
      "Epoch 134 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 134 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 134 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 134 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 134 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 134 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 134 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 134 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 134 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 134 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 134.\n",
      "Epoch 135 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 135 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 135 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 135 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 135 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 135 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 135 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 135 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 135 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 135 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 135.\n",
      "Epoch 136 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 136 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 136 of 200, 30% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 136 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 136 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 136 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 136 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 136 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 136 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 136 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 136.\n",
      "Epoch 137 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 137 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 137 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 137 of 200, 40% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 137 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 137 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 137 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 137 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 137 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 137 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 137.\n",
      "Epoch 138 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 138 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 138 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 138 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 138 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 138 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 138 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 138 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 138 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 138 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 138.\n",
      "Epoch 139 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 139 of 200, 20% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 139 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 139 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 139 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 139 of 200, 60% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 139 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 139 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 139 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 139 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 139.\n",
      "Epoch 140 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 140 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 140 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 140 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 140 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 140 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 140 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 140 of 200, 80% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 140 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 140 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 140.\n",
      "Epoch 141 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 141 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 141 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 141 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 141 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 141 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 141 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 141 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 141 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 141 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 141.\n",
      "Epoch 142 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 142 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 142 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 142 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 142 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 142 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 142 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 142 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 142 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 142 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 142.\n",
      "Epoch 143 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 143 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 143 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 143 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 143 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 143 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 143 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 143 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 143 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 143 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 143.\n",
      "Epoch 144 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 144 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 144 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 144 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 144 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 144 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 144 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 144 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 144 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 144 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 144.\n",
      "Epoch 145 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 145 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 145 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 145 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 145 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 145 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 145 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 145 of 200, 80% \t train_loss: 0.03  took: 0.03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 145 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 145.\n",
      "Epoch 146 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 146 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 146 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 146 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 146 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 146 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 146 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 146 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 146 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 146 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 146.\n",
      "Epoch 147 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 147 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 147 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 147 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 147 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 147 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 147 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 147 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 147 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 147 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 147.\n",
      "Epoch 148 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 148 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 148 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 148 of 200, 40% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 148 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 148 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 148 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 148 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 148 of 200, 90% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 148 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 148.\n",
      "Epoch 149 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 149 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 149 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 149 of 200, 40% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 149 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 149 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 149 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 149 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 149 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 149 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 149.\n",
      "Epoch 150 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 150 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 150 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 150 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 150 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 150 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 150 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 150 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 150 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 150 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 150.\n",
      "Epoch 151 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 151 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 151 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 151 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 151 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 151 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 151 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 151 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 151 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 151 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 151.\n",
      "Epoch 152 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 152 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 152 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 152 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 152 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 152 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 152 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 152 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 152 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 152 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 152.\n",
      "Epoch 153 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 153 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 153 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 153 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 153 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 153 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 153 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 153 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 153 of 200, 90% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 153 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 153.\n",
      "Epoch 154 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 154 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 154 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 154 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 154 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 154 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 154 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 154 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 154 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 154 of 200, 100% \t train_loss: 0.03  took: 0.06s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 154.\n",
      "Epoch 155 of 200, 10% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 155 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 155 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 155 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 155 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 155 of 200, 60% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 155 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 155 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 155 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 155 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 155.\n",
      "Epoch 156 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 156 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 156 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 156 of 200, 40% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 156 of 200, 50% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 156 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 156 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 156 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 156 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 156 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 156.\n",
      "Epoch 157 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 157 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 157 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 157 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 157 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 157 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 157 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 157 of 200, 80% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 157 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 157 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 157.\n",
      "Epoch 158 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 158 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 158 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 158 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 158 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 158 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 158 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 158 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 158 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 158 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 158.\n",
      "Epoch 159 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 159 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 159 of 200, 30% \t train_loss: 0.04  took: 0.02s\n",
      "Epoch 159 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 159 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 159 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 159 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 159 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 159 of 200, 90% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 159 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 159.\n",
      "Epoch 160 of 200, 10% \t train_loss: 0.03  took: 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 160 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 160 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 160 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 160 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 160 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 160 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 160 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 160 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 160.\n",
      "Epoch 161 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 161 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 161 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 161 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 161 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 161 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 161 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 161 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 161 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 161 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 161.\n",
      "Epoch 162 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 162 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 162 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 162 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 162 of 200, 50% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 162 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 162 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 162 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 162 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 162 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 162.\n",
      "Epoch 163 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 163 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 163 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 163 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 163 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 163 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 163 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 163 of 200, 80% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 163 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 163 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 163.\n",
      "Epoch 164 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 164 of 200, 20% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 164 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 164 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 164 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 164 of 200, 60% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 164 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 164 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 164 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 164 of 200, 100% \t train_loss: 0.03  took: 0.04s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 164.\n",
      "Epoch 165 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 165 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 165 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 165 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 165 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 165 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 165 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 165 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 165 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 165 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 165.\n",
      "Epoch 166 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 166 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 166 of 200, 30% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 166 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 166 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 166 of 200, 60% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 166 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 166 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 166 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 166 of 200, 100% \t train_loss: 0.03  took: 0.04s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 166.\n",
      "Epoch 167 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 167 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 167 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 167 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 167 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 167 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 167 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 167 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 167 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 167 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 167.\n",
      "Epoch 168 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 168 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 168 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 168 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 168 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 168 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 168 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 168 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 168 of 200, 90% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 168 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 168.\n",
      "Epoch 169 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 169 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 169 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 169 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 169 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 169 of 200, 60% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 169 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 169 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 169 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 169 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 169.\n",
      "Epoch 170 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 170 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 170 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 170 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 170 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 170 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 170 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 170 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 170 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 170 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 170.\n",
      "Epoch 171 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 171 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 171 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 171 of 200, 40% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 171 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 171 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 171 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 171 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 171 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 171 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 171.\n",
      "Epoch 172 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 172 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 172 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 172 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 172 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 172 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 172 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 172 of 200, 80% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 172 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 172 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 172.\n",
      "Epoch 173 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 173 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 173 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 173 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 173 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 173 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 173 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 173 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 173 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 173 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 173.\n",
      "Epoch 174 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 174 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 174 of 200, 30% \t train_loss: 0.03  took: 0.03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174 of 200, 40% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 174 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 174 of 200, 60% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 174 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 174 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 174 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 174 of 200, 100% \t train_loss: 0.03  took: 0.04s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 174.\n",
      "Epoch 175 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 175 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 175 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 175 of 200, 40% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 175 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 175 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 175 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 175 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 175 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 175 of 200, 100% \t train_loss: 0.03  took: 0.05s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 175.\n",
      "Epoch 176 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 176 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 176 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 176 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 176 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 176 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 176 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 176 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 176 of 200, 90% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 176 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 176.\n",
      "Epoch 177 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 177 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 177 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 177 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 177 of 200, 50% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 177 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 177 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 177 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 177 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 177 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 177.\n",
      "Epoch 178 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 178 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 178 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 178 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 178 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 178 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 178 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 178 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 178 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 178 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 178.\n",
      "Epoch 179 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 179 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 179 of 200, 30% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 179 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 179 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 179 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 179 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 179 of 200, 80% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 179 of 200, 90% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 179 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 179.\n",
      "Epoch 180 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 180 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 180 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 180 of 200, 40% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 180 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 180 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 180 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 180 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 180 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 180 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 180.\n",
      "Epoch 181 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 181 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 181 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 181 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 181 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 181 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 181 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 181 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 181 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 181 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 181.\n",
      "Epoch 182 of 200, 10% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 182 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 182 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 182 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 182 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 182 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 182 of 200, 70% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 182 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 182 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 182 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 182.\n",
      "Epoch 183 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 183 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 183 of 200, 30% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 183 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 183 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 183 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 183 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 183 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 183 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 183 of 200, 100% \t train_loss: 0.03  took: 0.04s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 183.\n",
      "Epoch 184 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 184 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 184 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 184 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 184 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 184 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 184 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 184 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 184 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 184 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 184.\n",
      "Epoch 185 of 200, 10% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 185 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 185 of 200, 30% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 185 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 185 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 185 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 185 of 200, 70% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 185 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 185 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 185 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 185.\n",
      "Epoch 186 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 186 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 186 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 186 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 186 of 200, 50% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 186 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 186 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 186 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 186 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 186 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 186.\n",
      "Epoch 187 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 187 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 187 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 187 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 187 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 187 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 187 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 187 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 187 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 187 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 187.\n",
      "Epoch 188 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 188 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 188 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 188 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 188 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 188 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 188 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 188 of 200, 80% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 188 of 200, 90% \t train_loss: 0.03  took: 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 188.\n",
      "Epoch 189 of 200, 10% \t train_loss: 0.03  took: 0.07s\n",
      "Epoch 189 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 189 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 189 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 189 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 189 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 189 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 189 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 189 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 189 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 189.\n",
      "Epoch 190 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 190 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 190 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 190 of 200, 40% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 190 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 190 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 190 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 190 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 190 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 190 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 190.\n",
      "Epoch 191 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 191 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 191 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 191 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 191 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 191 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 191 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 191 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 191 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 191 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 191.\n",
      "Epoch 192 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 192 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 192 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 192 of 200, 40% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 192 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 192 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 192 of 200, 70% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 192 of 200, 80% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 192 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 192 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 192.\n",
      "Epoch 193 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 193 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 193 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 193 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 193 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 193 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 193 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 193 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 193 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 193 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 193.\n",
      "Epoch 194 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 194 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 194 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 194 of 200, 40% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 194 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 194 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 194 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 194 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 194 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 194 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 194.\n",
      "Epoch 195 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 195 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 195 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 195 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 195 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 195 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 195 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 195 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 195 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 195 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 195.\n",
      "Epoch 196 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 196 of 200, 20% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 196 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 196 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 196 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 196 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 196 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 196 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 196 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 196 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 196.\n",
      "Epoch 197 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 197 of 200, 20% \t train_loss: 0.03  took: 0.01s\n",
      "Epoch 197 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 197 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 197 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 197 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 197 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 197 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 197 of 200, 90% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 197 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 197.\n",
      "Epoch 198 of 200, 10% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 198 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 198 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 198 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 198 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 198 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 198 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 198 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 198 of 200, 90% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 198 of 200, 100% \t train_loss: 0.03  took: 0.03s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 198.\n",
      "Epoch 199 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 199 of 200, 20% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 199 of 200, 30% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 199 of 200, 40% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 199 of 200, 50% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 199 of 200, 60% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 199 of 200, 70% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 199 of 200, 80% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 199 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 199 of 200, 100% \t train_loss: 0.02  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 199.\n",
      "Epoch 200 of 200, 10% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 200 of 200, 20% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 200 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 200 of 200, 40% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 200 of 200, 50% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 200 of 200, 60% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 200 of 200, 70% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 200 of 200, 80% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 200 of 200, 90% \t train_loss: 0.03  took: 0.02s\n",
      "Epoch 200 of 200, 100% \t train_loss: 0.03  took: 0.02s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 200.\n",
      "Training done! A list of 200 models saved.\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save snapshots regularly\n",
    "save_every = 1    # Save model after every few epoches\n",
    "CES_oc_bm.full_train(save_dir = './models/oneClass/benchmarks', save_every = save_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c061208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(CES_oc_bm.train_loss_history, CES_oc_bm.val_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a1ce9e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model for the benchmark is stored at: ./models/oneClass/benchmarks\\model179.pth\n",
      "selecting models takes: 0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Pick the best model for each test point\n",
    "start = time.time()\n",
    "best_loss_bm, best_model_bm, val_loss_history_bm = CES_oc_bm.select_model()\n",
    "print('The best model for the benchmark is stored at:', best_model_bm)\n",
    "print('selecting models takes:', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91e0f141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating each model in the list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:12<00:00, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization done!\n",
      "Calibration (one time effort) takes:12.65s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from inference import Conformal_PVals\n",
    "\n",
    "model_list_bm = CES_oc_bm.model_list\n",
    "\n",
    "# Compute conformity scores of calibration sets for each model\n",
    "# this initialization will be a one-time effort.\n",
    "cal_time = time.time()\n",
    "C_PVals_bm = Conformal_PVals(net_bm, device, cal_loader_bm, model_list_bm, random_state = 0)\n",
    "print('Calibration (one time effort) takes:{:.2f}s.'.format(time.time()-cal_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "511a34d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:05<00:00, 332.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing p-values for 1800 test points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pvals_bm = C_PVals_bm.compute_pvals(inputs, [best_model_bm]*len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4bad91ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average p-value for inliers is 0.499172, average p-value for outliers is 0.210420.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pvals(pvals_bm, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f6386130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply BH procedure yields FDP 0.015000, power 0.306098.\n"
     ]
    }
   ],
   "source": [
    "fdp, power = evaluate_bh(pvals_bm, labels, alpha=0.1)\n",
    "print('Apply BH procedure yields FDP {:3f}, power {:3f}.'.format(fdp,power))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a3261",
   "metadata": {},
   "source": [
    "### Train with CES data splitting and apply CES method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "da43918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 10\n",
      "n_epochs= 200\n",
      "learning_rate= 0.1\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "net_ces = ConvAutoencoder()\n",
    "Loss = th.nn.MSELoss()\n",
    "def criterion(outputs, inputs, targets):\n",
    "    return Loss(outputs, inputs)\n",
    "optimizer_ces = optim.Adam(net_ces.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# Initialize the CES class with model parameters\n",
    "CES_oc_ces = CES_oneClass(net_ces, device, train_loader_ces, batch_size=batch_size, max_epoch=n_epoch, \n",
    "                        learning_rate=lr, val_loader=val_loader_ces, criterion=criterion,optimizer=optimizer_ces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d778b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 200, 10% \t train_loss: 0.16  took: 0.08s\n",
      "Epoch 1 of 200, 20% \t train_loss: 0.13  took: 0.06s\n",
      "Epoch 1 of 200, 30% \t train_loss: 0.11  took: 0.06s\n",
      "Epoch 1 of 200, 40% \t train_loss: 0.10  took: 0.06s\n",
      "Epoch 1 of 200, 50% \t train_loss: 0.08  took: 0.07s\n",
      "Epoch 1 of 200, 60% \t train_loss: 0.07  took: 0.07s\n",
      "Epoch 1 of 200, 70% \t train_loss: 0.06  took: 0.06s\n",
      "Epoch 1 of 200, 80% \t train_loss: 0.05  took: 0.07s\n",
      "Epoch 1 of 200, 90% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 1 of 200, 100% \t train_loss: 0.04  took: 0.07s\n",
      "val_loss = 0.04\n",
      "Snapshot saved at epoch 1.\n",
      "Epoch 2 of 200, 10% \t train_loss: 0.05  took: 0.05s\n",
      "Epoch 2 of 200, 20% \t train_loss: 0.04  took: 0.03s\n",
      "Epoch 2 of 200, 30% \t train_loss: 0.04  took: 0.06s\n",
      "Epoch 2 of 200, 40% \t train_loss: 0.04  took: 0.06s\n",
      "Epoch 2 of 200, 50% \t train_loss: 0.04  took: 0.06s\n",
      "Epoch 2 of 200, 60% \t train_loss: 0.04  took: 0.05s\n",
      "Epoch 2 of 200, 70% \t train_loss: 0.03  took: 0.08s\n",
      "Epoch 2 of 200, 80% \t train_loss: 0.03  took: 0.07s\n",
      "Epoch 2 of 200, 90% \t train_loss: 0.03  took: 0.07s\n",
      "Epoch 2 of 200, 100% \t train_loss: 0.03  took: 0.07s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 2.\n",
      "Epoch 3 of 200, 10% \t train_loss: 0.04  took: 0.07s\n",
      "Epoch 3 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 3 of 200, 30% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 3 of 200, 40% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 3 of 200, 50% \t train_loss: 0.03  took: 0.07s\n",
      "Epoch 3 of 200, 60% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 3 of 200, 70% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 3 of 200, 80% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 3 of 200, 90% \t train_loss: 0.03  took: 0.07s\n",
      "Epoch 3 of 200, 100% \t train_loss: 0.03  took: 0.06s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 3.\n",
      "Epoch 4 of 200, 10% \t train_loss: 0.03  took: 0.10s\n",
      "Epoch 4 of 200, 20% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 4 of 200, 30% \t train_loss: 0.03  took: 0.03s\n",
      "Epoch 4 of 200, 40% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 4 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 4 of 200, 60% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 4 of 200, 70% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 4 of 200, 80% \t train_loss: 0.03  took: 0.08s\n",
      "Epoch 4 of 200, 90% \t train_loss: 0.03  took: 0.06s\n",
      "Epoch 4 of 200, 100% \t train_loss: 0.03  took: 0.08s\n",
      "val_loss = 0.03\n",
      "Snapshot saved at epoch 4.\n",
      "Epoch 5 of 200, 10% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 5 of 200, 20% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 5 of 200, 30% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 5 of 200, 40% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 5 of 200, 50% \t train_loss: 0.03  took: 0.05s\n",
      "Epoch 5 of 200, 60% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 5 of 200, 70% \t train_loss: 0.03  took: 0.04s\n",
      "Epoch 5 of 200, 80% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 5 of 200, 90% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 5 of 200, 100% \t train_loss: 0.02  took: 0.04s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 5.\n",
      "Epoch 6 of 200, 10% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 6 of 200, 20% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 6 of 200, 30% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 6 of 200, 40% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 6 of 200, 50% \t train_loss: 0.03  took: 0.07s\n",
      "Epoch 6 of 200, 60% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 6 of 200, 70% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 6 of 200, 80% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 6 of 200, 90% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 6 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 6.\n",
      "Epoch 7 of 200, 10% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 7 of 200, 20% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 7 of 200, 30% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 7 of 200, 40% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 7 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 7 of 200, 60% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 7 of 200, 70% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 7 of 200, 80% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 7 of 200, 90% \t train_loss: 0.02  took: 0.07s\n",
      "Epoch 7 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 7.\n",
      "Epoch 8 of 200, 10% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 8 of 200, 20% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 8 of 200, 30% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 8 of 200, 40% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 8 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 8 of 200, 60% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 8 of 200, 70% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 8 of 200, 80% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 8 of 200, 90% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 8 of 200, 100% \t train_loss: 0.02  took: 0.04s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 8.\n",
      "Epoch 9 of 200, 10% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 9 of 200, 20% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 9 of 200, 30% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 9 of 200, 40% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 9 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 9 of 200, 60% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 9 of 200, 70% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 9 of 200, 80% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 9 of 200, 90% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 9 of 200, 100% \t train_loss: 0.02  took: 0.05s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 9.\n",
      "Epoch 10 of 200, 10% \t train_loss: 0.02  took: 0.07s\n",
      "Epoch 10 of 200, 20% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 10 of 200, 30% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 10 of 200, 40% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 10 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 10 of 200, 60% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 10 of 200, 70% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 10 of 200, 80% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 10 of 200, 90% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 10 of 200, 100% \t train_loss: 0.02  took: 0.07s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 10.\n",
      "Epoch 11 of 200, 10% \t train_loss: 0.02  took: 0.07s\n",
      "Epoch 11 of 200, 20% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 11 of 200, 30% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 11 of 200, 40% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 11 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 11 of 200, 60% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 11 of 200, 70% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 11 of 200, 80% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 11 of 200, 90% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 11 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 11.\n",
      "Epoch 12 of 200, 10% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 12 of 200, 20% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 12 of 200, 30% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 12 of 200, 40% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 12 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 12 of 200, 60% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 12 of 200, 70% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 12 of 200, 80% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 12 of 200, 90% \t train_loss: 0.02  took: 0.07s\n",
      "Epoch 12 of 200, 100% \t train_loss: 0.02  took: 0.07s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 12.\n",
      "Epoch 13 of 200, 10% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 13 of 200, 20% \t train_loss: 0.02  took: 0.07s\n",
      "Epoch 13 of 200, 30% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 13 of 200, 40% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 13 of 200, 50% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 13 of 200, 60% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 13 of 200, 70% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 13 of 200, 80% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 13 of 200, 90% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 13 of 200, 100% \t train_loss: 0.02  took: 0.04s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 13.\n",
      "Epoch 14 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 14 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 14 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 14 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 14 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 14 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 14 of 200, 70% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 14 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 14 of 200, 90% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 14 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 14.\n",
      "Epoch 15 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 15 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 15 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 15 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 15 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 15 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 15 of 200, 70% \t train_loss: 0.02  took: 0.06s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 15 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 15 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 15.\n",
      "Epoch 16 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 16 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 16 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 16 of 200, 40% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 16 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 16 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 16 of 200, 70% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 16 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 16 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 16 of 200, 100% \t train_loss: 0.02  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 16.\n",
      "Epoch 17 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 17 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 17 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 17 of 200, 40% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 17 of 200, 50% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 17 of 200, 60% \t train_loss: 0.02  took: 0.07s\n",
      "Epoch 17 of 200, 70% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 17 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 17 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 17 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 17.\n",
      "Epoch 18 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 18 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 18 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 18 of 200, 40% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 18 of 200, 50% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 18 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 18 of 200, 70% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 18 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 18 of 200, 90% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 18 of 200, 100% \t train_loss: 0.02  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 18.\n",
      "Epoch 19 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 19 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 19 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 19 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 19 of 200, 50% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 19 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 19 of 200, 70% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 19 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 19 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 19 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 19.\n",
      "Epoch 20 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 20 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 20 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 20 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 20 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 20 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 20 of 200, 70% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 20 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 20 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 20 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 20.\n",
      "Epoch 21 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 21 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 21 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 21 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 21 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 21 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 21 of 200, 70% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 21 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 21 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 21 of 200, 100% \t train_loss: 0.02  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 21.\n",
      "Epoch 22 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 22 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 22 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 22 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 22 of 200, 50% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 22 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 22 of 200, 70% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 22 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 22 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 22 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 22.\n",
      "Epoch 23 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 23 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 23 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 23 of 200, 40% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 23 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 23 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 23 of 200, 70% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 23 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 23 of 200, 90% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 23 of 200, 100% \t train_loss: 0.02  took: 0.08s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 23.\n",
      "Epoch 24 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 24 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 24 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 24 of 200, 40% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 24 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 24 of 200, 60% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 24 of 200, 70% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 24 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 24 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 24 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 24.\n",
      "Epoch 25 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 25 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 25 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 25 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 25 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 25 of 200, 60% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 25 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 25 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 25 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 25 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 25.\n",
      "Epoch 26 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 26 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 26 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 26 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 26 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 26 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 26 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 26 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 26 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 26 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 26.\n",
      "Epoch 27 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 27 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 27 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 27 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 27 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 27 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 27 of 200, 70% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 27 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 27 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 27 of 200, 100% \t train_loss: 0.02  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 27.\n",
      "Epoch 28 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 28 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 28 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 28 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 28 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 28 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 28 of 200, 70% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 28 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 28 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 28 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 28.\n",
      "Epoch 29 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 29 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 29 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 29 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 29 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 29 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 29 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 29 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 29 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 29 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 29.\n",
      "Epoch 30 of 200, 10% \t train_loss: 0.01  took: 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 30 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 30 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 30 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 30 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 30 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 30 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 30 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 30 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 30.\n",
      "Epoch 31 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 31 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 31 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 31 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 31 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 31 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 31 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 31 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 31 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 31 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 31.\n",
      "Epoch 32 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 32 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 32 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 32 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 32 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 32 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 32 of 200, 70% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 32 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 32 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 32 of 200, 100% \t train_loss: 0.02  took: 0.05s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 32.\n",
      "Epoch 33 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 33 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 33 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 33 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 33 of 200, 50% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 33 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 33 of 200, 70% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 33 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 33 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 33 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 33.\n",
      "Epoch 34 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 34 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 34 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 34 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 34 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 34 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 34 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 34 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 34 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 34 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 34.\n",
      "Epoch 35 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 35 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 35 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 35 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 35 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 35 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 35 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 35 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 35 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 35 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 35.\n",
      "Epoch 36 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 36 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 36 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 36 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 36 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 36 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 36 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 36 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 36 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 36 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 36.\n",
      "Epoch 37 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 37 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 37 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 37 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 37 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 37 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 37 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 37 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 37 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 37 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 37.\n",
      "Epoch 38 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 38 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 38 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 38 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 38 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 38 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 38 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 38 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 38 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 38 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 38.\n",
      "Epoch 39 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 39 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 39 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 39 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 39 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 39 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 39 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 39 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 39 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 39 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 39.\n",
      "Epoch 40 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 40 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 40 of 200, 30% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 40 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 40 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 40 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 40 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 40 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 40 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 40 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 40.\n",
      "Epoch 41 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 41 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 41 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 41 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 41 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 41 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 41 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 41 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 41 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 41 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 41.\n",
      "Epoch 42 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 42 of 200, 20% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 42 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 42 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 42 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 42 of 200, 60% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 42 of 200, 70% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 42 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 42 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 42 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 42.\n",
      "Epoch 43 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 43 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 43 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 43 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 43 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 43 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 43 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 43 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 43 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 43 of 200, 100% \t train_loss: 0.01  took: 0.08s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 43.\n",
      "Epoch 44 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 44 of 200, 20% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 44 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 44 of 200, 40% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 44 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 44 of 200, 60% \t train_loss: 0.01  took: 0.09s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 44 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 44 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 44 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 44.\n",
      "Epoch 45 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 45 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 45 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 45 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 45 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 45 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 45 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 45 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 45 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 45 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 45.\n",
      "Epoch 46 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 46 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 46 of 200, 30% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 46 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 46 of 200, 50% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 46 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 46 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 46 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 46 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 46 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 46.\n",
      "Epoch 47 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 47 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 47 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 47 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 47 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 47 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 47 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 47 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 47 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 47 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 47.\n",
      "Epoch 48 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 48 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 48 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 48 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 48 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 48 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 48 of 200, 70% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 48 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 48 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 48 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 48.\n",
      "Epoch 49 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 49 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 49 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 49 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 49 of 200, 50% \t train_loss: 0.02  took: 0.07s\n",
      "Epoch 49 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 49 of 200, 70% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 49 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 49 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 49 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 49.\n",
      "Epoch 50 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 50 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 50 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 50 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 50 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 50 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 50 of 200, 70% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 50 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 50 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 50 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 50.\n",
      "Epoch 51 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 51 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 51 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 51 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 51 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 51 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 51 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 51 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 51 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 51 of 200, 100% \t train_loss: 0.01  took: 0.03s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 51.\n",
      "Epoch 52 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 52 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 52 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 52 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 52 of 200, 50% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 52 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 52 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 52 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 52 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 52 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 52.\n",
      "Epoch 53 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 53 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 53 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 53 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 53 of 200, 50% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 53 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 53 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 53 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 53 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 53 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 53.\n",
      "Epoch 54 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 54 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 54 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 54 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 54 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 54 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 54 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 54 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 54 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 54 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 54.\n",
      "Epoch 55 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 55 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 55 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 55 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 55 of 200, 50% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 55 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 55 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 55 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 55 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 55 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 55.\n",
      "Epoch 56 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 56 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 56 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 56 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 56 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 56 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 56 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 56 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 56 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 56 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 56.\n",
      "Epoch 57 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 57 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 57 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 57 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 57 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 57 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 57 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 57 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 57 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 57 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 57.\n",
      "Epoch 58 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 58 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 58 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 58 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 58 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 58 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 58 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 58 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 58 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 58 of 200, 100% \t train_loss: 0.01  took: 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 58.\n",
      "Epoch 59 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 59 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 59 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 59 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 59 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 59 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 59 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 59 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 59 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 59 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 59.\n",
      "Epoch 60 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 60 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 60 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 60 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 60 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 60 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 60 of 200, 70% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 60 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 60 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 60 of 200, 100% \t train_loss: 0.01  took: 0.03s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 60.\n",
      "Epoch 61 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 61 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 61 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 61 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 61 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 61 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 61 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 61 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 61 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 61 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 61.\n",
      "Epoch 62 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 62 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 62 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 62 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 62 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 62 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 62 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 62 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 62 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 62 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 62.\n",
      "Epoch 63 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 63 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 63 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 63 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 63 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 63 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 63 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 63 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 63 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 63 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 63.\n",
      "Epoch 64 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 64 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 64 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 64 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 64 of 200, 50% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 64 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 64 of 200, 70% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 64 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 64 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 64 of 200, 100% \t train_loss: 0.01  took: 0.03s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 64.\n",
      "Epoch 65 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 65 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 65 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 65 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 65 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 65 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 65 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 65 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 65 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 65 of 200, 100% \t train_loss: 0.01  took: 0.03s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 65.\n",
      "Epoch 66 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 66 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 66 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 66 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 66 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 66 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 66 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 66 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 66 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 66 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 66.\n",
      "Epoch 67 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 67 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 67 of 200, 30% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 67 of 200, 40% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 67 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 67 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 67 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 67 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 67 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 67 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 67.\n",
      "Epoch 68 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 68 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 68 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 68 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 68 of 200, 50% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 68 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 68 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 68 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 68 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 68 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 68.\n",
      "Epoch 69 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 69 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 69 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 69 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 69 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 69 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 69 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 69 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 69 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 69 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 69.\n",
      "Epoch 70 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 70 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 70 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 70 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 70 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 70 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 70 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 70 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 70 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 70 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 70.\n",
      "Epoch 71 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 71 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 71 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 71 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 71 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 71 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 71 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 71 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 71 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 71 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 71.\n",
      "Epoch 72 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 72 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 72 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 72 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 72 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 72 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 72 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 72 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 72 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 72 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 72.\n",
      "Epoch 73 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 73 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 73 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 73 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 73 of 200, 50% \t train_loss: 0.01  took: 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 of 200, 60% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 73 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 73 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 73 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 73 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 73.\n",
      "Epoch 74 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 74 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 74 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 74 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 74 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 74 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 74 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 74 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 74 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 74 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 74.\n",
      "Epoch 75 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 75 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 75 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 75 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 75 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 75 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 75 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 75 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 75 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 75 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 75.\n",
      "Epoch 76 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 76 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 76 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 76 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 76 of 200, 50% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 76 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 76 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 76 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 76 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 76 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 76.\n",
      "Epoch 77 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 77 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 77 of 200, 30% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 77 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 77 of 200, 50% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 77 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 77 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 77 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 77 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 77 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 77.\n",
      "Epoch 78 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 78 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 78 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 78 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 78 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 78 of 200, 60% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 78 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 78 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 78 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 78 of 200, 100% \t train_loss: 0.01  took: 0.11s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 78.\n",
      "Epoch 79 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 79 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 79 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 79 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 79 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 79 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 79 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 79 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 79 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 79 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 79.\n",
      "Epoch 80 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 80 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 80 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 80 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 80 of 200, 50% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 80 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 80 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 80 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 80 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 80 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 80.\n",
      "Epoch 81 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 81 of 200, 20% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 81 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 81 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 81 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 81 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 81 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 81 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 81 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 81 of 200, 100% \t train_loss: 0.01  took: 0.03s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 81.\n",
      "Epoch 82 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 82 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 82 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 82 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 82 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 82 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 82 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 82 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 82 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 82 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 82.\n",
      "Epoch 83 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 83 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 83 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 83 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 83 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 83 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 83 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 83 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 83 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 83 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 83.\n",
      "Epoch 84 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 84 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 84 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 84 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 84 of 200, 50% \t train_loss: 0.01  took: 0.02s\n",
      "Epoch 84 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 84 of 200, 70% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 84 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 84 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 84 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 84.\n",
      "Epoch 85 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 85 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 85 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 85 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 85 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 85 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 85 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 85 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 85 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 85 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 85.\n",
      "Epoch 86 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 86 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 86 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 86 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 86 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 86 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 86 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 86 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 86 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 86 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 86.\n",
      "Epoch 87 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 87 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 87 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 87 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 87 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 87 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 87 of 200, 70% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 87 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 87 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 87 of 200, 100% \t train_loss: 0.02  took: 0.04s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 87.\n",
      "Epoch 88 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 88 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 88 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 88 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 88 of 200, 50% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 88 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 88 of 200, 70% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 88 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 88 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 88 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 88.\n",
      "Epoch 89 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 89 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 89 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 89 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 89 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 89 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 89 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 89 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 89 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 89 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 89.\n",
      "Epoch 90 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 90 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 90 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 90 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 90 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 90 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 90 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 90 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 90 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 90 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 90.\n",
      "Epoch 91 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 91 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 91 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 91 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 91 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 91 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 91 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 91 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 91 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 91 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 91.\n",
      "Epoch 92 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 92 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 92 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 92 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 92 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 92 of 200, 60% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 92 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 92 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 92 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 92 of 200, 100% \t train_loss: 0.01  took: 0.08s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 92.\n",
      "Epoch 93 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 93 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 93 of 200, 30% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 93 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 93 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 93 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 93 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 93 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 93 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 93 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 93.\n",
      "Epoch 94 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 94 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 94 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 94 of 200, 40% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 94 of 200, 50% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 94 of 200, 60% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 94 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 94 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 94 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 94 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 94.\n",
      "Epoch 95 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 95 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 95 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 95 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 95 of 200, 50% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 95 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 95 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 95 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 95 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 95 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 95.\n",
      "Epoch 96 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 96 of 200, 20% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 96 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 96 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 96 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 96 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 96 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 96 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 96 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 96 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 96.\n",
      "Epoch 97 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 97 of 200, 20% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 97 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 97 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 97 of 200, 50% \t train_loss: 0.02  took: 0.04s\n",
      "Epoch 97 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 97 of 200, 70% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 97 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 97 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 97 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 97.\n",
      "Epoch 98 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 98 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 98 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 98 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 98 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 98 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 98 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 98 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 98 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 98 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 98.\n",
      "Epoch 99 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 99 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 99 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 99 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 99 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 99 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 99 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 99 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 99 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 99 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 99.\n",
      "Epoch 100 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 100 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 100 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 100 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 100 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 100 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 100 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 100 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 100 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 100 of 200, 100% \t train_loss: 0.01  took: 0.08s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 100.\n",
      "Epoch 101 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 101 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 101 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 101 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 101 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 101 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 101 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 101 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 101 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 101 of 200, 100% \t train_loss: 0.01  took: 0.08s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 101.\n",
      "Epoch 102 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 102 of 200, 20% \t train_loss: 0.01  took: 0.06s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 102 of 200, 40% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 102 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 102 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 102 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 102 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 102 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 102 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 102.\n",
      "Epoch 103 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 103 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 103 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 103 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 103 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 103 of 200, 60% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 103 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 103 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 103 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 103 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 103.\n",
      "Epoch 104 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 104 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 104 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 104 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 104 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 104 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 104 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 104 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 104 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 104 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 104.\n",
      "Epoch 105 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 105 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 105 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 105 of 200, 40% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 105 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 105 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 105 of 200, 70% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 105 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 105 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 105 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 105.\n",
      "Epoch 106 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 106 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 106 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 106 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 106 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 106 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 106 of 200, 70% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 106 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 106 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 106 of 200, 100% \t train_loss: 0.01  took: 0.08s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 106.\n",
      "Epoch 107 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 107 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 107 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 107 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 107 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 107 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 107 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 107 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 107 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 107 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 107.\n",
      "Epoch 108 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 108 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 108 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 108 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 108 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 108 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 108 of 200, 70% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 108 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 108 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 108 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 108.\n",
      "Epoch 109 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 109 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 109 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 109 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 109 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 109 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 109 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 109 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 109 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 109 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 109.\n",
      "Epoch 110 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 110 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 110 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 110 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 110 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 110 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 110 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 110 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 110 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 110 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 110.\n",
      "Epoch 111 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 111 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 111 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 111 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 111 of 200, 50% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 111 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 111 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 111 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 111 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 111 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 111.\n",
      "Epoch 112 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 112 of 200, 20% \t train_loss: 0.01  took: 0.02s\n",
      "Epoch 112 of 200, 30% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 112 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 112 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 112 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 112 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 112 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 112 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 112 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 112.\n",
      "Epoch 113 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 113 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 113 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 113 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 113 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 113 of 200, 60% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 113 of 200, 70% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 113 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 113 of 200, 90% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 113 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 113.\n",
      "Epoch 114 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 114 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 114 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 114 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 114 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 114 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 114 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 114 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 114 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 114 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 114.\n",
      "Epoch 115 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 115 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 115 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 115 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 115 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 115 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 115 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 115 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 115 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 115 of 200, 100% \t train_loss: 0.01  took: 0.03s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 115.\n",
      "Epoch 116 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 116 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 116 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 116 of 200, 40% \t train_loss: 0.01  took: 0.06s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 of 200, 50% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 116 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 116 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 116 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 116 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 116 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 116.\n",
      "Epoch 117 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 117 of 200, 20% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 117 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 117 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 117 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 117 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 117 of 200, 70% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 117 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 117 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 117 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 117.\n",
      "Epoch 118 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 118 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 118 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 118 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 118 of 200, 50% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 118 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 118 of 200, 70% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 118 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 118 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 118 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 118.\n",
      "Epoch 119 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 119 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 119 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 119 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 119 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 119 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 119 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 119 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 119 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 119 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 119.\n",
      "Epoch 120 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 120 of 200, 20% \t train_loss: 0.01  took: 0.10s\n",
      "Epoch 120 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 120 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 120 of 200, 50% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 120 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 120 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 120 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 120 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 120 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 120.\n",
      "Epoch 121 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 121 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 121 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 121 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 121 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 121 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 121 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 121 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 121 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 121 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 121.\n",
      "Epoch 122 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 122 of 200, 20% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 122 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 122 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 122 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 122 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 122 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 122 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 122 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 122 of 200, 100% \t train_loss: 0.01  took: 0.08s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 122.\n",
      "Epoch 123 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 123 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 123 of 200, 30% \t train_loss: 0.01  took: 0.10s\n",
      "Epoch 123 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 123 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 123 of 200, 60% \t train_loss: 0.01  took: 0.10s\n",
      "Epoch 123 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 123 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 123 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 123 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 123.\n",
      "Epoch 124 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 124 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 124 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 124 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 124 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 124 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 124 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 124 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 124 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 124 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 124.\n",
      "Epoch 125 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 125 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 125 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 125 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 125 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 125 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 125 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 125 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 125 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 125 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 125.\n",
      "Epoch 126 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 126 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 126 of 200, 30% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 126 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 126 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 126 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 126 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 126 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 126 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 126 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 126.\n",
      "Epoch 127 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 127 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 127 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 127 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 127 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 127 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 127 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 127 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 127 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 127 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 127.\n",
      "Epoch 128 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 128 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 128 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 128 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 128 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 128 of 200, 60% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 128 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 128 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 128 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 128 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 128.\n",
      "Epoch 129 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 129 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 129 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 129 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 129 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 129 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 129 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 129 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 129 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 129 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 129.\n",
      "Epoch 130 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 130 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 130 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 130 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 130 of 200, 50% \t train_loss: 0.01  took: 0.07s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 130 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 130 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 130 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 130 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 130.\n",
      "Epoch 131 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 131 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 131 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 131 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 131 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 131 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 131 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 131 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 131 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 131 of 200, 100% \t train_loss: 0.01  took: 0.03s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 131.\n",
      "Epoch 132 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 132 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 132 of 200, 30% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 132 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 132 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 132 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 132 of 200, 70% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 132 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 132 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 132 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 132.\n",
      "Epoch 133 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 133 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 133 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 133 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 133 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 133 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 133 of 200, 70% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 133 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 133 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 133 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 133.\n",
      "Epoch 134 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 134 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 134 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 134 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 134 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 134 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 134 of 200, 70% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 134 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 134 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 134 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 134.\n",
      "Epoch 135 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 135 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 135 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 135 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 135 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 135 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 135 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 135 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 135 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 135 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 135.\n",
      "Epoch 136 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 136 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 136 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 136 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 136 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 136 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 136 of 200, 70% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 136 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 136 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 136 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 136.\n",
      "Epoch 137 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 137 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 137 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 137 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 137 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 137 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 137 of 200, 70% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 137 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 137 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 137 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 137.\n",
      "Epoch 138 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 138 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 138 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 138 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 138 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 138 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 138 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 138 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 138 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 138 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 138.\n",
      "Epoch 139 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 139 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 139 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 139 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 139 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 139 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 139 of 200, 70% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 139 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 139 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 139 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 139.\n",
      "Epoch 140 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 140 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 140 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 140 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 140 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 140 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 140 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 140 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 140 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 140 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 140.\n",
      "Epoch 141 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 141 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 141 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 141 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 141 of 200, 50% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 141 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 141 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 141 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 141 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 141 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 141.\n",
      "Epoch 142 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 142 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 142 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 142 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 142 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 142 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 142 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 142 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 142 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 142 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 142.\n",
      "Epoch 143 of 200, 10% \t train_loss: 0.01  took: 0.10s\n",
      "Epoch 143 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 143 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 143 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 143 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 143 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 143 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 143 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 143 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 143 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 143.\n",
      "Epoch 144 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 144 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 144 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 144 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 144 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 144 of 200, 60% \t train_loss: 0.01  took: 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 144 of 200, 80% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 144 of 200, 90% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 144 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 144.\n",
      "Epoch 145 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 145 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 145 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 145 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 145 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 145 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 145 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 145 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 145 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 145 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 145.\n",
      "Epoch 146 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 146 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 146 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 146 of 200, 40% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 146 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 146 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 146 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 146 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 146 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 146 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 146.\n",
      "Epoch 147 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 147 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 147 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 147 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 147 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 147 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 147 of 200, 70% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 147 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 147 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 147 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 147.\n",
      "Epoch 148 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 148 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 148 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 148 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 148 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 148 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 148 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 148 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 148 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 148 of 200, 100% \t train_loss: 0.01  took: 0.03s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 148.\n",
      "Epoch 149 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 149 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 149 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 149 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 149 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 149 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 149 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 149 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 149 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 149 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 149.\n",
      "Epoch 150 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 150 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 150 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 150 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 150 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 150 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 150 of 200, 70% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 150 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 150 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 150 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 150.\n",
      "Epoch 151 of 200, 10% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 151 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 151 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 151 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 151 of 200, 50% \t train_loss: 0.02  took: 0.07s\n",
      "Epoch 151 of 200, 60% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 151 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 151 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 151 of 200, 90% \t train_loss: 0.02  took: 0.05s\n",
      "Epoch 151 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 151.\n",
      "Epoch 152 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 152 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 152 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 152 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 152 of 200, 50% \t train_loss: 0.02  took: 0.06s\n",
      "Epoch 152 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 152 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 152 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 152 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 152 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 152.\n",
      "Epoch 153 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 153 of 200, 20% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 153 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 153 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 153 of 200, 50% \t train_loss: 0.02  took: 0.08s\n",
      "Epoch 153 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 153 of 200, 70% \t train_loss: 0.02  took: 0.03s\n",
      "Epoch 153 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 153 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 153 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 153.\n",
      "Epoch 154 of 200, 10% \t train_loss: 0.01  took: 0.10s\n",
      "Epoch 154 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 154 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 154 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 154 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 154 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 154 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 154 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 154 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 154 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 154.\n",
      "Epoch 155 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 155 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 155 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 155 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 155 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 155 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 155 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 155 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 155 of 200, 90% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 155 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 155.\n",
      "Epoch 156 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 156 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 156 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 156 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 156 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 156 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 156 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 156 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 156 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 156 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 156.\n",
      "Epoch 157 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 157 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 157 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 157 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 157 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 157 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 157 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 157 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 157 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 157 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 157.\n",
      "Epoch 158 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 158 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 158 of 200, 30% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 158 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 158 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 158 of 200, 60% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 158 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 158 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 158 of 200, 90% \t train_loss: 0.01  took: 0.06s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 158.\n",
      "Epoch 159 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 159 of 200, 20% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 159 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 159 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 159 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 159 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 159 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 159 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 159 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 159 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 159.\n",
      "Epoch 160 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 160 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 160 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 160 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 160 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 160 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 160 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 160 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 160 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 160 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 160.\n",
      "Epoch 161 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 161 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 161 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 161 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 161 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 161 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 161 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 161 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 161 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 161 of 200, 100% \t train_loss: 0.01  took: 0.08s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 161.\n",
      "Epoch 162 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 162 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 162 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 162 of 200, 40% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 162 of 200, 50% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 162 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 162 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 162 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 162 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 162 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 162.\n",
      "Epoch 163 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 163 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 163 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 163 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 163 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 163 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 163 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 163 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 163 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 163 of 200, 100% \t train_loss: 0.02  took: 0.06s\n",
      "val_loss = 0.02\n",
      "Snapshot saved at epoch 163.\n",
      "Epoch 164 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 164 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 164 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 164 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 164 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 164 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 164 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 164 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 164 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 164 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 164.\n",
      "Epoch 165 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 165 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 165 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 165 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 165 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 165 of 200, 60% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 165 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 165 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 165 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 165 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 165.\n",
      "Epoch 166 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 166 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 166 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 166 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 166 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 166 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 166 of 200, 70% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 166 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 166 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 166 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 166.\n",
      "Epoch 167 of 200, 10% \t train_loss: 0.01  took: 0.10s\n",
      "Epoch 167 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 167 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 167 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 167 of 200, 50% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 167 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 167 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 167 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 167 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 167 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 167.\n",
      "Epoch 168 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 168 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 168 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 168 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 168 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 168 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 168 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 168 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 168 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 168 of 200, 100% \t train_loss: 0.01  took: 0.08s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 168.\n",
      "Epoch 169 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 169 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 169 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 169 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 169 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 169 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 169 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 169 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 169 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 169 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 169.\n",
      "Epoch 170 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 170 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 170 of 200, 30% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 170 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 170 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 170 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 170 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 170 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 170 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 170 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 170.\n",
      "Epoch 171 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 171 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 171 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 171 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 171 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 171 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 171 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 171 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 171 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 171 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 171.\n",
      "Epoch 172 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 172 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 172 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 172 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 172 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 172 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 172 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 172 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 172 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 172 of 200, 100% \t train_loss: 0.01  took: 0.04s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 172.\n",
      "Epoch 173 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 173 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 173 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 173 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 173 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 173 of 200, 60% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 173 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 173 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 173 of 200, 90% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 173 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 173.\n",
      "Epoch 174 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 174 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 174 of 200, 30% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 174 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 174 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 174 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 174 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 174 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 174 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 174 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 174.\n",
      "Epoch 175 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 175 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 175 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 175 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 175 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 175 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 175 of 200, 70% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 175 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 175 of 200, 90% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 175 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 175.\n",
      "Epoch 176 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 176 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 176 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 176 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 176 of 200, 50% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 176 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 176 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 176 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 176 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 176 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 176.\n",
      "Epoch 177 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 177 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 177 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 177 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 177 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 177 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 177 of 200, 70% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 177 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 177 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 177 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 177.\n",
      "Epoch 178 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 178 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 178 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 178 of 200, 40% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 178 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 178 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 178 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 178 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 178 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 178 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 178.\n",
      "Epoch 179 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 179 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 179 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 179 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 179 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 179 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 179 of 200, 70% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 179 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 179 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 179 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 179.\n",
      "Epoch 180 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 180 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 180 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 180 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 180 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 180 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 180 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 180 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 180 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 180 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 180.\n",
      "Epoch 181 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 181 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 181 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 181 of 200, 40% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 181 of 200, 50% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 181 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 181 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 181 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 181 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 181 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 181.\n",
      "Epoch 182 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 182 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 182 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 182 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 182 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 182 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 182 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 182 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 182 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 182 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 182.\n",
      "Epoch 183 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 183 of 200, 20% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 183 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 183 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 183 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 183 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 183 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 183 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 183 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 183 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 183.\n",
      "Epoch 184 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 184 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 184 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 184 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 184 of 200, 50% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 184 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 184 of 200, 70% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 184 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 184 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 184 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 184.\n",
      "Epoch 185 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 185 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 185 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 185 of 200, 40% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 185 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 185 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 185 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 185 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 185 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 185 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 185.\n",
      "Epoch 186 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 186 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 186 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 186 of 200, 40% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 186 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 186 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 186 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 186 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 186 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 186 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 187 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 187 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 187 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 187 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 187 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 187 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 187 of 200, 80% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 187 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 187 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 187.\n",
      "Epoch 188 of 200, 10% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 188 of 200, 20% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 188 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 188 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 188 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 188 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 188 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 188 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 188 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 188 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 188.\n",
      "Epoch 189 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 189 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 189 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 189 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 189 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 189 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 189 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 189 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 189 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 189 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 189.\n",
      "Epoch 190 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 190 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 190 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 190 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 190 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 190 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 190 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 190 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 190 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 190 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 190.\n",
      "Epoch 191 of 200, 10% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 191 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 191 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 191 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 191 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 191 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 191 of 200, 70% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 191 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 191 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 191 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 191.\n",
      "Epoch 192 of 200, 10% \t train_loss: 0.01  took: 0.10s\n",
      "Epoch 192 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 192 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 192 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 192 of 200, 50% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 192 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 192 of 200, 70% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 192 of 200, 80% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 192 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 192 of 200, 100% \t train_loss: 0.01  took: 0.03s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 192.\n",
      "Epoch 193 of 200, 10% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 193 of 200, 20% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 193 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 193 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 193 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 193 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 193 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 193 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 193 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 193 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 193.\n",
      "Epoch 194 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 194 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 194 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 194 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 194 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 194 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 194 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 194 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 194 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 194 of 200, 100% \t train_loss: 0.01  took: 0.04s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 194.\n",
      "Epoch 195 of 200, 10% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 195 of 200, 20% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 195 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 195 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 195 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 195 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 195 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 195 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 195 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 195 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 195.\n",
      "Epoch 196 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 196 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 196 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 196 of 200, 40% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 196 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 196 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 196 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 196 of 200, 80% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 196 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 196 of 200, 100% \t train_loss: 0.01  took: 0.05s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 196.\n",
      "Epoch 197 of 200, 10% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 197 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 197 of 200, 30% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 197 of 200, 40% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 197 of 200, 50% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 197 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 197 of 200, 70% \t train_loss: 0.01  took: 0.09s\n",
      "Epoch 197 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 197 of 200, 90% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 197 of 200, 100% \t train_loss: 0.01  took: 0.07s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 197.\n",
      "Epoch 198 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 198 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 198 of 200, 30% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 198 of 200, 40% \t train_loss: 0.01  took: 0.03s\n",
      "Epoch 198 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 198 of 200, 60% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 198 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 198 of 200, 80% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 198 of 200, 90% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 198 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 198.\n",
      "Epoch 199 of 200, 10% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 199 of 200, 20% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 199 of 200, 30% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 199 of 200, 40% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 199 of 200, 50% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 199 of 200, 60% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 199 of 200, 70% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 199 of 200, 80% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 199 of 200, 90% \t train_loss: 0.01  took: 0.07s\n",
      "Epoch 199 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 199.\n",
      "Epoch 200 of 200, 10% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 200 of 200, 20% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 200 of 200, 30% \t train_loss: 0.01  took: 0.04s\n",
      "Epoch 200 of 200, 40% \t train_loss: 0.01  took: 0.08s\n",
      "Epoch 200 of 200, 50% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 200 of 200, 60% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 200 of 200, 70% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 200 of 200, 80% \t train_loss: 0.01  took: 0.06s\n",
      "Epoch 200 of 200, 90% \t train_loss: 0.01  took: 0.05s\n",
      "Epoch 200 of 200, 100% \t train_loss: 0.01  took: 0.06s\n",
      "val_loss = 0.01\n",
      "Snapshot saved at epoch 200.\n",
      "Training done! A list of 200 models saved.\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save snapshots regularly\n",
    "save_every = 1    # Save model after every few epoches\n",
    "CES_oc_ces.full_train(save_dir = './models/oneClass/ces', save_every = save_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "02477bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(CES_oc_ces.train_loss_history, CES_oc_ces.val_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "872fcbba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 559.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 495.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 515.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 500.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 479.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 519.89it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:02<00:00, 602.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 575.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 554.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 496.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting models takes: 34.222877740859985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick the best model for each test point\n",
    "start = time.time()\n",
    "best_loss_ces, best_model_ces, test_val_loss_history_ces = CES_oc_ces.select_model(inputs)\n",
    "print('selecting models takes:', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "49408679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating each model in the list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:12<00:00, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization done!\n",
      "Calibration (one time effort) takes:12.02s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_list_ces = CES_oc_ces.model_list\n",
    "\n",
    "# Compute conformity scores of calibration sets for each model\n",
    "# this initialization will be a one-time effort.\n",
    "cal_time = time.time()\n",
    "C_PVals_ces = Conformal_PVals(net_ces, device, val_loader_ces, model_list_ces, random_state = 0)\n",
    "print('Calibration (one time effort) takes:{:.2f}s.'.format(time.time()-cal_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e6a46b03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model_ces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [103]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pvals_ces \u001b[38;5;241m=\u001b[39m C_PVals_ces\u001b[38;5;241m.\u001b[39mcompute_pvals(inputs, \u001b[43mbest_model_ces\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model_ces' is not defined"
     ]
    }
   ],
   "source": [
    "pvals_ces = C_PVals_ces.compute_pvals(inputs, best_model_ces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5ac61423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average p-value for inliers is 0.579221, average p-value for outliers is 0.208869.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pvals(pvals_ces, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b2059aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply BH procedure yields FDP 0.000000, power 0.000000.\n"
     ]
    }
   ],
   "source": [
    "fdp, power = evaluate_bh(pvals_ces, labels, alpha=0.1)\n",
    "print('Apply BH procedure yields FDP {:3f}, power {:3f}.'.format(fdp,power))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313bfba",
   "metadata": {},
   "source": [
    "## Apply the naive benchmark\n",
    "The naive benchmark method uses the same data splitting scheme as CES but it naively use the validation set for both model selection and calibration, hence losing the exchangeability between test points and validation points, potentially causes FDR inflation. The following section explores this naive benchmark and its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e4d43ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model selected by naive method is stored at: ./models/oneClass/ces\\model182.pth\n",
      "selecting models takes: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Pick the best model for each test point\n",
    "start = time.time()\n",
    "best_loss_naive, best_model_naive, val_loss_history_naive = CES_oc_ces.select_model()\n",
    "print('best model selected by naive method is stored at:', best_model_naive)\n",
    "print('selecting models takes:', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8048682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:05<00:00, 327.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing p-values for 1800 test points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pvals_naive = C_PVals_ces.compute_pvals(inputs, [best_model_naive]*len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "42b8b4a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average p-value for inliers is 0.496696, average p-value for outliers is 0.079546.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFlCAYAAAA+t0u5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaiElEQVR4nO3df5BcZb3n8fd3J5FwBVdMBhYJcYKCGFMYuUNg/UEFsyBE6gYUXVgKgwsbqNW79+K1SnAtvLUrhbvLr7UQrXCNwYLLjwsGcymuXDaiyG8nEjEQQUDAkRQJCWAAgyb57h/TCZ3JJNMz3T39TPf7VdU1fZ5zTs+3n/Tk08/Tp8+JzESSJJXh37S6AEmS9CaDWZKkghjMkiQVxGCWJKkgBrMkSQUxmCVJKsiEVhcAMGXKlOzp6Wl1GZIkjZkVK1a8mJndg9uLCOaenh76+vpaXYYkSWMmIp4dqt2pbEmSCmIwS5JUEINZkqSCDPsZc0QcCHwf+HfAVmBRZv7fiHgHcCPQAzwDfCYzX6rscwFwFrAF+G+ZeUdTqpcktdSf//xn+vv72bRpU6tLKdakSZOYOnUqEydOrGn7Wg7+2gz8XWb+IiL2BlZExJ3AmcDyzPxGRJwPnA98OSJmAKcC7wfeCfy/iDgkM7eM4vlIkgrW39/P3nvvTU9PDxHR6nKKk5msX7+e/v5+pk+fXtM+w05lZ+aazPxF5f5GYDVwADAfuKay2TXASZX784EbMvONzPwt8CQweyRPRJI0PmzatInJkycbyrsQEUyePHlEMwoj+ow5InqADwIPAvtl5hoYCG9g38pmBwC/q9qtv9ImSWpDhvLujbR/ag7miNgLuAX428z8w+42HaJtp4s+R8TCiOiLiL5169bVWoYkSTv40Ic+NOw2c+bM2X6+jHnz5vHyyy83uarRq+kEIxExkYFQvi4zf1BpfiEi9s/MNRGxP7C20t4PHFi1+1Tg+cGPmZmLgEUAvb29OwW3JGn8ufzOJxr6eOcde8iw29x3330jeszbb799RNtv2bKFrq6uEe1Tj2FHzDEwBv8usDozL6tatQxYULm/APhhVfupEbFHREwHDgYealzJkiS9aa+99gLgJz/5CXPmzOGUU07h0EMP5fTTTydz53FfT08PL774IgDXXnsts2fPZtasWZxzzjls2bJl+2NeeOGFHHnkkdx///2cf/75zJgxg8MOO4wvfelLTX0+tUxlfxg4A/hYRKys3OYB3wCOjYjfAMdWlsnMR4GbgMeAHwGf94hsSdJYePjhh7niiit47LHHePrpp7n33nt3ue3q1au58cYbuffee1m5ciVdXV1cd911ALz22mvMnDmTBx98kBkzZrB06VIeffRRHnnkEb761a829TkMO5Wdmfcw9OfGAHN3sc9FwEV11CVJ0ojNnj2bqVOnAjBr1iyeeeYZPvKRjwy57fLly1mxYgVHHHEEAH/84x/Zd9+B45i7urr41Kc+BcDb3vY2Jk2axNlnn80nPvEJTjzxxKY+hyIuYiFJUiPsscce2+93dXWxefPmXW6bmSxYsICLL754p3WTJk3a/rnyhAkTeOihh1i+fDk33HADV155JT/+8Y8bX3xF5wTzXVUdf8wFratDklSEuXPnMn/+fM477zz23XdfNmzYwMaNG3nXu961w3avvvoqr7/+OvPmzeOoo47iPe95T1Pr6pxgliSpyowZM/j617/Occcdx9atW5k4cSLf+ta3dgrmjRs3Mn/+fDZt2kRmcvnllze1rhjqiLWx1tvbm02/HrMjZklquNWrV/O+972v1WUUb6h+iogVmdk7eFuvLiVJUkEMZkmSCmIwS5JUEINZkqSCGMySJBXEYJYkqSAGsySpoyxZsoTnn3/zooelXRLSE4xIkhrnrp1Pb1mXJpx3YsmSJcycOZN3vvOdO60r4ZKQ7RvMjX5xSJKKddlll7F48WIAzj77bE466SROPPFEVq1aBcAll1zCq6++ysyZM+nr6+P0009nzz335P7779/hcXp6eujr62PKlClce+21fPOb3+RPf/oTRx55JFdddRVdXV3stddefPGLX+SOO+7g0ksv5bbbbmPZsmVMmDCB4447jksuuaSu5+JUtiRpXFuxYgXf+973ePDBB3nggQe4+uqreemll4bc9pRTTqG3t5frrruOlStXsueeew65XSsvCdm+I2ZJUke45557OPnkk3nrW98KwCc/+Ul+9rOf1fWYrbwkpMEsSRrXhrrmw8svv8zWrVu3L2/atGnEj9mqS0I6lS1JGteOPvpobr31Vl5//XVee+01li5dygknnMDatWtZv349b7zxBrfddtv27ffee282bty428ecO3cuN998M2vXrgVgw4YNPPvssztt9+qrr/LKK68wb948rrjiClauXFn383HELEka1w4//HDOPPNMZs+eDQwc/HXEEUdw4YUXcuSRRzJ9+nQOPfTQ7dufeeaZnHvuuUMe/LVNKy8J2b6XfdzdUdle9lGSGsLLPtbGyz5KkjROGcySJBXEYJYkqSAGsySpLiUcq1SykfaPwSxJGrVJkyaxfv16w3kXMpP169czadKkmvfx61KSpFGbOnUq/f39rFu3rtWlFGvSpElMnTq15u0NZknSqE2cOJHp06e3uoy24lS2JEkFMZglSSqIwSxJUkEMZkmSCmIwS5JUkGGDOSIWR8TaiFhV1XZjRKys3J6JiJWV9p6I+GPVuu80sXZJktpOLV+XWgJcCXx/W0Nm/sdt9yPiUuCVqu2fysxZDapPkqSOMmwwZ+bdEdEz1LqICOAzwMcaXJckSR2p3s+YPwq8kJm/qWqbHhEPR8RPI+Kju9oxIhZGRF9E9HnGGEmSBtQbzKcB11ctrwGmZeYHgS8C/xgRbxtqx8xclJm9mdnb3d1dZxmSJLWHUQdzREwAPgncuK0tM9/IzPWV+yuAp4BD6i1SkqROUc+I+T8Av87M/m0NEdEdEV2V+wcBBwNP11eiJEmdo5avS10P3A+8NyL6I+KsyqpT2XEaG+Bo4JGI+CVwM3BuZm5oZMGSJLWzWo7KPm0X7WcO0XYLcEv9ZUmS1Jk885ckSQUxmCVJKojBLElSQQxmSZIKYjBLklQQg1mSpIIYzJIkFcRgliSpIAazJEkFMZglSSqIwSxJUkEMZkmSCmIwS5JUEINZkqSCGMySJBXEYJYkqSAGsyRJBTGYJUkqiMEsSVJBDGZJkgpiMEuSVBCDWZKkghjMkiQVxGCWJKkgBrMkSQUxmCVJKojBLElSQQxmSZIKYjBLklQQg1mSpIIYzJIkFWTYYI6IxRGxNiJWVbX9fUT8PiJWVm7zqtZdEBFPRsTjEfHxZhUuSVI7qmXEvAQ4foj2yzNzVuV2O0BEzABOBd5f2eeqiOhqVLGSJLW7YYM5M+8GNtT4ePOBGzLzjcz8LfAkMLuO+iRJ6ij1fMb8hYh4pDLVvU+l7QDgd1Xb9FfadhIRCyOiLyL61q1bV0cZkiS1j9EG87eBdwOzgDXApZX2GGLbHOoBMnNRZvZmZm93d/coy5Akqb2MKpgz84XM3JKZW4GreXO6uh84sGrTqcDz9ZUoSVLnGFUwR8T+VYsnA9uO2F4GnBoRe0TEdOBg4KH6SpQkqXNMGG6DiLgemANMiYh+4GvAnIiYxcA09TPAOQCZ+WhE3AQ8BmwGPp+ZW5pSuSRJbWjYYM7M04Zo/u5utr8IuKieoiRJ6lSe+UuSpIIYzJIkFcRgliSpIAazJEkFMZglSSqIwSxJUkEMZkmSCmIwS5JUEINZkqSCGMySJBXEYJYkqSAGsyRJBTGYJUkqiMEsSVJBDGZJkgpiMEuSVBCDWZKkghjMkiQVxGCWJKkgBrMkSQUxmCVJKojBLElSQQxmSZIKYjBLklQQg1mSpIIYzJIkFcRgliSpIAazJEkFMZglSSqIwSxJUkGGDeaIWBwRayNiVVXb/4mIX0fEIxGxNCLeXmnviYg/RsTKyu07TaxdkqS2U8uIeQlw/KC2O4GZmXkY8ARwQdW6pzJzVuV2bmPKlCSpMwwbzJl5N7BhUNu/ZubmyuIDwNQm1CZJUsdpxGfM/xn4l6rl6RHxcET8NCI+2oDHlySpY0yoZ+eI+O/AZuC6StMaYFpmro+IvwRujYj3Z+Yfhth3IbAQYNq0afWUIUlS2xj1iDkiFgAnAqdnZgJk5huZub5yfwXwFHDIUPtn5qLM7M3M3u7u7tGWIUlSWxlVMEfE8cCXgb/KzNer2rsjoqty/yDgYODpRhQqSVInGHYqOyKuB+YAUyKiH/gaA0dh7wHcGREAD1SOwD4a+B8RsRnYApybmRuGfGBJkrSTYYM5M08bovm7u9j2FuCWeouSJKlTeeYvSZIKYjBLklQQg1mSpIIYzJIkFcRgliSpIAazJEkFMZglSSqIwSxJUkEMZkmSCmIwS5JUEINZkqSCGMySJBXEYJYkqSAGsyRJBTGYJUkqiMEsSVJBDGZJkgpiMEuSVBCDWZKkghjMkiQVxGCWJKkgBrMkSQUxmCVJKojBLElSQQxmSZIKYjBLklQQg1mSpIIYzJIkFcRgliSpIAazJEkFMZglSSrIsMEcEYsjYm1ErKpqe0dE3BkRv6n83Kdq3QUR8WREPB4RH29W4ZIktaNaRsxLgOMHtZ0PLM/Mg4HllWUiYgZwKvD+yj5XRURXw6qVJKnNDRvMmXk3sGFQ83zgmsr9a4CTqtpvyMw3MvO3wJPA7MaUKklS+xvtZ8z7ZeYagMrPfSvtBwC/q9quv9K2k4hYGBF9EdG3bt26UZYhSVJ7afTBXzFEWw61YWYuyszezOzt7u5ucBmSJI1Pow3mFyJif4DKz7WV9n7gwKrtpgLPj748SZI6y2iDeRmwoHJ/AfDDqvZTI2KPiJgOHAw8VF+JkiR1jgnDbRAR1wNzgCkR0Q98DfgGcFNEnAU8B3waIDMfjYibgMeAzcDnM3NLk2qXJKntDBvMmXnaLlbN3cX2FwEX1VOUJEmdyjN/SZJUEINZkqSCGMySJBXEYJYkqSAGsyRJBTGYJUkqiMEsSVJBDGZJkgpiMEuSVBCDWZKkghjMkiQVxGCWJKkgBrMkSQUxmCVJKojBLElSQQxmSZIKYjBLklQQg1mSpIIYzJIkFcRgliSpIBNaXUBL3HXxjsvHXNCaOiRJGsQRsyRJBTGYJUkqiMEsSVJBDGZJkgpiMEuSVBCDWZKkghjMkiQVxGCWJKkgBrMkSQUZ9Zm/IuK9wI1VTQcBFwJvB/4LsK7S/pXMvH20v0eSpE4y6mDOzMeBWQAR0QX8HlgKfA64PDMvaUSBkiR1kkZNZc8FnsrMZxv0eJIkdaRGBfOpwPVVy1+IiEciYnFE7NOg3yFJUturO5gj4i3AXwH/VGn6NvBuBqa51wCX7mK/hRHRFxF969atG2oTSZI6TiNGzCcAv8jMFwAy84XM3JKZW4GrgdlD7ZSZizKzNzN7u7u7G1CGJEnjXyOC+TSqprEjYv+qdScDqxrwOyRJ6gijPiobICL+AjgWOKeq+X9HxCwggWcGrZMkSbtRVzBn5uvA5EFtZ9RVkSRJHcwzf0mSVBCDWZKkghjMkiQVxGCWJKkgdR38pbJdfucTOyyfd+whLapEklQrR8ySJBXEYJYkqSAGsyRJBTGYJUkqiMEsSVJBDGZJkgpiMEuSVBCDWZKkghjMkiQVxGCWJKkgBrMkSQUxmCVJKojBLElSQQxmSZIKYjBLklQQr8cMcNfFOy4fc0Fr6pAkdTxHzJIkFcRgliSpIAazJEkFMZglSSqIwSxJUkEMZkmSCuLXpdpR5etfRz23HoAHpi1sZTWSpBFwxCxJUkEMZkmSCmIwS5JUkLo+Y46IZ4CNwBZgc2b2RsQ7gBuBHuAZ4DOZ+VJ9ZUqS1BkaMWI+JjNnZWZvZfl8YHlmHgwsryxLkqQaNGMqez5wTeX+NcBJTfgdkiS1pXqDOYF/jYgVEbHtOzn7ZeYagMrPfev8HZIkdYx6v8f84cx8PiL2Be6MiF/XumMlyBcCTJs2rc4yJElqD3WNmDPz+crPtcBSYDbwQkTsD1D5uXYX+y7KzN7M7O3u7q6nDEmS2saogzki3hoRe2+7DxwHrAKWAQsqmy0AflhvkZIkdYp6prL3A5ZGxLbH+cfM/FFE/By4KSLOAp4DPl1/mZIkdYZRB3NmPg18YIj29cDceoqSJKlTeeYvSZIKYjBLklQQg1mSpIIYzJIkFcRgliSpIAazJEkFMZglSSqIwSxJUkEMZkmSCmIwS5JUkHov+yh1tMvvfGKH5fOOPaRFlUhqF46YJUkqiMEsSVJBDGZJkgpiMEuSVBCDWZKkghjMkiQVxK9LqW2U+NWlEmuSVDaDWZKarLQ3aKXVox05lS1JUkEcMbfCXRfvuHzMBa2pQ5JUHEfMkiQVxBGzJA3Dz2Q1lhwxS5JUEINZkqSCGMySJBXEYJYkqSAGsyRJBfGobEkN5RHMagetfB0bzJI0zvjmp705lS1JUkFGHcwRcWBE3BURqyPi0Yj4m0r730fE7yNiZeU2r3HlSpLU3uqZyt4M/F1m/iIi9gZWRMSdlXWXZ+Yl9ZcnSVJnGXUwZ+YaYE3l/saIWA0c0KjCJEnqRA05+CsieoAPAg8CHwa+EBGfBfoYGFW/NMQ+C4GFANOmTWtEGdIOBh8gAx4kI6l8dR/8FRF7AbcAf5uZfwC+DbwbmMXAiPrSofbLzEWZ2ZuZvd3d3fWWIUlSW6grmCNiIgOhfF1m/gAgM1/IzC2ZuRW4Gphdf5mSJHWGUU9lR0QA3wVWZ+ZlVe37Vz5/BjgZWFVfiZK28furUvur5zPmDwNnAL+KiJWVtq8Ap0XELCCBZ4Bz6vgdkiR1lHqOyr4HiCFW3T76cjSkuy7ecfmYC1pThxrOEbCkwTzzlyRJBfFc2ZKaylkBaWQM5mZw6lmSmqqd3/A5lS1JUkEcMasY7fwOWOPLUGeNk8aKwTxO3P/0+u33H9j8hKElSW3KqWxJkgrSMSPm6hEnwL8/aHLtO3swl6QmqvdjHD8Gai8dE8ylcWq6NfwPTFLpnMqWJKkgHTtirmtqW5JUF2evds0RsyRJBenYEfOYGnzwWJvwHa86la99NZPB3AhtGrzSUAwlqbmcypYkqSCOmIfiCLhjOPqTxoanOa2dwVzR6KO0Pepbqk07vjkyhFQPp7IlSSpI246YB49YJUntq51mXhwxS5JUkLYdMetNRz23aODOXZO9AEcj3XUxRz1Xdc7zaQtbWExthvrsczyPLKTRKnmEbTBru5JfqK1in7TfgUz+m6p0TmVLklQQR8wFOOq5RQPTzNs43awatePorx2fkzQSBvMuNPt7zbtd//SXxuR7zyOdoixySrPqZDBHPbd+XHzOW7rSXxcG98gV+bc7Qu3wHGrlVLYkSQVxxNwgY/m96ZKmvrcf8Q2jO+p7nI14q9+1Vx+RPZ510khEjdPomYtWz4SU9HdgMI+G59KuSav/0CQo6z/c0WqH59Bq46kPncqWJKkgjphHqV1O+bnDVDTDnyRj8PY7qXNqut6p8ZE+n532bfFHBM4yjL3xNJJqlka87nztNk7TRswRcXxEPB4RT0bE+c36PZIktZOmjJgjogv4FnAs0A/8PCKWZeZjzfh97WikI/KaD0oaNKId1ki3342hRibtcgDVNk0dfdVzCtDKv+O2/Uc6M1L6QXkla5e+dGZh7DRrKns28GRmPg0QETcA8wGDuRkG/YddkmGnvluolmn5kQRhTc91hFPlu3vDVct/+Nv2H27fZqv76P2CDNvvNfw9NjvkdvX4w/27N/xNwxh+62Ln53bJbteX/AapWVPZBwC/q1rur7RJkqTdiMxs/INGfBr4eGaeXVk+A5idmX9dtc1CYNtblvcCj9f5a6cAL9b5GLIfG8V+rJ992Bj2Y2M0ox/flZndgxubNZXdDxxYtTwVeL56g8xcBDRsPi0i+jKzt1GP16nsx8awH+tnHzaG/dgYY9mPzZrK/jlwcERMj4i3AKcCy5r0uyRJahtNGTFn5uaI+AJwB9AFLM7MR5vxuyRJaidNO8FIZt4O3N6sxx9CuYf/ji/2Y2PYj/WzDxvDfmyMMevHphz8JUmSRsdzZUuSVJBxFczDneYzBnyzsv6RiDi8FXWWroZ+PL3Sf49ExH0R8YFW1Fm6Wk87GxFHRMSWiDhlLOsbL2rpx4iYExErI+LRiPjpWNc4HtTwd/1vI+KfI+KXlX78XCvqLF1ELI6ItRGxahfrm58zmTkubgwcRPYUcBDwFuCXwIxB28wD/gUI4CjgwVbXXdqtxn78ELBP5f4J9uPo+rFqux8zcLzFKa2uu7Rbja/HtzNw1sBpleV9W113abca+/ErwP+q3O8GNgBvaXXtpd2Ao4HDgVW7WN/0nBlPI+btp/nMzD8B207zWW0+8P0c8ADw9ojYf6wLLdyw/ZiZ92XmS5XFBxj4Hrp2VMvrEeCvgVuAtWNZ3DhSSz/+J+AHmfkcQGbalzurpR8T2DsiAtiLgWDePLZlli8z72agb3al6TkznoK5ltN8eirQ4Y20j85i4N2hdjRsP0bEAcDJwHfGsK7xppbX4yHAPhHxk4hYERGfHbPqxo9a+vFK4H0MnOzpV8DfZObWsSmvrTQ9Z8bT9ZhjiLbBh5TXsk2nq7mPIuIYBoL5I02taHyqpR+vAL6cmVsGBikaQi39OAH4S2AusCdwf0Q8kJle7uhNtfTjx4GVwMeAdwN3RsTPMvMPTa6t3TQ9Z8ZTMA97ms8at+l0NfVRRBwG/ANwQmaWeemq1qqlH3uBGyqhPAWYFxGbM/PWMalwfKj17/rFzHwNeC0i7gY+ABjMb6qlHz8HfCMHPih9MiJ+CxwKPDQ2JbaNpufMeJrKruU0n8uAz1aOmjsKeCUz14x1oYUbth8jYhrwA+AMRyW7NGw/Zub0zOzJzB7gZuC/Gso7qeXv+ofARyNiQkT8BXAksHqM6yxdLf34HAOzDkTEfgxcPOjpMa2yPTQ9Z8bNiDl3cZrPiDi3sv47DBz5Og94EnidgXeIqlJjP14ITAauqoz2Nqcnwd9Bjf2oYdTSj5m5OiJ+BDwCbAX+ITOH/CpLp6rx9fg/gSUR8SsGpmO/nJledWqQiLgemANMiYh+4GvARBi7nPHMX5IkFWQ8TWVLktT2DGZJkgpiMEuSVBCDWZKkghjMkiQVxGCWJKkgBrMkSQUxmCVJKsj/B7AMSbCc5M5XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pvals(pvals_naive, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f073b0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply BH procedure yields FDP 0.034444, power 0.684146.\n"
     ]
    }
   ],
   "source": [
    "fdp, power = evaluate_bh(pvals_naive, labels, alpha=0.1)\n",
    "print('Apply BH procedure yields FDP {:3f}, power {:3f}.'.format(fdp,power))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce92c3d",
   "metadata": {},
   "source": [
    "# Experiment 2: CES for multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd35b4",
   "metadata": {},
   "source": [
    "### Load CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2347282b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "num_workers = 2\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a2e0e3",
   "metadata": {},
   "source": [
    "### Benchmark data-splitting vs CES data-splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ad14339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "num_workers = 0\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "# MNIST is a simple dataset, hence we only take 300 inlier data to demonstrate\n",
    "# Benchmark data splitting: equally split the data into 3 sets\n",
    "n_full = len(train_set)\n",
    "n_train_bm = 2000\n",
    "n_val_bm = 1000\n",
    "n_cal_bm = 1000\n",
    "n_data = n_train_bm + n_val_bm + n_cal_bm\n",
    "\n",
    "train_set_bm, val_set_bm, cal_set_bm, _ = th.utils.data.random_split(train_set,\\\n",
    "                                 [n_train_bm, n_val_bm, n_cal_bm, n_full-n_data])\n",
    "\n",
    "# CES data splitting: calibration set is not needed, merge back to the training set\n",
    "n_train_ces = 3000\n",
    "n_val_ces = 1000\n",
    "\n",
    "train_set_ces, val_set_ces, _ = th.utils.data.random_split(train_set,\\\n",
    "                                 [n_train_ces, n_val_ces, n_full-n_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bb1c3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader objects\n",
    "# For benchmarks\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "train_loader_bm = th.utils.data.DataLoader(train_set_bm, batch_size=batch_size,\n",
    "                                          num_workers=num_workers)\n",
    "\n",
    "val_loader_bm = th.utils.data.DataLoader(val_set_bm, batch_size=100,\n",
    "                                          num_workers=num_workers)\n",
    "\n",
    "cal_loader_bm = th.utils.data.DataLoader(cal_set_bm, batch_size=100,\n",
    "                                          num_workers=num_workers)\n",
    "\n",
    "# For CES\n",
    "train_loader_ces = th.utils.data.DataLoader(train_set_ces, batch_size=batch_size,\n",
    "                                          num_workers=num_workers)\n",
    "\n",
    "val_loader_ces = th.utils.data.DataLoader(val_set_ces, batch_size=100,\n",
    "                                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ef207634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loader\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "n_test_samples = 2000\n",
    "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))\n",
    "test_loader = th.utils.data.DataLoader(test_set, batch_size=n_test_samples, sampler=test_sampler,\n",
    "                                         num_workers=num_workers)\n",
    "\n",
    "# get all test images\n",
    "dataiter = iter(test_loader)\n",
    "inputs, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e937e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      bird      plane       deer       bird\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some sample test data\n",
    "\n",
    "imshow(torchvision.utils.make_grid(inputs[:4]), norm=True)\n",
    "# print labels\n",
    "print(' '.join('{:>10}'.format(classes[labels[j]]) for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6736101f",
   "metadata": {},
   "source": [
    "### Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "120567b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from method import CES_multiClass\n",
    "from networks import SimpleConvolutionalNetwork\n",
    "from inference import Conformal_PSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "308a9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the model parameters\n",
    "lr = 0.0001\n",
    "n_epoch = 5\n",
    "n_classes = len(classes)\n",
    "\n",
    "# Create loss and optimizer\n",
    "# CES_oneClass object will assume criterion takes three parameters: output, input and target, \n",
    "# create wrapper function to modify the criterion.\n",
    "net_bm = SimpleConvolutionalNetwork()\n",
    "Loss = th.nn.CrossEntropyLoss()\n",
    "def criterion(outputs, inputs, targets):\n",
    "    return Loss(outputs, targets)\n",
    "optimizer_bm = optim.Adam(net_bm.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7635afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "if th.cuda.is_available():\n",
    "    # Make CuDNN Determinist\n",
    "    th.backends.cudnn.deterministic = True\n",
    "    th.cuda.manual_seed(seed)\n",
    "\n",
    "# Define default device, we should use the GPU (cuda) if available\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")### Define subset of the dataset (so it is faster to train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029c7637",
   "metadata": {},
   "source": [
    "### Train the benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "574cc622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 64\n",
      "n_epochs= 5\n",
      "learning_rate= 0.0001\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "# Initialize the CES class with model parameters\n",
    "CES_mc_bm = CES_multiClass(net_bm, device, train_loader_bm, n_classes=n_classes, batch_size=batch_size, max_epoch=n_epoch, \n",
    "                        learning_rate=lr, val_loader=val_loader_bm, criterion=criterion,optimizer=optimizer_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c7d6cd69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 5, 9% \t train_loss: 2.32 train_acc: 10.94% took: 7.49s\n",
      "Epoch 1 of 5, 18% \t train_loss: 2.30 train_acc: 9.38% took: 0.11s\n",
      "Epoch 1 of 5, 28% \t train_loss: 2.29 train_acc: 13.02% took: 0.11s\n",
      "Epoch 1 of 5, 37% \t train_loss: 2.27 train_acc: 16.67% took: 0.09s\n",
      "Epoch 1 of 5, 46% \t train_loss: 2.26 train_acc: 15.10% took: 0.12s\n",
      "Epoch 1 of 5, 56% \t train_loss: 2.26 train_acc: 18.75% took: 0.10s\n",
      "Epoch 1 of 5, 65% \t train_loss: 2.22 train_acc: 21.35% took: 0.11s\n",
      "Epoch 1 of 5, 75% \t train_loss: 2.22 train_acc: 21.88% took: 0.09s\n",
      "Epoch 1 of 5, 84% \t train_loss: 2.19 train_acc: 19.27% took: 0.11s\n",
      "Epoch 1 of 5, 93% \t train_loss: 2.19 train_acc: 16.15% took: 0.10s\n",
      "val_loss = 2.18 val_acc = 16.20%\n",
      "Snapshot saved at epoch 1.\n",
      "Epoch 2 of 5, 9% \t train_loss: 2.17 train_acc: 19.27% took: 7.59s\n",
      "Epoch 2 of 5, 18% \t train_loss: 2.15 train_acc: 19.27% took: 0.11s\n",
      "Epoch 2 of 5, 28% \t train_loss: 2.15 train_acc: 21.35% took: 0.11s\n",
      "Epoch 2 of 5, 37% \t train_loss: 2.12 train_acc: 23.96% took: 0.09s\n",
      "Epoch 2 of 5, 46% \t train_loss: 2.12 train_acc: 27.60% took: 0.11s\n",
      "Epoch 2 of 5, 56% \t train_loss: 2.10 train_acc: 28.65% took: 0.11s\n",
      "Epoch 2 of 5, 65% \t train_loss: 2.07 train_acc: 26.04% took: 0.11s\n",
      "Epoch 2 of 5, 75% \t train_loss: 2.08 train_acc: 26.56% took: 0.11s\n",
      "Epoch 2 of 5, 84% \t train_loss: 2.06 train_acc: 29.69% took: 0.11s\n",
      "Epoch 2 of 5, 93% \t train_loss: 2.06 train_acc: 28.12% took: 0.11s\n",
      "val_loss = 2.07 val_acc = 22.40%\n",
      "Snapshot saved at epoch 2.\n",
      "Epoch 3 of 5, 9% \t train_loss: 2.05 train_acc: 29.17% took: 7.32s\n",
      "Epoch 3 of 5, 18% \t train_loss: 2.03 train_acc: 26.04% took: 0.10s\n",
      "Epoch 3 of 5, 28% \t train_loss: 2.04 train_acc: 27.60% took: 0.10s\n",
      "Epoch 3 of 5, 37% \t train_loss: 2.01 train_acc: 31.25% took: 0.10s\n",
      "Epoch 3 of 5, 46% \t train_loss: 2.01 train_acc: 30.21% took: 0.11s\n",
      "Epoch 3 of 5, 56% \t train_loss: 2.01 train_acc: 30.73% took: 0.12s\n",
      "Epoch 3 of 5, 65% \t train_loss: 1.95 train_acc: 34.38% took: 0.11s\n",
      "Epoch 3 of 5, 75% \t train_loss: 1.98 train_acc: 30.73% took: 0.11s\n",
      "Epoch 3 of 5, 84% \t train_loss: 1.96 train_acc: 34.38% took: 0.11s\n",
      "Epoch 3 of 5, 93% \t train_loss: 1.95 train_acc: 35.42% took: 0.12s\n",
      "val_loss = 1.99 val_acc = 27.90%\n",
      "Snapshot saved at epoch 3.\n",
      "Epoch 4 of 5, 9% \t train_loss: 1.95 train_acc: 34.38% took: 7.43s\n",
      "Epoch 4 of 5, 18% \t train_loss: 1.95 train_acc: 33.85% took: 0.10s\n",
      "Epoch 4 of 5, 28% \t train_loss: 1.95 train_acc: 35.94% took: 0.10s\n",
      "Epoch 4 of 5, 37% \t train_loss: 1.91 train_acc: 34.38% took: 0.10s\n",
      "Epoch 4 of 5, 46% \t train_loss: 1.92 train_acc: 31.77% took: 0.11s\n",
      "Epoch 4 of 5, 56% \t train_loss: 1.96 train_acc: 31.25% took: 0.10s\n",
      "Epoch 4 of 5, 65% \t train_loss: 1.85 train_acc: 35.94% took: 0.10s\n",
      "Epoch 4 of 5, 75% \t train_loss: 1.90 train_acc: 32.81% took: 0.09s\n",
      "Epoch 4 of 5, 84% \t train_loss: 1.89 train_acc: 36.46% took: 0.12s\n",
      "Epoch 4 of 5, 93% \t train_loss: 1.86 train_acc: 40.62% took: 0.10s\n",
      "val_loss = 1.93 val_acc = 31.50%\n",
      "Snapshot saved at epoch 4.\n",
      "Epoch 5 of 5, 9% \t train_loss: 1.88 train_acc: 36.98% took: 8.07s\n",
      "Epoch 5 of 5, 18% \t train_loss: 1.88 train_acc: 34.38% took: 0.11s\n",
      "Epoch 5 of 5, 28% \t train_loss: 1.88 train_acc: 39.58% took: 0.10s\n",
      "Epoch 5 of 5, 37% \t train_loss: 1.85 train_acc: 38.54% took: 0.09s\n",
      "Epoch 5 of 5, 46% \t train_loss: 1.85 train_acc: 33.33% took: 0.11s\n",
      "Epoch 5 of 5, 56% \t train_loss: 1.90 train_acc: 35.42% took: 0.11s\n",
      "Epoch 5 of 5, 65% \t train_loss: 1.77 train_acc: 41.15% took: 0.11s\n",
      "Epoch 5 of 5, 75% \t train_loss: 1.83 train_acc: 34.90% took: 0.11s\n",
      "Epoch 5 of 5, 84% \t train_loss: 1.84 train_acc: 38.54% took: 0.10s\n",
      "Epoch 5 of 5, 93% \t train_loss: 1.79 train_acc: 43.23% took: 0.12s\n",
      "val_loss = 1.89 val_acc = 33.90%\n",
      "Snapshot saved at epoch 5.\n",
      "Training done! A list of 5 models saved.\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save snapshots regularly\n",
    "save_every = 1    # Save model after every few epoches\n",
    "CES_mc_bm.full_train(save_dir = './models/multiClass/benchmarks', save_every = save_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "874bebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Calibrating each model in the list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:39<00:00,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization done!\n",
      "Calibration (one time effort) takes:39.81s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from inference import Conformal_PSet\n",
    "\n",
    "alpha = 0.1\n",
    "n_classes = len(classes)\n",
    "model_list_bm = CES_mc_bm.model_list     # Get the saved model list from the CES class\n",
    "\n",
    "# Compute conformity scores of calibration sets for each model and corresponding calibrated\n",
    "# confidence level, this might take some time if we have too many saved models but fortunately\n",
    "# this initialization will be a one-time effort.\n",
    "cal_time = time.time()\n",
    "C_PSet_bm = Conformal_PSet(net_bm, device, cal_loader_bm, n_classes, model_list_bm, \\\n",
    "                           alpha, lc=True, random_state=0)\n",
    "print('Calibration (one time effort) takes:{:.2f}s.'.format(time.time()-cal_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9a19caed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting models takes: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Pick the best model for each test point\n",
    "start = time.time()\n",
    "best_loss_bm, best_model_bm, test_val_loss_history_bm = CES_mc_bm.select_model()\n",
    "print('selecting models takes:', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "01f318c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [01:33<00:00, 21.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing marginal prediction sets for 2000 test points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [01:32<00:00, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing label conditional prediction sets for 2000 test points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the marginal conformal pvalues \n",
    "pset_m_bm= C_PSet_bm.pred_set(inputs, [[best_model_bm]*n_classes]*len(inputs), marginal=True)\n",
    "# Get the label conditional conformal pvalues \n",
    "pset_lc_bm = C_PSet_bm.pred_set(inputs, [[best_model_bm]*n_classes]*len(inputs), marginal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5e509aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate marginal prediction sets.\n",
      "==================================================\n",
      "Marginal coverage:       91.900%\n",
      "Average size:            6.577\n",
      "Average size | coverage: 6.580\n",
      "==================================================\n",
      "Conditional coverage for label plane:       88.265%\n",
      "Average size:            5.949\n",
      "Average size | coverage: 5.809\n",
      "Conditional coverage for label car:       94.444%\n",
      "Average size:            6.576\n",
      "Average size | coverage: 6.615\n",
      "Conditional coverage for label bird:       92.821%\n",
      "Average size:            6.687\n",
      "Average size | coverage: 6.901\n",
      "Conditional coverage for label cat:       97.990%\n",
      "Average size:            6.970\n",
      "Average size | coverage: 6.985\n",
      "Conditional coverage for label deer:       85.859%\n",
      "Average size:            6.773\n",
      "Average size | coverage: 6.829\n",
      "Conditional coverage for label dog:       88.108%\n",
      "Average size:            6.962\n",
      "Average size | coverage: 6.982\n",
      "Conditional coverage for label frog:       93.056%\n",
      "Average size:            6.681\n",
      "Average size | coverage: 6.617\n",
      "Conditional coverage for label horse:       94.301%\n",
      "Average size:            7.052\n",
      "Average size | coverage: 7.060\n",
      "Conditional coverage for label ship:       91.705%\n",
      "Average size:            5.756\n",
      "Average size | coverage: 5.613\n",
      "Conditional coverage for label truck:       92.118%\n",
      "Average size:            6.473\n",
      "Average size | coverage: 6.471\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate marginal prediction sets.')\n",
    "print('='*50)\n",
    "evaluate_marginal(pset_m_bm, labels.numpy())\n",
    "print('='*50)\n",
    "evaluate_conditional(pset_m_bm, labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ddc03931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate label conditional prediction sets.\n",
      "==================================================\n",
      "Marginal coverage:       92.950%\n",
      "Average size:            6.721\n",
      "Average size | coverage: 6.748\n",
      "==================================================\n",
      "Conditional coverage for label plane:       91.327%\n",
      "Average size:            5.995\n",
      "Average size | coverage: 5.939\n",
      "Conditional coverage for label car:       92.424%\n",
      "Average size:            6.758\n",
      "Average size | coverage: 6.831\n",
      "Conditional coverage for label bird:       89.744%\n",
      "Average size:            6.826\n",
      "Average size | coverage: 7.120\n",
      "Conditional coverage for label cat:       97.487%\n",
      "Average size:            7.060\n",
      "Average size | coverage: 7.082\n",
      "Conditional coverage for label deer:       91.414%\n",
      "Average size:            6.874\n",
      "Average size | coverage: 6.934\n",
      "Conditional coverage for label dog:       95.676%\n",
      "Average size:            7.086\n",
      "Average size | coverage: 7.119\n",
      "Conditional coverage for label frog:       96.759%\n",
      "Average size:            6.769\n",
      "Average size | coverage: 6.722\n",
      "Conditional coverage for label horse:       90.155%\n",
      "Average size:            7.332\n",
      "Average size | coverage: 7.356\n",
      "Conditional coverage for label ship:       92.166%\n",
      "Average size:            5.871\n",
      "Average size | coverage: 5.715\n",
      "Conditional coverage for label truck:       92.118%\n",
      "Average size:            6.749\n",
      "Average size | coverage: 6.781\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate label conditional prediction sets.')\n",
    "print('='*50)\n",
    "evaluate_marginal(pset_lc_bm, labels.numpy())\n",
    "print('='*50)\n",
    "evaluate_conditional(pset_lc_bm, labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c13488e",
   "metadata": {},
   "source": [
    "### Train the CES model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64c30956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 64\n",
      "n_epochs= 10\n",
      "learning_rate= 0.001\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "net_ces = SimpleConvolutionalNetwork()\n",
    "Loss = th.nn.CrossEntropyLoss()\n",
    "def criterion(outputs, inputs, targets):\n",
    "    return Loss(outputs, targets)\n",
    "optimizer_ces = optim.Adam(net_ces.parameters(), lr=lr)\n",
    "\n",
    "# Initialize the CES class with model parameters\n",
    "CES_mc_ces = CES_multiClass(net_ces, device, train_loader_ces, n_classes=n_classes, batch_size=batch_size, max_epoch=n_epoch, \n",
    "                        learning_rate=lr, val_loader=val_loader_ces, criterion=criterion,optimizer=optimizer_ces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "674b6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "\n",
    "if th.cuda.is_available():\n",
    "    # Make CuDNN Determinist\n",
    "    th.backends.cudnn.deterministic = True\n",
    "    th.cuda.manual_seed(seed)\n",
    "\n",
    "# Define default device, we should use the GPU (cuda) if available\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")### Define subset of the dataset (so it is faster to train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bf1f0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10, 8% \t train_loss: 2.26 train_acc: 17.97% took: 5.57s\n",
      "Epoch 1 of 10, 17% \t train_loss: 2.22 train_acc: 16.41% took: 0.07s\n",
      "Epoch 1 of 10, 25% \t train_loss: 2.11 train_acc: 25.39% took: 0.06s\n",
      "Epoch 1 of 10, 34% \t train_loss: 2.05 train_acc: 28.91% took: 0.07s\n",
      "Epoch 1 of 10, 42% \t train_loss: 2.05 train_acc: 23.05% took: 0.06s\n",
      "Epoch 1 of 10, 51% \t train_loss: 2.06 train_acc: 25.78% took: 0.08s\n",
      "Epoch 1 of 10, 59% \t train_loss: 2.01 train_acc: 27.73% took: 0.07s\n",
      "Epoch 1 of 10, 68% \t train_loss: 1.96 train_acc: 28.12% took: 0.06s\n",
      "Epoch 1 of 10, 76% \t train_loss: 1.93 train_acc: 28.12% took: 0.06s\n",
      "Epoch 1 of 10, 85% \t train_loss: 1.79 train_acc: 39.45% took: 0.08s\n",
      "Epoch 1 of 10, 93% \t train_loss: 1.90 train_acc: 31.64% took: 0.06s\n",
      "val_loss = 1.83 val_acc = 34.20%\n",
      "Snapshot saved at epoch 1.\n",
      "Epoch 2 of 10, 8% \t train_loss: 1.77 train_acc: 36.72% took: 5.86s\n",
      "Epoch 2 of 10, 17% \t train_loss: 1.77 train_acc: 40.23% took: 0.07s\n",
      "Epoch 2 of 10, 25% \t train_loss: 1.79 train_acc: 35.94% took: 0.07s\n",
      "Epoch 2 of 10, 34% \t train_loss: 1.72 train_acc: 39.84% took: 0.06s\n",
      "Epoch 2 of 10, 42% \t train_loss: 1.76 train_acc: 36.72% took: 0.08s\n",
      "Epoch 2 of 10, 51% \t train_loss: 1.72 train_acc: 38.67% took: 0.07s\n",
      "Epoch 2 of 10, 59% \t train_loss: 1.79 train_acc: 35.16% took: 0.06s\n",
      "Epoch 2 of 10, 68% \t train_loss: 1.74 train_acc: 34.38% took: 0.06s\n",
      "Epoch 2 of 10, 76% \t train_loss: 1.73 train_acc: 39.84% took: 0.06s\n",
      "Epoch 2 of 10, 85% \t train_loss: 1.53 train_acc: 49.22% took: 0.06s\n",
      "Epoch 2 of 10, 93% \t train_loss: 1.67 train_acc: 41.02% took: 0.06s\n",
      "val_loss = 1.69 val_acc = 37.80%\n",
      "Snapshot saved at epoch 2.\n",
      "Epoch 3 of 10, 8% \t train_loss: 1.57 train_acc: 45.70% took: 6.06s\n",
      "Epoch 3 of 10, 17% \t train_loss: 1.54 train_acc: 46.48% took: 0.07s\n",
      "Epoch 3 of 10, 25% \t train_loss: 1.59 train_acc: 46.09% took: 0.07s\n",
      "Epoch 3 of 10, 34% \t train_loss: 1.50 train_acc: 50.00% took: 0.08s\n",
      "Epoch 3 of 10, 42% \t train_loss: 1.55 train_acc: 43.75% took: 0.07s\n",
      "Epoch 3 of 10, 51% \t train_loss: 1.51 train_acc: 47.27% took: 0.07s\n",
      "Epoch 3 of 10, 59% \t train_loss: 1.62 train_acc: 41.41% took: 0.07s\n",
      "Epoch 3 of 10, 68% \t train_loss: 1.59 train_acc: 45.70% took: 0.07s\n",
      "Epoch 3 of 10, 76% \t train_loss: 1.56 train_acc: 46.09% took: 0.07s\n",
      "Epoch 3 of 10, 85% \t train_loss: 1.37 train_acc: 57.42% took: 0.07s\n",
      "Epoch 3 of 10, 93% \t train_loss: 1.49 train_acc: 48.44% took: 0.07s\n",
      "val_loss = 1.61 val_acc = 40.30%\n",
      "Snapshot saved at epoch 3.\n",
      "Epoch 4 of 10, 8% \t train_loss: 1.42 train_acc: 50.00% took: 6.07s\n",
      "Epoch 4 of 10, 17% \t train_loss: 1.39 train_acc: 51.95% took: 0.07s\n",
      "Epoch 4 of 10, 25% \t train_loss: 1.46 train_acc: 51.95% took: 0.07s\n",
      "Epoch 4 of 10, 34% \t train_loss: 1.34 train_acc: 56.64% took: 0.07s\n",
      "Epoch 4 of 10, 42% \t train_loss: 1.41 train_acc: 50.39% took: 0.07s\n",
      "Epoch 4 of 10, 51% \t train_loss: 1.38 train_acc: 51.17% took: 0.07s\n",
      "Epoch 4 of 10, 59% \t train_loss: 1.50 train_acc: 46.88% took: 0.07s\n",
      "Epoch 4 of 10, 68% \t train_loss: 1.44 train_acc: 48.05% took: 0.06s\n",
      "Epoch 4 of 10, 76% \t train_loss: 1.43 train_acc: 48.44% took: 0.08s\n",
      "Epoch 4 of 10, 85% \t train_loss: 1.25 train_acc: 58.98% took: 0.08s\n",
      "Epoch 4 of 10, 93% \t train_loss: 1.34 train_acc: 54.69% took: 0.06s\n",
      "val_loss = 1.59 val_acc = 41.60%\n",
      "Snapshot saved at epoch 4.\n",
      "Epoch 5 of 10, 8% \t train_loss: 1.30 train_acc: 53.12% took: 6.23s\n",
      "Epoch 5 of 10, 17% \t train_loss: 1.28 train_acc: 53.52% took: 0.06s\n",
      "Epoch 5 of 10, 25% \t train_loss: 1.34 train_acc: 53.91% took: 0.06s\n",
      "Epoch 5 of 10, 34% \t train_loss: 1.23 train_acc: 58.20% took: 0.06s\n",
      "Epoch 5 of 10, 42% \t train_loss: 1.29 train_acc: 55.47% took: 0.07s\n",
      "Epoch 5 of 10, 51% \t train_loss: 1.26 train_acc: 56.25% took: 0.06s\n",
      "Epoch 5 of 10, 59% \t train_loss: 1.39 train_acc: 50.78% took: 0.06s\n",
      "Epoch 5 of 10, 68% \t train_loss: 1.32 train_acc: 53.12% took: 0.06s\n",
      "Epoch 5 of 10, 76% \t train_loss: 1.32 train_acc: 51.95% took: 0.07s\n",
      "Epoch 5 of 10, 85% \t train_loss: 1.15 train_acc: 63.67% took: 0.07s\n",
      "Epoch 5 of 10, 93% \t train_loss: 1.23 train_acc: 58.59% took: 0.06s\n",
      "val_loss = 1.58 val_acc = 42.40%\n",
      "Snapshot saved at epoch 5.\n",
      "Epoch 6 of 10, 8% \t train_loss: 1.19 train_acc: 58.98% took: 6.57s\n",
      "Epoch 6 of 10, 17% \t train_loss: 1.18 train_acc: 57.03% took: 0.10s\n",
      "Epoch 6 of 10, 25% \t train_loss: 1.24 train_acc: 58.59% took: 0.09s\n",
      "Epoch 6 of 10, 34% \t train_loss: 1.13 train_acc: 61.33% took: 0.09s\n",
      "Epoch 6 of 10, 42% \t train_loss: 1.17 train_acc: 60.94% took: 0.11s\n",
      "Epoch 6 of 10, 51% \t train_loss: 1.16 train_acc: 59.77% took: 0.10s\n",
      "Epoch 6 of 10, 59% \t train_loss: 1.31 train_acc: 55.08% took: 0.10s\n",
      "Epoch 6 of 10, 68% \t train_loss: 1.21 train_acc: 56.25% took: 0.11s\n",
      "Epoch 6 of 10, 76% \t train_loss: 1.23 train_acc: 55.86% took: 0.11s\n",
      "Epoch 6 of 10, 85% \t train_loss: 1.06 train_acc: 68.75% took: 0.11s\n",
      "Epoch 6 of 10, 93% \t train_loss: 1.14 train_acc: 62.50% took: 0.10s\n",
      "val_loss = 1.58 val_acc = 43.10%\n",
      "Snapshot saved at epoch 6.\n",
      "Epoch 7 of 10, 8% \t train_loss: 1.09 train_acc: 62.11% took: 6.53s\n",
      "Epoch 7 of 10, 17% \t train_loss: 1.09 train_acc: 60.55% took: 0.10s\n",
      "Epoch 7 of 10, 25% \t train_loss: 1.15 train_acc: 62.50% took: 0.09s\n",
      "Epoch 7 of 10, 34% \t train_loss: 1.05 train_acc: 65.23% took: 0.09s\n",
      "Epoch 7 of 10, 42% \t train_loss: 1.08 train_acc: 63.28% took: 0.10s\n",
      "Epoch 7 of 10, 51% \t train_loss: 1.07 train_acc: 64.84% took: 0.10s\n",
      "Epoch 7 of 10, 59% \t train_loss: 1.22 train_acc: 57.81% took: 0.10s\n",
      "Epoch 7 of 10, 68% \t train_loss: 1.10 train_acc: 61.33% took: 0.11s\n",
      "Epoch 7 of 10, 76% \t train_loss: 1.13 train_acc: 60.16% took: 0.09s\n",
      "Epoch 7 of 10, 85% \t train_loss: 0.98 train_acc: 71.09% took: 0.11s\n",
      "Epoch 7 of 10, 93% \t train_loss: 1.04 train_acc: 67.58% took: 0.11s\n",
      "val_loss = 1.58 val_acc = 44.00%\n",
      "Snapshot saved at epoch 7.\n",
      "Epoch 8 of 10, 8% \t train_loss: 0.99 train_acc: 67.19% took: 7.32s\n",
      "Epoch 8 of 10, 17% \t train_loss: 1.00 train_acc: 64.06% took: 0.12s\n",
      "Epoch 8 of 10, 25% \t train_loss: 1.07 train_acc: 63.28% took: 0.11s\n",
      "Epoch 8 of 10, 34% \t train_loss: 0.97 train_acc: 70.70% took: 0.14s\n",
      "Epoch 8 of 10, 42% \t train_loss: 0.99 train_acc: 68.75% took: 0.10s\n",
      "Epoch 8 of 10, 51% \t train_loss: 0.99 train_acc: 68.75% took: 0.11s\n",
      "Epoch 8 of 10, 59% \t train_loss: 1.14 train_acc: 60.16% took: 0.11s\n",
      "Epoch 8 of 10, 68% \t train_loss: 1.00 train_acc: 66.80% took: 0.11s\n",
      "Epoch 8 of 10, 76% \t train_loss: 1.05 train_acc: 62.89% took: 0.11s\n",
      "Epoch 8 of 10, 85% \t train_loss: 0.90 train_acc: 71.48% took: 0.11s\n",
      "Epoch 8 of 10, 93% \t train_loss: 0.96 train_acc: 68.75% took: 0.11s\n",
      "val_loss = 1.60 val_acc = 44.30%\n",
      "Snapshot saved at epoch 8.\n",
      "Epoch 9 of 10, 8% \t train_loss: 0.91 train_acc: 69.53% took: 7.24s\n",
      "Epoch 9 of 10, 17% \t train_loss: 0.91 train_acc: 69.14% took: 0.09s\n",
      "Epoch 9 of 10, 25% \t train_loss: 0.99 train_acc: 68.36% took: 0.10s\n",
      "Epoch 9 of 10, 34% \t train_loss: 0.89 train_acc: 73.05% took: 0.10s\n",
      "Epoch 9 of 10, 42% \t train_loss: 0.90 train_acc: 70.70% took: 0.11s\n",
      "Epoch 9 of 10, 51% \t train_loss: 0.91 train_acc: 70.70% took: 0.12s\n",
      "Epoch 9 of 10, 59% \t train_loss: 1.05 train_acc: 64.84% took: 0.12s\n",
      "Epoch 9 of 10, 68% \t train_loss: 0.91 train_acc: 70.31% took: 0.12s\n",
      "Epoch 9 of 10, 76% \t train_loss: 0.97 train_acc: 65.62% took: 0.12s\n",
      "Epoch 9 of 10, 85% \t train_loss: 0.82 train_acc: 75.39% took: 0.12s\n",
      "Epoch 9 of 10, 93% \t train_loss: 0.88 train_acc: 71.88% took: 0.12s\n",
      "val_loss = 1.61 val_acc = 45.10%\n",
      "Snapshot saved at epoch 9.\n",
      "Epoch 10 of 10, 8% \t train_loss: 0.82 train_acc: 73.44% took: 7.55s\n",
      "Epoch 10 of 10, 17% \t train_loss: 0.82 train_acc: 73.05% took: 0.10s\n",
      "Epoch 10 of 10, 25% \t train_loss: 0.90 train_acc: 70.70% took: 0.09s\n",
      "Epoch 10 of 10, 34% \t train_loss: 0.81 train_acc: 74.22% took: 0.10s\n",
      "Epoch 10 of 10, 42% \t train_loss: 0.81 train_acc: 74.22% took: 0.11s\n",
      "Epoch 10 of 10, 51% \t train_loss: 0.83 train_acc: 73.05% took: 0.12s\n",
      "Epoch 10 of 10, 59% \t train_loss: 0.98 train_acc: 66.80% took: 0.12s\n",
      "Epoch 10 of 10, 68% \t train_loss: 0.82 train_acc: 73.83% took: 0.13s\n",
      "Epoch 10 of 10, 76% \t train_loss: 0.88 train_acc: 67.97% took: 0.13s\n",
      "Epoch 10 of 10, 85% \t train_loss: 0.76 train_acc: 78.91% took: 0.13s\n",
      "Epoch 10 of 10, 93% \t train_loss: 0.81 train_acc: 76.17% took: 0.12s\n",
      "val_loss = 1.64 val_acc = 44.60%\n",
      "Snapshot saved at epoch 10.\n",
      "Training done! A list of 10 models saved.\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save snapshots regularly\n",
    "save_every = 1    # Save model after every few epoches\n",
    "CES_mc_ces.full_train(save_dir = './models/multiClass/ces', save_every = save_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72ced315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating each model in the list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:11<00:00,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization done!\n",
      "Calibration (one time effort) takes:71.08s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "model_list_ces = CES_mc_ces.model_list     # Get the saved model list from the CES class\n",
    "\n",
    "# Compute conformity scores of calibration sets for each model and corresponding calibrated\n",
    "# confidence level, this might take some time if we have too many saved models but fortunately\n",
    "# this initialization will be a one-time effort.\n",
    "cal_time = time.time()\n",
    "C_PSet_ces = Conformal_PSet(net_ces, device, val_loader_ces, n_classes, model_list_ces, \\\n",
    "                           alpha,random_state = 0)\n",
    "print('Calibration (one time effort) takes:{:.2f}s.'.format(time.time()-cal_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1842462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 0 of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:07<00:00, 257.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 1 of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 183.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 2 of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 187.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 3 of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 188.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 4 of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:11<00:00, 181.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 5 of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 185.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 6 of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 188.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 7 of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 8 of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 187.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 9 of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 188.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting models takes: 104.24921941757202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick the best model for each test point\n",
    "start = time.time()\n",
    "best_loss_ces, best_model_ces, test_val_loss_history_ces = CES_mc_ces.select_model(inputs)\n",
    "print('selecting models takes:', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "875f0a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:39<00:00, 50.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing marginal prediction sets for 2000 test points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:47<00:00, 41.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing label conditional prediction sets for 2000 test points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the marginal conformal pvalues \n",
    "pset_m_ces= C_PSet_ces.pred_set(inputs, best_model_ces, marginal=True)\n",
    "# Get the label conditional conformal pvalues \n",
    "pset_lc_ces = C_PSet_ces.pred_set(inputs, best_model_ces, marginal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11fc2002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate marginal prediction sets.\n",
      "==================================================\n",
      "Marginal coverage:       90.750%\n",
      "Average size:            4.452\n",
      "Average size | coverage: 4.482\n",
      "==================================================\n",
      "Conditional coverage for label plane:       85.714%\n",
      "Average size:            3.730\n",
      "Average size | coverage: 3.607\n",
      "Conditional coverage for label car:       95.960%\n",
      "Average size:            3.566\n",
      "Average size | coverage: 3.537\n",
      "Conditional coverage for label bird:       90.769%\n",
      "Average size:            4.626\n",
      "Average size | coverage: 4.768\n",
      "Conditional coverage for label cat:       83.417%\n",
      "Average size:            5.503\n",
      "Average size | coverage: 5.663\n",
      "Conditional coverage for label deer:       91.919%\n",
      "Average size:            4.742\n",
      "Average size | coverage: 4.775\n",
      "Conditional coverage for label dog:       94.595%\n",
      "Average size:            4.924\n",
      "Average size | coverage: 4.994\n",
      "Conditional coverage for label frog:       94.907%\n",
      "Average size:            5.157\n",
      "Average size | coverage: 5.210\n",
      "Conditional coverage for label horse:       91.192%\n",
      "Average size:            4.959\n",
      "Average size | coverage: 4.955\n",
      "Conditional coverage for label ship:       93.088%\n",
      "Average size:            3.502\n",
      "Average size | coverage: 3.510\n",
      "Conditional coverage for label truck:       85.714%\n",
      "Average size:            3.882\n",
      "Average size | coverage: 3.908\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate marginal prediction sets.')\n",
    "print('='*50)\n",
    "evaluate_marginal(pset_m_ces, labels.numpy())\n",
    "print('='*50)\n",
    "evaluate_conditional(pset_m_ces, labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e7ae8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate label conditional prediction sets.\n",
      "==================================================\n",
      "Marginal coverage:       90.100%\n",
      "Average size:            4.410\n",
      "Average size | coverage: 4.452\n",
      "==================================================\n",
      "Conditional coverage for label plane:       88.776%\n",
      "Average size:            3.612\n",
      "Average size | coverage: 3.511\n",
      "Conditional coverage for label car:       94.444%\n",
      "Average size:            3.722\n",
      "Average size | coverage: 3.717\n",
      "Conditional coverage for label bird:       91.282%\n",
      "Average size:            4.533\n",
      "Average size | coverage: 4.702\n",
      "Conditional coverage for label cat:       88.442%\n",
      "Average size:            5.397\n",
      "Average size | coverage: 5.528\n",
      "Conditional coverage for label deer:       83.333%\n",
      "Average size:            4.763\n",
      "Average size | coverage: 4.861\n",
      "Conditional coverage for label dog:       88.649%\n",
      "Average size:            4.795\n",
      "Average size | coverage: 4.860\n",
      "Conditional coverage for label frog:       93.056%\n",
      "Average size:            5.083\n",
      "Average size | coverage: 5.154\n",
      "Conditional coverage for label horse:       91.192%\n",
      "Average size:            4.798\n",
      "Average size | coverage: 4.795\n",
      "Conditional coverage for label ship:       94.470%\n",
      "Average size:            3.502\n",
      "Average size | coverage: 3.507\n",
      "Conditional coverage for label truck:       86.700%\n",
      "Average size:            3.956\n",
      "Average size | coverage: 4.023\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate label conditional prediction sets.')\n",
    "print('='*50)\n",
    "evaluate_marginal(pset_lc_ces, labels.numpy())\n",
    "print('='*50)\n",
    "evaluate_conditional(pset_lc_ces, labels.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
